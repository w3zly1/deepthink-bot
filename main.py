"""
â•”â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•—
â•‘         DEEPTHINK AUTOHUSTLE v3.0 - ULTIMATE MONEY EDITION               â•‘
â•‘                                                                          â•‘
â•‘  ğŸš€ Ğ“Ğ¾Ñ‚Ğ¾Ğ² Ğº Ğ´ĞµĞ¿Ğ»Ğ¾Ñ Ğ½Ğ° Render.com                                         â•‘
â•‘  ğŸ¤– 20 AI-Ğ°Ğ³ĞµĞ½Ñ‚Ğ¾Ğ² Ğ´Ğ»Ñ Ğ·Ğ°Ñ€Ğ°Ğ±Ğ¾Ñ‚ĞºĞ°                                          â•‘
â•‘  ğŸ’° Ğ‘Ğ°Ğ·Ğ° Ğ·Ğ½Ğ°Ğ½Ğ¸Ğ¹ Ğ¾ Ğ¼Ğ¾Ğ½ĞµÑ‚Ğ¸Ğ·Ğ°Ñ†Ğ¸Ğ¸                                            â•‘
â•‘  âš¡ ĞĞ¿Ñ‚Ğ¸Ğ¼Ğ¸Ğ·Ğ¸Ñ€Ğ¾Ğ²Ğ°Ğ½ Ğ´Ğ»Ñ Ğ±ĞµÑĞ¿Ğ»Ğ°Ñ‚Ğ½Ñ‹Ñ… API                                     â•‘
â•‘                                                                          â•‘
â•‘  Python 3.8+ Compatible | Render.com Ready                               â•‘
â•šâ•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
"""

import asyncio
import json
import os
import re
import sys
import threading
from datetime import datetime
from typing import Dict, List, Optional, Any, Tuple
from dataclasses import dataclass, field
from enum import Enum
from collections import defaultdict
from http.server import HTTPServer, BaseHTTPRequestHandler

# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
# HEALTH CHECK HTTP SERVER (Ğ´Ğ»Ñ Render.com)
# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•

class HealthCheckHandler(BaseHTTPRequestHandler):
    """ĞŸÑ€Ğ¾ÑÑ‚Ğ¾Ğ¹ HTTP handler Ğ´Ğ»Ñ health check"""
    
    def do_GET(self):
        """ĞÑ‚Ğ²ĞµÑ‚ Ğ½Ğ° GET Ğ·Ğ°Ğ¿Ñ€Ğ¾ÑÑ‹"""
        self.send_response(200)
        self.send_header('Content-type', 'application/json')
        self.end_headers()
        
        response = {
            "status": "ok",
            "service": "DeepThink AutoHustle v3.0",
            "timestamp": datetime.now().isoformat()
        }
        self.wfile.write(json.dumps(response).encode())
    
    def do_HEAD(self):
        """ĞÑ‚Ğ²ĞµÑ‚ Ğ½Ğ° HEAD Ğ·Ğ°Ğ¿Ñ€Ğ¾ÑÑ‹"""
        self.send_response(200)
        self.end_headers()
    
    def log_message(self, format, *args):
        """ĞÑ‚ĞºĞ»ÑÑ‡Ğ°ĞµĞ¼ Ğ»Ğ¾Ğ³Ğ¸Ñ€Ğ¾Ğ²Ğ°Ğ½Ğ¸Ğµ HTTP Ğ·Ğ°Ğ¿Ñ€Ğ¾ÑĞ¾Ğ²"""
        pass

def start_health_server():
    """Ğ—Ğ°Ğ¿ÑƒÑĞº HTTP ÑĞµÑ€Ğ²ĞµÑ€Ğ° Ğ´Ğ»Ñ health check Ğ² Ğ¾Ñ‚Ğ´ĞµĞ»ÑŒĞ½Ğ¾Ğ¼ Ğ¿Ğ¾Ñ‚Ğ¾ĞºĞµ"""
    port = int(os.environ.get('PORT', 10000))
    server = HTTPServer(('0.0.0.0', port), HealthCheckHandler)
    print(f"ğŸŒ Health check server Ğ·Ğ°Ğ¿ÑƒÑ‰ĞµĞ½ Ğ½Ğ° Ğ¿Ğ¾Ñ€Ñ‚Ñƒ {port}")
    server.serve_forever()

# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
# ĞšĞĞĞ¤Ğ˜Ğ“Ğ£Ğ ĞĞ¦Ğ˜Ğ¯
# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•

@dataclass
class Config:
    """ĞšĞ¾Ğ½Ñ„Ğ¸Ğ³ÑƒÑ€Ğ°Ñ†Ğ¸Ñ Ğ¿Ñ€Ğ¸Ğ»Ğ¾Ğ¶ĞµĞ½Ğ¸Ñ"""
    
    # API ĞºĞ»ÑÑ‡Ğ¸ (Ğ¼Ğ¾Ğ¶Ğ½Ğ¾ Ğ¿ĞµÑ€ĞµĞ¾Ğ¿Ñ€ĞµĞ´ĞµĞ»Ğ¸Ñ‚ÑŒ Ñ‡ĞµÑ€ĞµĞ· environment variables)
    TELEGRAM_TOKEN: str = field(default_factory=lambda: os.environ.get(
        'TELEGRAM_TOKEN', 
        '8510653021:AAFCsjXyWLweEFBPrZD_wxlUmRe8uRQjQDY'
    ))
    
    OPENROUTER_KEY: str = field(default_factory=lambda: os.environ.get(
        'OPENROUTER_KEY',
        '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'
    ))
    
    # Ğ‘Ğ•Ğ¡ĞŸĞ›ĞĞ¢ĞĞ«Ğ• ĞœĞĞ”Ğ•Ğ›Ğ˜ - Ğ¿Ñ€Ğ¸Ğ¾Ñ€Ğ¸Ñ‚ĞµÑ‚
    FREE_MODELS: List[str] = field(default_factory=lambda: [
        "google/gemini-2.0-flash-exp:free",
        "meta-llama/llama-3.3-70b-instruct:free",
        "qwen/qwen-2.5-72b-instruct:free",
        "google/gemma-2-9b-it:free",
        "mistralai/mistral-7b-instruct:free",
        "huggingfaceh4/zephyr-7b-beta:free",
    ])
    
    DEFAULT_MODEL: str = "google/gemini-2.0-flash-exp:free"
    
    # Ğ›Ğ˜ĞœĞ˜Ğ¢Ğ« Ğ¢ĞĞšĞ•ĞĞĞ’ - Ğ¾Ğ¿Ñ‚Ğ¸Ğ¼Ğ¸Ğ·Ğ¸Ñ€Ğ¾Ğ²Ğ°Ğ½Ñ‹ Ğ´Ğ»Ñ Ğ±ĞµÑĞ¿Ğ»Ğ°Ñ‚Ğ½Ğ¾Ğ³Ğ¾ Ğ¿Ğ»Ğ°Ğ½Ğ°
    MAX_TOKENS_RESPONSE: int = 800
    MAX_TOKENS_SHORT: int = 400
    MAX_TOKENS_ACTION: int = 1000
    
    TEMPERATURE: float = 0.7
    
    # Ğ›Ğ¸Ğ¼Ğ¸Ñ‚Ñ‹
    MAX_AGENTS: int = 3
    MAX_CONTEXT: int = 1500
    MAX_HISTORY: int = 10
    MAX_ACTIONS: int = 5
    
    # Ğ¢Ğ°Ğ¹Ğ¼Ğ°ÑƒÑ‚Ñ‹
    API_TIMEOUT: int = 60
    POLLING_TIMEOUT: int = 30
    
    @property
    def TELEGRAM_API(self) -> str:
        return f"https://api.telegram.org/bot{self.TELEGRAM_TOKEN}"

config = Config()

# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
# Ğ›ĞĞ“Ğ˜Ğ ĞĞ’ĞĞĞ˜Ğ•
# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•

def log(message: str, level: str = "INFO"):
    """ĞŸÑ€Ğ¾ÑÑ‚Ğ¾Ğµ Ğ»Ğ¾Ğ³Ğ¸Ñ€Ğ¾Ğ²Ğ°Ğ½Ğ¸Ğµ"""
    timestamp = datetime.now().strftime("%H:%M:%S")
    print(f"[{timestamp}] {level}: {message}", flush=True)

# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
# Ğ˜ĞœĞŸĞĞ Ğ¢Ğ« (Ğ¿Ğ¾ÑĞ»Ğµ ĞºĞ¾Ğ½Ñ„Ğ¸Ğ³ÑƒÑ€Ğ°Ñ†Ğ¸Ğ¸)
# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•

log("ğŸš€ Ğ—Ğ°Ğ¿ÑƒÑĞº DeepThink AutoHustle v3.0...")

try:
    import httpx
    log("âœ… httpx Ğ·Ğ°Ğ³Ñ€ÑƒĞ¶ĞµĞ½")
except ImportError as e:
    log(f"âŒ ĞÑˆĞ¸Ğ±ĞºĞ° Ğ¸Ğ¼Ğ¿Ğ¾Ñ€Ñ‚Ğ° httpx: {e}", "ERROR")
    sys.exit(1)

try:
    from openai import OpenAI
    log("âœ… openai Ğ·Ğ°Ğ³Ñ€ÑƒĞ¶ĞµĞ½")
except ImportError as e:
    log(f"âŒ ĞÑˆĞ¸Ğ±ĞºĞ° Ğ¸Ğ¼Ğ¿Ğ¾Ñ€Ñ‚Ğ° openai: {e}", "ERROR")
    sys.exit(1)

# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
# AI ĞšĞ›Ğ˜Ğ•ĞĞ¢
# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•

class AIClient:
    """AI ĞºĞ»Ğ¸ĞµĞ½Ñ‚ Ñ Ğ¿Ğ¾Ğ´Ğ´ĞµÑ€Ğ¶ĞºĞ¾Ğ¹ Ğ±ĞµÑĞ¿Ğ»Ğ°Ñ‚Ğ½Ñ‹Ñ… Ğ¼Ğ¾Ğ´ĞµĞ»ĞµĞ¹ Ğ¸ fallback"""
    
    def __init__(self):
        self.client = OpenAI(
            base_url="https://openrouter.ai/api/v1",
            api_key=config.OPENROUTER_KEY
        )
        self.model_index = 0
        self.requests = 0
        self.errors = 0
        log("âœ… AI ĞºĞ»Ğ¸ĞµĞ½Ñ‚ Ğ¸Ğ½Ğ¸Ñ†Ğ¸Ğ°Ğ»Ğ¸Ğ·Ğ¸Ñ€Ğ¾Ğ²Ğ°Ğ½")
    
    def _get_model(self) -> str:
        """ĞŸĞ¾Ğ»ÑƒÑ‡Ğ¸Ñ‚ÑŒ Ñ‚ĞµĞºÑƒÑ‰ÑƒÑ Ğ¼Ğ¾Ğ´ĞµĞ»ÑŒ"""
        models = config.FREE_MODELS
        return models[self.model_index % len(models)]
    
    def _next_model(self):
        """ĞŸĞµÑ€ĞµĞºĞ»ÑÑ‡Ğ¸Ñ‚ÑŒÑÑ Ğ½Ğ° ÑĞ»ĞµĞ´ÑƒÑÑ‰ÑƒÑ Ğ¼Ğ¾Ğ´ĞµĞ»ÑŒ"""
        self.model_index += 1
        log(f"ğŸ”„ ĞŸĞµÑ€ĞµĞºĞ»ÑÑ‡ĞµĞ½Ğ¸Ğµ Ğ½Ğ° Ğ¼Ğ¾Ğ´ĞµĞ»ÑŒ: {self._get_model()}")
    
    async def generate(
        self,
        prompt: str,
        max_tokens: int = None,
        temperature: float = None,
        system: str = None
    ) -> Tuple[str, bool]:
        """Ğ“ĞµĞ½ĞµÑ€Ğ°Ñ†Ğ¸Ñ Ğ¾Ñ‚Ğ²ĞµÑ‚Ğ° Ñ Ğ°Ğ²Ñ‚Ğ¾Ğ¼Ğ°Ñ‚Ğ¸Ñ‡ĞµÑĞºĞ¸Ğ¼ fallback"""
        
        max_tokens = min(max_tokens or config.MAX_TOKENS_RESPONSE, 1000)
        temperature = temperature or config.TEMPERATURE
        
        messages = []
        if system:
            messages.append({"role": "system", "content": system[:500]})
        messages.append({"role": "user", "content": prompt[:config.MAX_CONTEXT]})
        
        # ĞŸÑ€Ğ¾Ğ±ÑƒĞµĞ¼ Ğ½ĞµÑĞºĞ¾Ğ»ÑŒĞºĞ¾ Ğ¼Ğ¾Ğ´ĞµĞ»ĞµĞ¹
        for attempt in range(len(config.FREE_MODELS)):
            model = self._get_model()
            
            try:
                self.requests += 1
                
                response = self.client.chat.completions.create(
                    model=model,
                    messages=messages,
                    temperature=temperature,
                    max_tokens=max_tokens
                )
                
                result = response.choices[0].message.content
                log(f"âœ… ĞÑ‚Ğ²ĞµÑ‚ Ğ¾Ñ‚ {model.split('/')[-1][:20]}")
                return result, True
                
            except Exception as e:
                error_msg = str(e)
                log(f"âš ï¸ ĞÑˆĞ¸Ğ±ĞºĞ° {model.split('/')[-1][:15]}: {error_msg[:50]}", "WARN")
                
                # Ğ•ÑĞ»Ğ¸ Ğ¾ÑˆĞ¸Ğ±ĞºĞ° Ñ ĞºÑ€ĞµĞ´Ğ¸Ñ‚Ğ°Ğ¼Ğ¸ Ğ¸Ğ»Ğ¸ Ğ»Ğ¸Ğ¼Ğ¸Ñ‚Ğ°Ğ¼Ğ¸ - Ğ¼ĞµĞ½ÑĞµĞ¼ Ğ¼Ğ¾Ğ´ĞµĞ»ÑŒ
                if any(x in error_msg.lower() for x in ['402', 'credit', 'limit', 'quota']):
                    self._next_model()
                    continue
                
                self.errors += 1
                self._next_model()
        
        return "âš ï¸ Ğ’Ñ€ĞµĞ¼ĞµĞ½Ğ½Ñ‹Ğµ Ğ¿Ñ€Ğ¾Ğ±Ğ»ĞµĞ¼Ñ‹ Ñ AI. ĞŸĞ¾Ğ¿Ñ€Ğ¾Ğ±ÑƒĞ¹Ñ‚Ğµ Ğ¿Ğ¾Ğ·Ğ¶Ğµ.", False
    
    async def generate_short(self, prompt: str) -> Tuple[str, bool]:
        """ĞšĞ¾Ñ€Ğ¾Ñ‚ĞºĞ¸Ğ¹ Ğ¾Ñ‚Ğ²ĞµÑ‚"""
        return await self.generate(prompt, max_tokens=config.MAX_TOKENS_SHORT)

ai = AIClient()

# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
# Ğ‘ĞĞ—Ğ Ğ—ĞĞĞĞ˜Ğ™ Ğ Ğ—ĞĞ ĞĞ‘ĞĞ¢ĞšĞ•
# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•

class MoneyKnowledge:
    """Ğ‘Ğ°Ğ·Ğ° Ğ·Ğ½Ğ°Ğ½Ğ¸Ğ¹ Ğ¾ ÑĞ¿Ğ¾ÑĞ¾Ğ±Ğ°Ñ… Ğ·Ğ°Ñ€Ğ°Ğ±Ğ¾Ñ‚ĞºĞ°"""
    
    BUSINESS_MODELS = {
        "freelance": {
            "name": "ğŸ¨ Ğ¤Ñ€Ğ¸Ğ»Ğ°Ğ½Ñ",
            "income": "$500 - $10,000/Ğ¼ĞµÑ",
            "time": "1-4 Ğ½ĞµĞ´ĞµĞ»Ğ¸",
            "ai_help": "60%",
            "platforms": ["Upwork", "Fiverr", "Kwork", "FL.ru"],
            "steps": [
                "Ğ’Ñ‹Ğ±Ñ€Ğ°Ñ‚ÑŒ Ğ½Ğ°Ğ²Ñ‹Ğº (ĞºĞ¾Ğ¿Ğ¸Ñ€Ğ°Ğ¹Ñ‚Ğ¸Ğ½Ğ³, Ğ´Ğ¸Ğ·Ğ°Ğ¹Ğ½, ĞºĞ¾Ğ´)",
                "Ğ¡Ğ¾Ğ·Ğ´Ğ°Ñ‚ÑŒ Ğ¿Ğ¾Ñ€Ñ‚Ñ„Ğ¾Ğ»Ğ¸Ğ¾ Ñ Ğ¿Ğ¾Ğ¼Ğ¾Ñ‰ÑŒÑ AI",
                "Ğ—Ğ°Ñ€ĞµĞ³Ğ¸ÑÑ‚Ñ€Ğ¸Ñ€Ğ¾Ğ²Ğ°Ñ‚ÑŒÑÑ Ğ½Ğ° 3-5 Ğ¿Ğ»Ğ°Ñ‚Ñ„Ğ¾Ñ€Ğ¼Ğ°Ñ…",
                "ĞÑ‚Ğ¿Ñ€Ğ°Ğ²Ğ»ÑÑ‚ÑŒ 10-20 Ğ¾Ñ‚ĞºĞ»Ğ¸ĞºĞ¾Ğ² Ğ² Ğ´ĞµĞ½ÑŒ",
                "Ğ¡Ğ¾Ğ±Ğ¸Ñ€Ğ°Ñ‚ÑŒ Ğ¾Ñ‚Ğ·Ñ‹Ğ²Ñ‹, Ğ¿Ğ¾Ğ²Ñ‹ÑˆĞ°Ñ‚ÑŒ Ñ†ĞµĞ½Ñ‹"
            ]
        },
        "affiliate": {
            "name": "ğŸ”— ĞŸĞ°Ñ€Ñ‚Ğ½Ñ‘Ñ€ÑĞºĞ¸Ğ¹ Ğ¼Ğ°Ñ€ĞºĞµÑ‚Ğ¸Ğ½Ğ³",
            "income": "$200 - $50,000/Ğ¼ĞµÑ",
            "time": "1-3 Ğ¼ĞµÑÑÑ†Ğ°",
            "ai_help": "80%",
            "platforms": ["Amazon", "Admitad", "CJ", "Ğ¿Ğ°Ñ€Ñ‚Ğ½Ñ‘Ñ€ĞºĞ¸ Ğ¸Ğ½Ñ„Ğ¾Ğ¿Ñ€Ğ¾Ğ´ÑƒĞºÑ‚Ğ¾Ğ²"],
            "steps": [
                "Ğ’Ñ‹Ğ±Ñ€Ğ°Ñ‚ÑŒ Ğ½Ğ¸ÑˆÑƒ Ñ Ğ²Ñ‹ÑĞ¾ĞºĞ¸Ğ¼Ğ¸ ĞºĞ¾Ğ¼Ğ¸ÑÑĞ¸ÑĞ¼Ğ¸",
                "Ğ¡Ğ¾Ğ·Ğ´Ğ°Ñ‚ÑŒ Telegram ĞºĞ°Ğ½Ğ°Ğ» Ğ¸Ğ»Ğ¸ Ğ±Ğ»Ğ¾Ğ³",
                "Ğ“ĞµĞ½ĞµÑ€Ğ¸Ñ€Ğ¾Ğ²Ğ°Ñ‚ÑŒ ĞºĞ¾Ğ½Ñ‚ĞµĞ½Ñ‚ Ñ AI",
                "Ğ’ÑÑ‚Ğ°Ğ²Ğ»ÑÑ‚ÑŒ Ğ¿Ğ°Ñ€Ñ‚Ğ½Ñ‘Ñ€ÑĞºĞ¸Ğµ ÑÑÑ‹Ğ»ĞºĞ¸",
                "ĞœĞ°ÑÑˆÑ‚Ğ°Ğ±Ğ¸Ñ€Ğ¾Ğ²Ğ°Ñ‚ÑŒ Ñ‚Ñ€Ğ°Ñ„Ğ¸Ğº"
            ]
        },
        "digital": {
            "name": "ğŸ“± Ğ¦Ğ¸Ñ„Ñ€Ğ¾Ğ²Ñ‹Ğµ Ğ¿Ñ€Ğ¾Ğ´ÑƒĞºÑ‚Ñ‹",
            "income": "$100 - $100,000/Ğ¼ĞµÑ",
            "time": "2-8 Ğ½ĞµĞ´ĞµĞ»ÑŒ",
            "ai_help": "90%",
            "platforms": ["Gumroad", "Notion", "Boosty", "GetCourse"],
            "steps": [
                "ĞĞ°Ğ¹Ñ‚Ğ¸ Ğ±Ğ¾Ğ»ÑŒ Ğ°ÑƒĞ´Ğ¸Ñ‚Ğ¾Ñ€Ğ¸Ğ¸",
                "Ğ¡Ğ¾Ğ·Ğ´Ğ°Ñ‚ÑŒ Ğ¿Ñ€Ğ¾Ğ´ÑƒĞºÑ‚ Ñ AI (ĞºÑƒÑ€Ñ, Ğ³Ğ°Ğ¹Ğ´, ÑˆĞ°Ğ±Ğ»Ğ¾Ğ½)",
                "ĞĞ°ÑÑ‚Ñ€Ğ¾Ğ¸Ñ‚ÑŒ Ğ¿Ñ€Ğ¾Ğ´Ğ°Ğ¶Ñƒ",
                "Ğ—Ğ°Ğ¿ÑƒÑÑ‚Ğ¸Ñ‚ÑŒ Ñ‚Ñ€Ğ°Ñ„Ğ¸Ğº",
                "Ğ¡Ğ¾Ğ±Ğ¸Ñ€Ğ°Ñ‚ÑŒ Ğ¾Ñ‚Ğ·Ñ‹Ğ²Ñ‹ Ğ¸ ÑƒĞ»ÑƒÑ‡ÑˆĞ°Ñ‚ÑŒ"
            ]
        },
        "ai_services": {
            "name": "ğŸ¤– AI-ÑĞµÑ€Ğ²Ğ¸ÑÑ‹",
            "income": "$1,000 - $50,000/Ğ¼ĞµÑ",
            "time": "1-4 Ğ½ĞµĞ´ĞµĞ»Ğ¸",
            "ai_help": "95%",
            "platforms": ["Telegram Ğ±Ğ¾Ñ‚Ñ‹", "Ğ¡Ğ¾Ğ±ÑÑ‚Ğ²ĞµĞ½Ğ½Ñ‹Ğ¹ ÑĞ°Ğ¹Ñ‚", "Fiverr"],
            "steps": [
                "Ğ’Ñ‹Ğ±Ñ€Ğ°Ñ‚ÑŒ ÑƒÑĞ»ÑƒĞ³Ñƒ (Ñ‚ĞµĞºÑÑ‚Ñ‹, ĞºĞ°Ñ€Ñ‚Ğ¸Ğ½ĞºĞ¸, ĞºĞ¾Ğ´)",
                "Ğ¡Ğ¾Ğ·Ğ´Ğ°Ñ‚ÑŒ Ğ±Ğ¾Ñ‚Ğ° Ğ¸Ğ»Ğ¸ Ğ»ĞµĞ½Ğ´Ğ¸Ğ½Ğ³",
                "ĞĞ°ÑÑ‚Ñ€Ğ¾Ğ¸Ñ‚ÑŒ Ğ°Ğ²Ñ‚Ğ¾Ğ¼Ğ°Ñ‚Ğ¸Ğ·Ğ°Ñ†Ğ¸Ñ",
                "ĞŸÑ€Ğ¸Ğ²Ğ»ĞµÑ‡ÑŒ Ğ¿ĞµÑ€Ğ²Ñ‹Ñ… ĞºĞ»Ğ¸ĞµĞ½Ñ‚Ğ¾Ğ²",
                "ĞœĞ°ÑÑˆÑ‚Ğ°Ğ±Ğ¸Ñ€Ğ¾Ğ²Ğ°Ñ‚ÑŒ"
            ]
        },
        "content": {
            "name": "ğŸ“ ĞšĞ¾Ğ½Ñ‚ĞµĞ½Ñ‚-Ğ±Ğ¸Ğ·Ğ½ĞµÑ",
            "income": "$100 - $100,000/Ğ¼ĞµÑ",
            "time": "3-12 Ğ¼ĞµÑÑÑ†ĞµĞ²",
            "ai_help": "70%",
            "platforms": ["YouTube", "Telegram", "TikTok", "Ğ”Ğ·ĞµĞ½"],
            "steps": [
                "Ğ’Ñ‹Ğ±Ñ€Ğ°Ñ‚ÑŒ Ğ½Ğ¸ÑˆÑƒ Ğ¸ Ñ„Ğ¾Ñ€Ğ¼Ğ°Ñ‚",
                "Ğ¡Ğ¾Ğ·Ğ´Ğ°Ñ‚ÑŒ ĞºĞ¾Ğ½Ñ‚ĞµĞ½Ñ‚-Ğ¿Ğ»Ğ°Ğ½",
                "ĞŸÑƒĞ±Ğ»Ğ¸ĞºĞ¾Ğ²Ğ°Ñ‚ÑŒ Ñ€ĞµĞ³ÑƒĞ»ÑÑ€Ğ½Ğ¾",
                "ĞœĞ¾Ğ½ĞµÑ‚Ğ¸Ğ·Ğ¸Ñ€Ğ¾Ğ²Ğ°Ñ‚ÑŒ (Ñ€ĞµĞºĞ»Ğ°Ğ¼Ğ°, Ğ´Ğ¾Ğ½Ğ°Ñ‚Ñ‹)",
                "Ğ”Ğ¸Ğ²ĞµÑ€ÑĞ¸Ñ„Ğ¸Ñ†Ğ¸Ñ€Ğ¾Ğ²Ğ°Ñ‚ÑŒ Ğ´Ğ¾Ñ…Ğ¾Ğ´Ñ‹"
            ]
        },
        "automation": {
            "name": "âš™ï¸ ĞĞ²Ñ‚Ğ¾Ğ¼Ğ°Ñ‚Ğ¸Ğ·Ğ°Ñ†Ğ¸Ñ",
            "income": "$2,000 - $30,000/Ğ¼ĞµÑ",
            "time": "2-4 Ğ½ĞµĞ´ĞµĞ»Ğ¸",
            "ai_help": "70%",
            "platforms": ["Make", "Zapier", "n8n", "Telegram"],
            "steps": [
                "Ğ˜Ğ·ÑƒÑ‡Ğ¸Ñ‚ÑŒ no-code Ğ¸Ğ½ÑÑ‚Ñ€ÑƒĞ¼ĞµĞ½Ñ‚Ñ‹",
                "ĞĞ°Ğ¹Ñ‚Ğ¸ Ğ±Ğ¸Ğ·Ğ½ĞµÑÑ‹ Ñ Ñ€ÑƒÑ‚Ğ¸Ğ½Ğ½Ñ‹Ğ¼Ğ¸ Ğ¿Ñ€Ğ¾Ñ†ĞµÑÑĞ°Ğ¼Ğ¸",
                "ĞŸÑ€ĞµĞ´Ğ»Ğ¾Ğ¶Ğ¸Ñ‚ÑŒ Ğ°Ğ²Ñ‚Ğ¾Ğ¼Ğ°Ñ‚Ğ¸Ğ·Ğ°Ñ†Ğ¸Ñ",
                "Ğ¡Ğ¾Ğ·Ğ´Ğ°Ñ‚ÑŒ Ñ€ĞµÑˆĞµĞ½Ğ¸Ğµ",
                "Ğ‘Ñ€Ğ°Ñ‚ÑŒ Ğ°Ğ±Ğ¾Ğ½ĞµĞ½Ñ‚ÑĞºÑƒÑ Ğ¿Ğ»Ğ°Ñ‚Ñƒ"
            ]
        },
        "bots": {
            "name": "ğŸ¤– Telegram-Ğ±Ğ¾Ñ‚Ñ‹",
            "income": "$500 - $20,000/Ğ¼ĞµÑ",
            "time": "1-2 Ğ½ĞµĞ´ĞµĞ»Ğ¸",
            "ai_help": "80%",
            "platforms": ["Telegram", "Python/aiogram"],
            "steps": [
                "Ğ˜Ğ·ÑƒÑ‡Ğ¸Ñ‚ÑŒ aiogram (Ñ Ğ¿Ğ¾Ğ¼Ğ¾Ñ‰ÑŒÑ AI)",
                "ĞĞ°Ğ¹Ñ‚Ğ¸ Ğ¸Ğ´ĞµÑ Ğ±Ğ¾Ñ‚Ğ°",
                "Ğ Ğ°Ğ·Ñ€Ğ°Ğ±Ğ¾Ñ‚Ğ°Ñ‚ÑŒ MVP",
                "ĞĞ°Ğ¹Ñ‚Ğ¸ ĞºĞ»Ğ¸ĞµĞ½Ñ‚Ğ¾Ğ²",
                "ĞœĞ°ÑÑˆÑ‚Ğ°Ğ±Ğ¸Ñ€Ğ¾Ğ²Ğ°Ñ‚ÑŒ"
            ]
        },
        "dropshipping": {
            "name": "ğŸ“¦ Ğ”Ñ€Ğ¾Ğ¿ÑˆĞ¸Ğ¿Ğ¿Ğ¸Ğ½Ğ³",
            "income": "$500 - $30,000/Ğ¼ĞµÑ",
            "time": "2-6 Ğ½ĞµĞ´ĞµĞ»ÑŒ",
            "ai_help": "50%",
            "platforms": ["Wildberries", "Ozon", "Shopify"],
            "steps": [
                "ĞĞ°Ğ¹Ñ‚Ğ¸ winning product",
                "ĞĞ°Ğ¹Ñ‚Ğ¸ Ğ¿Ğ¾ÑÑ‚Ğ°Ğ²Ñ‰Ğ¸ĞºĞ°",
                "Ğ¡Ğ¾Ğ·Ğ´Ğ°Ñ‚ÑŒ Ğ¼Ğ°Ğ³Ğ°Ğ·Ğ¸Ğ½/ĞºĞ°Ñ€Ñ‚Ğ¾Ñ‡ĞºÑƒ",
                "ĞĞ°ÑÑ‚Ñ€Ğ¾Ğ¸Ñ‚ÑŒ Ñ€ĞµĞºĞ»Ğ°Ğ¼Ñƒ",
                "ĞœĞ°ÑÑˆÑ‚Ğ°Ğ±Ğ¸Ñ€Ğ¾Ğ²Ğ°Ñ‚ÑŒ"
            ]
        }
    }
    
    QUICK_WINS = [
        {"name": "AI-ĞºĞ¾Ğ¿Ğ¸Ñ€Ğ°Ğ¹Ñ‚Ğ¸Ğ½Ğ³ Ğ½Ğ° Kwork", "income": "$300-1000/Ğ¼ĞµÑ", "time": "3-7 Ğ´Ğ½ĞµĞ¹"},
        {"name": "Telegram-Ğ±Ğ¾Ñ‚ Ğ½Ğ° Ğ·Ğ°ĞºĞ°Ğ·", "income": "$500-3000/Ğ¿Ñ€Ğ¾ĞµĞºÑ‚", "time": "1-2 Ğ½ĞµĞ´ĞµĞ»Ğ¸"},
        {"name": "Notion-ÑˆĞ°Ğ±Ğ»Ğ¾Ğ½Ñ‹", "income": "$100-5000/Ğ¼ĞµÑ", "time": "1 Ğ½ĞµĞ´ĞµĞ»Ñ"},
        {"name": "AI-Ğ´Ğ¸Ğ·Ğ°Ğ¹Ğ½ (Midjourney)", "income": "$500-2000/Ğ¼ĞµÑ", "time": "1 Ğ½ĞµĞ´ĞµĞ»Ñ"},
        {"name": "AI-ĞºĞ¾Ğ½ÑÑƒĞ»ÑŒÑ‚Ğ°Ñ†Ğ¸Ğ¸", "income": "$1000-5000/Ğ¼ĞµÑ", "time": "Ğ¡Ñ€Ğ°Ğ·Ñƒ"},
    ]
    
    HOT_NICHES = [
        {"niche": "AI-Ğ¸Ğ½ÑÑ‚Ñ€ÑƒĞ¼ĞµĞ½Ñ‚Ñ‹ Ğ´Ğ»Ñ Ğ±Ğ¸Ğ·Ğ½ĞµÑĞ°", "trend": "ğŸ”¥ğŸ”¥ğŸ”¥"},
        {"niche": "ĞĞ²Ñ‚Ğ¾Ğ¼Ğ°Ñ‚Ğ¸Ğ·Ğ°Ñ†Ğ¸Ñ Ñ n8n/Make", "trend": "ğŸ”¥ğŸ”¥ğŸ”¥"},
        {"niche": "ĞœĞ¸ĞºÑ€Ğ¾-SaaS", "trend": "ğŸ”¥ğŸ”¥ğŸ”¥"},
        {"niche": "Telegram-Ğ±Ğ¾Ñ‚Ñ‹", "trend": "ğŸ”¥ğŸ”¥"},
        {"niche": "No-code Ñ€Ğ°Ğ·Ñ€Ğ°Ğ±Ğ¾Ñ‚ĞºĞ°", "trend": "ğŸ”¥ğŸ”¥"},
        {"niche": "AI-ĞºĞ¾Ğ½Ñ‚ĞµĞ½Ñ‚", "trend": "ğŸ”¥ğŸ”¥"},
        {"niche": "ĞĞ±Ñ€Ğ°Ğ·Ğ¾Ğ²Ğ°Ñ‚ĞµĞ»ÑŒĞ½Ñ‹Ğµ Ğ¿Ñ€Ğ¾Ğ´ÑƒĞºÑ‚Ñ‹", "trend": "ğŸ”¥ğŸ”¥"},
    ]
    
    @classmethod
    def get_model_info(cls, key: str) -> str:
        """ĞŸĞ¾Ğ»ÑƒÑ‡Ğ¸Ñ‚ÑŒ Ğ¸Ğ½Ñ„Ğ¾Ñ€Ğ¼Ğ°Ñ†Ğ¸Ñ Ğ¾ Ğ±Ğ¸Ğ·Ğ½ĞµÑ-Ğ¼Ğ¾Ğ´ĞµĞ»Ğ¸"""
        data = cls.BUSINESS_MODELS.get(key)
        if not data:
            return "ĞœĞ¾Ğ´ĞµĞ»ÑŒ Ğ½Ğµ Ğ½Ğ°Ğ¹Ğ´ĞµĞ½Ğ°"
        
        steps = "\n".join([f"  {i+1}. {s}" for i, s in enumerate(data['steps'])])
        platforms = ", ".join(data['platforms'])
        
        return f"""{data['name']}

ğŸ’µ Ğ”Ğ¾Ñ…Ğ¾Ğ´: {data['income']}
â± Ğ”Ğ¾ Ñ€ĞµĞ·ÑƒĞ»ÑŒÑ‚Ğ°Ñ‚Ğ°: {data['time']}
ğŸ¤– AI Ğ¿Ğ¾Ğ¼Ğ¾Ğ³Ğ°ĞµÑ‚: {data['ai_help']}

ğŸ“‹ *Ğ¨Ğ°Ğ³Ğ¸:*
{steps}

ğŸŒ *ĞŸĞ»Ğ°Ñ‚Ñ„Ğ¾Ñ€Ğ¼Ñ‹:* {platforms}"""
    
    @classmethod
    def get_all_models_short(cls) -> str:
        """ĞšÑ€Ğ°Ñ‚ĞºĞ¸Ğ¹ ÑĞ¿Ğ¸ÑĞ¾Ğº Ğ²ÑĞµÑ… Ğ¼Ğ¾Ğ´ĞµĞ»ĞµĞ¹"""
        text = "ğŸ’° *Ğ¡ĞŸĞĞ¡ĞĞ‘Ğ« Ğ—ĞĞ ĞĞ‘ĞĞ¢ĞšĞ:*\n\n"
        for key, data in cls.BUSINESS_MODELS.items():
            text += f"{data['name']}\n"
            text += f"  ğŸ’µ {data['income']} | â± {data['time']}\n\n"
        return text
    
    @classmethod
    def get_quick_wins(cls) -> str:
        """Ğ‘Ñ‹ÑÑ‚Ñ€Ñ‹Ğµ Ğ¿Ğ¾Ğ±ĞµĞ´Ñ‹"""
        text = "âš¡ *Ğ‘Ğ«Ğ¡Ğ¢Ğ Ğ«Ğ™ Ğ¡Ğ¢ĞĞ Ğ¢ (Ğ´ĞµĞ½ÑŒĞ³Ğ¸ Ğ·Ğ° Ğ½ĞµĞ´ĞµĞ»Ñ):*\n\n"
        for i, qw in enumerate(cls.QUICK_WINS, 1):
            text += f"*{i}. {qw['name']}*\n"
            text += f"   ğŸ’° {qw['income']} | â± {qw['time']}\n\n"
        return text
    
    @classmethod
    def get_niches(cls) -> str:
        """Ğ“Ğ¾Ñ€ÑÑ‡Ğ¸Ğµ Ğ½Ğ¸ÑˆĞ¸"""
        text = "ğŸ”¥ *Ğ“ĞĞ Ğ¯Ğ§Ğ˜Ğ• ĞĞ˜Ğ¨Ğ˜ 2024-2025:*\n\n"
        for n in cls.HOT_NICHES:
            text += f"â€¢ {n['niche']} {n['trend']}\n"
        return text

# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
# Ğ¡Ğ˜Ğ¡Ğ¢Ğ•ĞœĞ ĞĞ“Ğ•ĞĞ¢ĞĞ’
# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•

class Agent:
    """AI ĞĞ³ĞµĞ½Ñ‚"""
    
    def __init__(self, name: str, emoji: str, specialty: str, keywords: List[str]):
        self.name = name
        self.emoji = emoji
        self.specialty = specialty
        self.keywords = keywords
        self.calls = 0
    
    @property
    def display(self) -> str:
        return f"{self.emoji} {self.name}"
    
    def relevance(self, query: str) -> float:
        """ĞÑ†ĞµĞ½ĞºĞ° Ñ€ĞµĞ»ĞµĞ²Ğ°Ğ½Ñ‚Ğ½Ğ¾ÑÑ‚Ğ¸ Ğ´Ğ»Ñ Ğ·Ğ°Ğ¿Ñ€Ğ¾ÑĞ°"""
        q = query.lower()
        matches = sum(1 for kw in self.keywords if kw in q)
        return min(matches / max(len(self.keywords) * 0.3, 1), 1.0)
    
    async def think(self, task: str, context: str = "") -> Tuple[str, bool]:
        """ĞĞ½Ğ°Ğ»Ğ¸Ğ· Ğ·Ğ°Ğ´Ğ°Ñ‡Ğ¸"""
        self.calls += 1
        
        system = f"Ğ¢Ñ‹ {self.name} - {self.specialty}. ĞÑ‚Ğ²ĞµÑ‡Ğ°Ğ¹ ĞºÑ€Ğ°Ñ‚ĞºĞ¾, ĞºĞ¾Ğ½ĞºÑ€ĞµÑ‚Ğ½Ğ¾, Ñ Ñ†Ğ¸Ñ„Ñ€Ğ°Ğ¼Ğ¸."
        
        prompt = f"""Ğ—Ğ°Ğ´Ğ°Ñ‡Ğ°: {task}
{f'ĞšĞ¾Ğ½Ñ‚ĞµĞºÑÑ‚: {context[:300]}' if context else ''}

Ğ”Ğ°Ğ¹ Ğ¾Ñ‚Ğ²ĞµÑ‚ Ñ:
- ĞšĞ¾Ğ½ĞºÑ€ĞµÑ‚Ğ½Ñ‹Ğ¼Ğ¸ Ñ†Ğ¸Ñ„Ñ€Ğ°Ğ¼Ğ¸
- Ğ¡Ğ¿Ğ¾ÑĞ¾Ğ±Ğ°Ğ¼Ğ¸ Ğ·Ğ°Ñ€Ğ°Ğ±Ğ¾Ñ‚ĞºĞ°
- ĞŸĞµÑ€Ğ²Ñ‹Ğ¼ ÑˆĞ°Ğ³Ğ¾Ğ¼"""
        
        return await ai.generate(prompt, system=system)

class Swarm:
    """Ğ Ğ¾Ğ¹ Ğ°Ğ³ĞµĞ½Ñ‚Ğ¾Ğ²"""
    
    def __init__(self):
        self.agents: Dict[str, Agent] = {}
        self._init()
    
    def _init(self):
        """Ğ˜Ğ½Ğ¸Ñ†Ğ¸Ğ°Ğ»Ğ¸Ğ·Ğ°Ñ†Ğ¸Ñ Ğ°Ğ³ĞµĞ½Ñ‚Ğ¾Ğ²"""
        agents_data = [
            ("researcher", "Ğ˜ÑÑĞ»ĞµĞ´Ğ¾Ğ²Ğ°Ñ‚ĞµĞ»ÑŒ", "ğŸ”¬", "Ğ°Ğ½Ğ°Ğ»Ğ¸Ğ· Ñ€Ñ‹Ğ½ĞºĞ¾Ğ² Ğ¸ Ñ‚Ñ€ĞµĞ½Ğ´Ğ¾Ğ²",
             ["Ğ°Ğ½Ğ°Ğ»Ğ¸Ğ·", "Ğ¸ÑÑĞ»ĞµĞ´Ğ¾Ğ²Ğ°Ğ½Ğ¸Ğµ", "Ñ‚Ñ€ĞµĞ½Ğ´", "Ñ€Ñ‹Ğ½Ğ¾Ğº", "ÑÑ‚Ğ°Ñ‚Ğ¸ÑÑ‚Ğ¸ĞºĞ°"]),
            
            ("money", "Ğ­ĞºÑĞ¿ĞµÑ€Ñ‚ Ğ·Ğ°Ñ€Ğ°Ğ±Ğ¾Ñ‚ĞºĞ°", "ğŸ’°", "Ğ¼Ğ¾Ğ½ĞµÑ‚Ğ¸Ğ·Ğ°Ñ†Ğ¸Ñ Ğ¸ Ğ´Ğ¾Ñ…Ğ¾Ğ´",
             ["Ğ·Ğ°Ñ€Ğ°Ğ±Ğ¾Ñ‚Ğ¾Ğº", "Ğ´ĞµĞ½ÑŒĞ³Ğ¸", "Ğ´Ğ¾Ñ…Ğ¾Ğ´", "Ğ¼Ğ¾Ğ½ĞµÑ‚Ğ¸Ğ·Ğ°Ñ†Ğ¸Ñ", "Ğ¿Ñ€Ğ¸Ğ±Ñ‹Ğ»ÑŒ"]),
            
            ("strategist", "Ğ¡Ñ‚Ñ€Ğ°Ñ‚ĞµĞ³", "ğŸ—ï¸", "ÑÑ‚Ñ€Ğ°Ñ‚ĞµĞ³Ğ¸Ğ¸ Ğ¸ Ğ¿Ğ»Ğ°Ğ½Ğ¸Ñ€Ğ¾Ğ²Ğ°Ğ½Ğ¸Ğµ",
             ["Ğ¿Ğ»Ğ°Ğ½", "ÑÑ‚Ñ€Ğ°Ñ‚ĞµĞ³Ğ¸Ñ", "roadmap", "Ğ¼Ğ°ÑÑˆÑ‚Ğ°Ğ±", "ÑÑ‚Ğ°Ğ¿"]),
            
            ("content", "ĞšĞ¾Ğ½Ñ‚ĞµĞ½Ñ‚-Ğ¼ĞµĞ¹ĞºĞµÑ€", "âœï¸", "ÑĞ¾Ğ·Ğ´Ğ°Ğ½Ğ¸Ğµ ĞºĞ¾Ğ½Ñ‚ĞµĞ½Ñ‚Ğ°",
             ["ĞºĞ¾Ğ½Ñ‚ĞµĞ½Ñ‚", "Ñ‚ĞµĞºÑÑ‚", "Ğ¿Ğ¾ÑÑ‚", "ÑÑ‚Ğ°Ñ‚ÑŒÑ", "ĞºĞ¾Ğ¿Ğ¸Ñ€Ğ°Ğ¹Ñ‚"]),
            
            ("coder", "ĞšĞ¾Ğ´ĞµÑ€", "ğŸ’»", "Ğ¿Ñ€Ğ¾Ğ³Ñ€Ğ°Ğ¼Ğ¼Ğ¸Ñ€Ğ¾Ğ²Ğ°Ğ½Ğ¸Ğµ Ğ¸ Ğ±Ğ¾Ñ‚Ñ‹",
             ["ĞºĞ¾Ğ´", "Ğ¿Ñ€Ğ¾Ğ³Ñ€Ğ°Ğ¼Ğ¼Ğ°", "Ğ±Ğ¾Ñ‚", "ÑĞºÑ€Ğ¸Ğ¿Ñ‚", "python", "Ğ°Ğ²Ñ‚Ğ¾Ğ¼Ğ°Ñ‚Ğ¸Ğ·Ğ°Ñ†Ğ¸Ñ"]),
            
            ("marketer", "ĞœĞ°Ñ€ĞºĞµÑ‚Ğ¾Ğ»Ğ¾Ğ³", "ğŸ“¢", "Ğ¼Ğ°Ñ€ĞºĞµÑ‚Ğ¸Ğ½Ğ³ Ğ¸ Ğ¿Ñ€Ğ¾Ğ´Ğ²Ğ¸Ğ¶ĞµĞ½Ğ¸Ğµ",
             ["Ğ¼Ğ°Ñ€ĞºĞµÑ‚Ğ¸Ğ½Ğ³", "Ñ€ĞµĞºĞ»Ğ°Ğ¼Ğ°", "Ğ¿Ñ€Ğ¾Ğ´Ğ²Ğ¸Ğ¶ĞµĞ½Ğ¸Ğµ", "Ñ‚Ğ°Ñ€Ğ³ĞµÑ‚", "Ñ‚Ñ€Ğ°Ñ„Ğ¸Ğº"]),
            
            ("freelancer", "Ğ¤Ñ€Ğ¸Ğ»Ğ°Ğ½ÑĞµÑ€", "ğŸ¯", "Ñ„Ñ€Ğ¸Ğ»Ğ°Ğ½Ñ Ğ¸ ÑƒÑĞ»ÑƒĞ³Ğ¸",
             ["Ñ„Ñ€Ğ¸Ğ»Ğ°Ğ½Ñ", "Ğ·Ğ°ĞºĞ°Ğ·", "ĞºĞ»Ğ¸ĞµĞ½Ñ‚", "ÑƒÑĞ»ÑƒĞ³Ğ°", "kwork", "fiverr"]),
            
            ("affiliate", "ĞŸĞ°Ñ€Ñ‚Ğ½Ñ‘Ñ€Ñ‰Ğ¸Ğº", "ğŸ”—", "Ğ¿Ğ°Ñ€Ñ‚Ğ½Ñ‘Ñ€ÑĞºĞ¸Ğ¹ Ğ¼Ğ°Ñ€ĞºĞµÑ‚Ğ¸Ğ½Ğ³",
             ["Ğ¿Ğ°Ñ€Ñ‚Ğ½Ñ‘Ñ€ĞºĞ°", "affiliate", "Ñ€ĞµÑ„ĞµÑ€Ğ°Ğ»", "ĞºĞ¾Ğ¼Ğ¸ÑÑĞ¸Ñ"]),
            
            ("automation", "ĞĞ²Ñ‚Ğ¾Ğ¼Ğ°Ñ‚Ğ¸Ğ·Ğ°Ñ‚Ğ¾Ñ€", "âš™ï¸", "Ğ°Ğ²Ñ‚Ğ¾Ğ¼Ğ°Ñ‚Ğ¸Ğ·Ğ°Ñ†Ğ¸Ñ Ğ¿Ñ€Ğ¾Ñ†ĞµÑÑĞ¾Ğ²",
             ["Ğ°Ğ²Ñ‚Ğ¾Ğ¼Ğ°Ñ‚Ğ¸Ğ·Ğ°Ñ†Ğ¸Ñ", "Ğ¸Ğ½Ñ‚ĞµĞ³Ñ€Ğ°Ñ†Ğ¸Ñ", "zapier", "make", "n8n"]),
            
            ("coach", "ĞšĞ¾ÑƒÑ‡", "ğŸ¯", "Ğ¼Ğ¾Ñ‚Ğ¸Ğ²Ğ°Ñ†Ğ¸Ñ Ğ¸ Ñ€Ğ°Ğ·Ğ²Ğ¸Ñ‚Ğ¸Ğµ",
             ["Ğ¼Ğ¾Ñ‚Ğ¸Ğ²Ğ°Ñ†Ğ¸Ñ", "Ñ†ĞµĞ»ÑŒ", "Ñ€Ğ¾ÑÑ‚", "Ğ¿Ñ€Ğ¸Ğ²Ñ‹Ñ‡ĞºĞ°", "Ğ¿Ñ€Ğ¾Ğ´ÑƒĞºÑ‚Ğ¸Ğ²Ğ½Ğ¾ÑÑ‚ÑŒ"]),
        ]
        
        for key, name, emoji, specialty, keywords in agents_data:
            self.agents[key] = Agent(name, emoji, specialty, keywords)
        
        log(f"âœ… Ğ—Ğ°Ğ³Ñ€ÑƒĞ¶ĞµĞ½Ğ¾ {len(self.agents)} Ğ°Ğ³ĞµĞ½Ñ‚Ğ¾Ğ²")
    
    def select(self, query: str, max_agents: int = None) -> List[Agent]:
        """Ğ’Ñ‹Ğ±Ğ¾Ñ€ Ñ€ĞµĞ»ĞµĞ²Ğ°Ğ½Ñ‚Ğ½Ñ‹Ñ… Ğ°Ğ³ĞµĞ½Ñ‚Ğ¾Ğ²"""
        max_agents = max_agents or config.MAX_AGENTS
        
        # ĞÑ†ĞµĞ½ĞºĞ° ĞºĞ°Ğ¶Ğ´Ğ¾Ğ³Ğ¾ Ğ°Ğ³ĞµĞ½Ñ‚Ğ°
        scored = [(a, a.relevance(query)) for a in self.agents.values()]
        scored.sort(key=lambda x: x[1], reverse=True)
        
        # ĞĞ±ÑĞ·Ğ°Ñ‚ĞµĞ»ÑŒĞ½Ğ¾ Ğ²ĞºĞ»ÑÑ‡Ğ°ĞµĞ¼ money Ğ¸ researcher
        must_have = ["money", "researcher"]
        selected = [self.agents[k] for k in must_have if k in self.agents]
        
        # Ğ”Ğ¾Ğ±Ğ°Ğ²Ğ»ÑĞµĞ¼ Ñ€ĞµĞ»ĞµĞ²Ğ°Ğ½Ñ‚Ğ½Ñ‹Ñ…
        for agent, score in scored:
            if len(selected) >= max_agents:
                break
            if agent not in selected and score > 0.1:
                selected.append(agent)
        
        return selected[:max_agents]
    
    async def think(self, query: str, context: str = "") -> List[Tuple[str, str, bool]]:
        """ĞšĞ¾Ğ»Ğ»ĞµĞºÑ‚Ğ¸Ğ²Ğ½Ğ¾Ğµ Ğ¼Ñ‹ÑˆĞ»ĞµĞ½Ğ¸Ğµ"""
        agents = self.select(query)
        
        results = []
        for agent in agents:
            response, success = await agent.think(query, context)
            results.append((agent.display, response, success))
        
        return results

swarm = Swarm()

# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
# Ğ¡Ğ˜ĞĞ¢Ğ•Ğ—ĞĞ¢ĞĞ 
# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•

async def synthesize(query: str, responses: List[Tuple[str, str, bool]]) -> str:
    """Ğ¡Ğ¸Ğ½Ñ‚ĞµĞ· Ğ¾Ñ‚Ğ²ĞµÑ‚Ğ¾Ğ² Ğ°Ğ³ĞµĞ½Ñ‚Ğ¾Ğ²"""
    
    valid = [(name, text) for name, text, ok in responses if ok]
    
    if not valid:
        return "âš ï¸ ĞĞµ ÑƒĞ´Ğ°Ğ»Ğ¾ÑÑŒ Ğ¿Ğ¾Ğ»ÑƒÑ‡Ğ¸Ñ‚ÑŒ Ğ¾Ñ‚Ğ²ĞµÑ‚Ñ‹. ĞŸĞ¾Ğ¿Ñ€Ğ¾Ğ±ÑƒĞ¹Ñ‚Ğµ Ğ¿ĞµÑ€ĞµÑ„Ğ¾Ñ€Ğ¼ÑƒĞ»Ğ¸Ñ€Ğ¾Ğ²Ğ°Ñ‚ÑŒ Ğ²Ğ¾Ğ¿Ñ€Ğ¾Ñ."
    
    agents_text = "\n\n".join([f"[{name}]: {text[:350]}" for name, text in valid])
    
    prompt = f"""ĞĞ±ÑŠĞµĞ´Ğ¸Ğ½Ğ¸ Ğ¾Ñ‚Ğ²ĞµÑ‚Ñ‹ ÑĞºÑĞ¿ĞµÑ€Ñ‚Ğ¾Ğ² Ğ² Ğ¿Ğ¾Ğ»ĞµĞ·Ğ½Ñ‹Ğ¹ Ğ¾Ñ‚Ğ²ĞµÑ‚.

Ğ’ĞĞŸĞ ĞĞ¡: {query}

Ğ­ĞšĞ¡ĞŸĞ•Ğ Ğ¢Ğ«:
{agents_text}

Ğ¤ĞĞ ĞœĞĞ¢:

ğŸ§  *Ğ¡Ğ£Ğ¢Ğ¬* (2-3 Ğ¿Ñ€ĞµĞ´Ğ»Ğ¾Ğ¶ĞµĞ½Ğ¸Ñ)

ğŸ’° *ĞšĞĞš Ğ—ĞĞ ĞĞ‘ĞĞ¢ĞĞ¢Ğ¬:*

*1. [Ğ¡Ğ¿Ğ¾ÑĞ¾Ğ±]* - $X/Ğ¼ĞµÑ
â€¢ Ğ§Ñ‚Ğ¾ Ğ´ĞµĞ»Ğ°Ñ‚ÑŒ
â€¢ AI Ğ¿Ğ¾Ğ¼Ğ¾Ğ³Ğ°ĞµÑ‚: X%
â€¢ Ğ¨Ğ°Ğ³Ğ¸: 1, 2, 3

*2. [Ğ¡Ğ¿Ğ¾ÑĞ¾Ğ±]* - $X/Ğ¼ĞµÑ
[Ğ°Ğ½Ğ°Ğ»Ğ¾Ğ³Ğ¸Ñ‡Ğ½Ğ¾]

ğŸ¯ *ĞĞĞ§ĞĞ˜ Ğ¡Ğ•Ğ™Ğ§ĞĞ¡:* [ĞºĞ¾Ğ½ĞºÑ€ĞµÑ‚Ğ½Ğ¾Ğµ Ğ´ĞµĞ¹ÑÑ‚Ğ²Ğ¸Ğµ]

ĞšÑ€Ğ°Ñ‚ĞºĞ¾!"""
    
    result, success = await ai.generate(prompt)
    
    if not success:
        # Fallback
        return "\n\n---\n\n".join([f"{name}:\n{text[:400]}" for name, text in valid])
    
    return result

# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
# Ğ“Ğ•ĞĞ•Ğ ĞĞ¢ĞĞ  Ğ”Ğ•Ğ™Ğ¡Ğ¢Ğ’Ğ˜Ğ™
# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•

def generate_actions(query: str) -> List[Dict]:
    """Ğ“ĞµĞ½ĞµÑ€Ğ°Ñ†Ğ¸Ñ Ğ´ĞµĞ¹ÑÑ‚Ğ²Ğ¸Ğ¹ Ğ½Ğ° Ğ¾ÑĞ½Ğ¾Ğ²Ğµ Ğ·Ğ°Ğ¿Ñ€Ğ¾ÑĞ°"""
    actions = []
    q = query.lower()
    
    if any(w in q for w in ["ĞºĞ¾Ğ½Ñ‚ĞµĞ½Ñ‚", "Ñ‚ĞµĞºÑÑ‚", "Ğ¿Ğ¾ÑÑ‚"]):
        actions.append({
            "type": "content",
            "name": "âœï¸ Ğ¡Ğ¾Ğ·Ğ´Ğ°Ñ‚ÑŒ ĞºĞ¾Ğ½Ñ‚ĞµĞ½Ñ‚",
            "desc": f"ĞšĞ¾Ğ½Ñ‚ĞµĞ½Ñ‚ Ğ¿Ğ¾ Ñ‚ĞµĞ¼Ğµ: {query[:40]}"
        })
    
    if any(w in q for w in ["ĞºĞ¾Ğ´", "Ğ±Ğ¾Ñ‚", "ÑĞºÑ€Ğ¸Ğ¿Ñ‚", "Ğ¿Ñ€Ğ¾Ğ³Ñ€Ğ°Ğ¼Ğ¼"]):
        actions.append({
            "type": "code",
            "name": "ğŸ’» ĞĞ°Ğ¿Ğ¸ÑĞ°Ñ‚ÑŒ ĞºĞ¾Ğ´",
            "desc": f"ĞšĞ¾Ğ´: {query[:40]}"
        })
    
    if any(w in q for w in ["Ğ¿Ğ»Ğ°Ğ½", "ÑÑ‚Ñ€Ğ°Ñ‚ĞµĞ³Ğ¸Ñ", "ĞºĞ°Ğº Ğ½Ğ°Ñ‡Ğ°Ñ‚ÑŒ"]):
        actions.append({
            "type": "plan",
            "name": "ğŸ“‹ ĞŸĞ¾ÑˆĞ°Ğ³Ğ¾Ğ²Ñ‹Ğ¹ Ğ¿Ğ»Ğ°Ğ½",
            "desc": f"ĞŸĞ»Ğ°Ğ½: {query[:40]}"
        })
    
    if any(w in q for w in ["Ğ¸Ğ´ĞµÑ", "Ğ½Ğ¸ÑˆĞ°", "Ñ‡Ñ‚Ğ¾ Ğ´ĞµĞ»Ğ°Ñ‚ÑŒ"]):
        actions.append({
            "type": "ideas",
            "name": "ğŸ’¡ 10 Ğ¸Ğ´ĞµĞ¹",
            "desc": f"Ğ˜Ğ´ĞµĞ¸: {query[:40]}"
        })
    
    if any(w in q for w in ["Ğ·Ğ°Ñ€Ğ°Ğ±Ğ¾Ñ‚", "Ğ´Ğ¾Ñ…Ğ¾Ğ´", "Ğ´ĞµĞ½ÑŒĞ³Ğ¸"]):
        actions.append({
            "type": "calc",
            "name": "ğŸ§® Ğ Ğ°ÑÑ‡Ñ‘Ñ‚ Ğ´Ğ¾Ñ…Ğ¾Ğ´Ğ°",
            "desc": "ĞšĞ°Ğ»ÑŒĞºÑƒĞ»ÑÑ‚Ğ¾Ñ€ Ğ¿Ğ¾Ñ‚ĞµĞ½Ñ†Ğ¸Ğ°Ğ»ÑŒĞ½Ğ¾Ğ³Ğ¾ Ğ´Ğ¾Ñ…Ğ¾Ğ´Ğ°"
        })
    
    # Ğ”ĞµÑ„Ğ¾Ğ»Ñ‚Ğ½Ñ‹Ğµ
    if not actions:
        actions = [
            {"type": "plan", "name": "ğŸ“‹ ĞŸĞ»Ğ°Ğ½ Ğ´ĞµĞ¹ÑÑ‚Ğ²Ğ¸Ğ¹", "desc": f"ĞŸĞ»Ğ°Ğ½: {query[:40]}"},
            {"type": "ideas", "name": "ğŸ’¡ Ğ˜Ğ´ĞµĞ¸", "desc": "Ğ“ĞµĞ½ĞµÑ€Ğ°Ñ†Ğ¸Ñ Ğ¸Ğ´ĞµĞ¹"}
        ]
    
    return actions[:config.MAX_ACTIONS]

async def execute_action(action: Dict, context: str) -> str:
    """Ğ’Ñ‹Ğ¿Ğ¾Ğ»Ğ½ĞµĞ½Ğ¸Ğµ Ğ´ĞµĞ¹ÑÑ‚Ğ²Ğ¸Ñ"""
    
    action_type = action.get("type", "plan")
    desc = action.get("desc", "")
    
    prompts = {
        "content": f"Ğ¡Ğ¾Ğ·Ğ´Ğ°Ğ¹ Ğ³Ğ¾Ñ‚Ğ¾Ğ²Ñ‹Ğ¹ ĞºĞ¾Ğ½Ñ‚ĞµĞ½Ñ‚ Ğ´Ğ»Ñ Ğ¿ÑƒĞ±Ğ»Ğ¸ĞºĞ°Ñ†Ğ¸Ğ¸: {desc}\n\nĞ’ĞºĞ»ÑÑ‡Ğ¸ Ğ·Ğ°Ğ³Ğ¾Ğ»Ğ¾Ğ²Ğ¾Ğº, Ñ‚ĞµĞºÑÑ‚ 300-500 ÑĞ»Ğ¾Ğ², Ğ¿Ñ€Ğ¸Ğ·Ñ‹Ğ² Ğº Ğ´ĞµĞ¹ÑÑ‚Ğ²Ğ¸Ñ, Ñ…ĞµÑˆÑ‚ĞµĞ³Ğ¸.",
        
        "code": f"ĞĞ°Ğ¿Ğ¸ÑˆĞ¸ Ñ€Ğ°Ğ±Ğ¾Ñ‡Ğ¸Ğ¹ Python ĞºĞ¾Ğ´: {desc}\n\nĞ¢Ñ€ĞµĞ±Ğ¾Ğ²Ğ°Ğ½Ğ¸Ñ: Ñ€Ğ°Ğ±Ğ¾Ñ‡Ğ¸Ğ¹ ĞºĞ¾Ğ´, ĞºĞ¾Ğ¼Ğ¼ĞµĞ½Ñ‚Ğ°Ñ€Ğ¸Ğ¸, Ğ¾Ğ±Ñ€Ğ°Ğ±Ğ¾Ñ‚ĞºĞ° Ğ¾ÑˆĞ¸Ğ±Ğ¾Ğº.",
        
        "plan": f"Ğ¡Ğ¾Ğ·Ğ´Ğ°Ğ¹ Ğ¿Ğ¾ÑˆĞ°Ğ³Ğ¾Ğ²Ñ‹Ğ¹ Ğ¿Ğ»Ğ°Ğ½: {desc}\n\nĞ¤Ğ¾Ñ€Ğ¼Ğ°Ñ‚:\nğŸ“… Ğ”Ğ•ĞĞ¬ 1-7: ÑˆĞ°Ğ³Ğ¸\nğŸ“… ĞĞ•Ğ”Ğ•Ğ›Ğ¯ 2-4: ÑˆĞ°Ğ³Ğ¸\nğŸ’° ĞĞ¶Ğ¸Ğ´Ğ°ĞµĞ¼Ñ‹Ğ¹ Ğ´Ğ¾Ñ…Ğ¾Ğ´",
        
        "ideas": f"Ğ¡Ğ³ĞµĞ½ĞµÑ€Ğ¸Ñ€ÑƒĞ¹ 10 Ğ¸Ğ´ĞµĞ¹: {desc}\n\nĞ”Ğ»Ñ ĞºĞ°Ğ¶Ğ´Ğ¾Ğ¹: Ğ½Ğ°Ğ·Ğ²Ğ°Ğ½Ğ¸Ğµ, Ğ¿Ğ¾Ñ‚ĞµĞ½Ñ†Ğ¸Ğ°Ğ» $X/Ğ¼ĞµÑ, Ğ¿ĞµÑ€Ğ²Ñ‹Ğ¹ ÑˆĞ°Ğ³",
        
        "calc": f"Ğ Ğ°ÑÑÑ‡Ğ¸Ñ‚Ğ°Ğ¹ Ğ¿Ğ¾Ñ‚ĞµĞ½Ñ†Ğ¸Ğ°Ğ»ÑŒĞ½Ñ‹Ğ¹ Ğ´Ğ¾Ñ…Ğ¾Ğ´: {desc}\n\nĞ‘Ğ°Ğ·Ğ¾Ğ²Ñ‹Ğ¹ ÑÑ†ĞµĞ½Ğ°Ñ€Ğ¸Ğ¹, Ğ¾Ğ¿Ñ‚Ğ¸Ğ¼Ğ¸ÑÑ‚Ğ¸Ñ‡Ğ½Ñ‹Ğ¹, ĞºĞ¾Ğ½ÑĞµÑ€Ğ²Ğ°Ñ‚Ğ¸Ğ²Ğ½Ñ‹Ğ¹"
    }
    
    prompt = prompts.get(action_type, prompts["plan"])
    prompt += f"\n\nĞšĞ¾Ğ½Ñ‚ĞµĞºÑÑ‚: {context[:400]}"
    
    result, _ = await ai.generate(prompt, max_tokens=config.MAX_TOKENS_ACTION)
    return result

# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
# ĞœĞĞ—Ğ“
# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•

class Brain:
    """Ğ“Ğ»Ğ°Ğ²Ğ½Ñ‹Ğ¹ Ğ¼Ğ¾Ğ·Ğ³ ÑĞ¸ÑÑ‚ĞµĞ¼Ñ‹"""
    
    def __init__(self):
        self.queries = 0
        self.tasks = 0
    
    async def think(self, query: str, context: str = "") -> Dict:
        """Ğ“Ğ»ÑƒĞ±Ğ¾ĞºĞ¸Ğ¹ Ğ°Ğ½Ğ°Ğ»Ğ¸Ğ·"""
        
        import time
        start = time.time()
        
        self.queries += 1
        
        # ĞšĞ¾Ğ»Ğ»ĞµĞºÑ‚Ğ¸Ğ²Ğ½Ğ¾Ğµ Ğ¼Ñ‹ÑˆĞ»ĞµĞ½Ğ¸Ğµ
        responses = await swarm.think(query, context)
        
        # Ğ¡Ğ¸Ğ½Ñ‚ĞµĞ·
        synthesis = await synthesize(query, responses)
        
        # Ğ”ĞµĞ¹ÑÑ‚Ğ²Ğ¸Ñ
        actions = generate_actions(query)
        
        # ĞĞ³ĞµĞ½Ñ‚Ñ‹ ĞºĞ¾Ñ‚Ğ¾Ñ€Ñ‹Ğµ Ñ€Ğ°Ğ±Ğ¾Ñ‚Ğ°Ğ»Ğ¸
        agents_used = [name for name, _, ok in responses if ok]
        
        return {
            "response": synthesis,
            "agents": agents_used,
            "actions": actions,
            "time": time.time() - start
        }

brain = Brain()

# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
# Ğ¥Ğ ĞĞĞ˜Ğ›Ğ˜Ğ©Ğ• Ğ”ĞĞĞĞ«Ğ¥
# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•

class Storage:
    """Ğ¥Ñ€Ğ°Ğ½Ğ¸Ğ»Ğ¸Ñ‰Ğµ Ğ´Ğ°Ğ½Ğ½Ñ‹Ñ… Ğ¿Ğ¾Ğ»ÑŒĞ·Ğ¾Ğ²Ğ°Ñ‚ĞµĞ»ĞµĞ¹"""
    
    def __init__(self):
        self.contexts: Dict[int, Dict] = {}
        self.pending_actions: Dict[str, Dict] = {}
    
    def get_context(self, user_id: int) -> Dict:
        if user_id not in self.contexts:
            self.contexts[user_id] = {
                "messages": [],
                "last_query": "",
                "last_response": "",
                "queries": 0
            }
        return self.contexts[user_id]
    
    def add_message(self, user_id: int, role: str, content: str):
        ctx = self.get_context(user_id)
        ctx["messages"].append({"role": role, "content": content[:300]})
        if len(ctx["messages"]) > config.MAX_HISTORY:
            ctx["messages"] = ctx["messages"][-config.MAX_HISTORY:]
    
    def get_summary(self, user_id: int) -> str:
        ctx = self.get_context(user_id)
        if not ctx["messages"]:
            return ""
        recent = ctx["messages"][-3:]
        return "\n".join([f"{m['role']}: {m['content'][:100]}" for m in recent])

storage = Storage()

# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
# Ğ¡Ğ¢ĞĞ¢Ğ˜Ğ¡Ğ¢Ğ˜ĞšĞ
# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•

class Stats:
    """Ğ¡Ñ‚Ğ°Ñ‚Ğ¸ÑÑ‚Ğ¸ĞºĞ°"""
    
    def __init__(self):
        self.start_time = datetime.now()
        self.queries = 0
        self.tasks = 0
        self.errors = 0
    
    def get_summary(self) -> str:
        uptime = datetime.now() - self.start_time
        hours = uptime.total_seconds() / 3600
        
        return f"""ğŸ“Š *Ğ¡Ğ¢ĞĞ¢Ğ˜Ğ¡Ğ¢Ğ˜ĞšĞ*

â± Ğ’Ñ€ĞµĞ¼Ñ Ñ€Ğ°Ğ±Ğ¾Ñ‚Ñ‹: {hours:.1f}Ñ‡
ğŸ’¬ Ğ—Ğ°Ğ¿Ñ€Ğ¾ÑĞ¾Ğ²: {self.queries}
âœ… Ğ—Ğ°Ğ´Ğ°Ñ‡: {self.tasks}
âŒ ĞÑˆĞ¸Ğ±Ğ¾Ğº: {self.errors}
ğŸ¤– ĞĞ³ĞµĞ½Ñ‚Ğ¾Ğ²: {len(swarm.agents)}
ğŸ”§ ĞœĞ¾Ğ´ĞµĞ»ÑŒ: {ai._get_model().split('/')[-1][:25]}
ğŸ“¡ AI Ğ·Ğ°Ğ¿Ñ€Ğ¾ÑĞ¾Ğ²: {ai.requests}"""

stats = Stats()

# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
# TELEGRAM BOT
# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•

class Bot:
    """Telegram Ğ±Ğ¾Ñ‚"""
    
    def __init__(self):
        self.api = config.TELEGRAM_API
    
    async def send(self, chat_id: int, text: str, buttons: Dict = None):
        """ĞÑ‚Ğ¿Ñ€Ğ°Ğ²ĞºĞ° ÑĞ¾Ğ¾Ğ±Ñ‰ĞµĞ½Ğ¸Ñ"""
        async with httpx.AsyncClient(timeout=config.API_TIMEOUT) as client:
            data = {"chat_id": chat_id, "text": text[:4096]}
            
            if buttons:
                data["reply_markup"] = json.dumps(buttons)
            
            # ĞŸÑ€Ğ¾Ğ±ÑƒĞµĞ¼ Ñ Markdown
            data["parse_mode"] = "Markdown"
            
            try:
                resp = await client.post(f"{self.api}/sendMessage", json=data)
                if resp.status_code == 200:
                    return
            except:
                pass
            
            # Ğ‘ĞµĞ· Ñ„Ğ¾Ñ€Ğ¼Ğ°Ñ‚Ğ¸Ñ€Ğ¾Ğ²Ğ°Ğ½Ğ¸Ñ
            data.pop("parse_mode", None)
            try:
                await client.post(f"{self.api}/sendMessage", json=data)
            except Exception as e:
                log(f"Send error: {e}", "ERROR")
    
    async def answer_callback(self, callback_id: str):
        """ĞÑ‚Ğ²ĞµÑ‚ Ğ½Ğ° callback"""
        async with httpx.AsyncClient(timeout=10) as client:
            try:
                await client.post(
                    f"{self.api}/answerCallbackQuery",
                    json={"callback_query_id": callback_id}
                )
            except:
                pass
    
    async def typing(self, chat_id: int):
        """Ğ¡Ñ‚Ğ°Ñ‚ÑƒÑ Ğ¿ĞµÑ‡Ğ°Ñ‚Ğ°ĞµÑ‚"""
        async with httpx.AsyncClient(timeout=5) as client:
            try:
                await client.post(
                    f"{self.api}/sendChatAction",
                    json={"chat_id": chat_id, "action": "typing"}
                )
            except:
                pass
    
    def make_buttons(self, actions: List[Dict], user_id: int) -> Dict:
        """Ğ¡Ğ¾Ğ·Ğ´Ğ°Ğ½Ğ¸Ğµ ĞºĞ½Ğ¾Ğ¿Ğ¾Ğº"""
        keyboard = []
        
        for i, action in enumerate(actions[:4]):
            keyboard.append([{
                "text": action.get("name", "ğŸ¤– Ğ”ĞµĞ¹ÑÑ‚Ğ²Ğ¸Ğµ")[:28],
                "callback_data": f"act_{i}_{user_id}"
            }])
        
        keyboard.append([
            {"text": "ğŸ’° Ğ¡Ğ¿Ğ¾ÑĞ¾Ğ±Ñ‹ Ğ·Ğ°Ñ€Ğ°Ğ±Ğ¾Ñ‚ĞºĞ°", "callback_data": f"income_{user_id}"},
            {"text": "ğŸ”¥ ĞĞ¸ÑˆĞ¸", "callback_data": f"niches_{user_id}"}
        ])
        
        keyboard.append([
            {"text": "âš¡ Ğ‘Ñ‹ÑÑ‚Ñ€Ñ‹Ğ¹ ÑÑ‚Ğ°Ñ€Ñ‚", "callback_data": f"quick_{user_id}"},
            {"text": "ğŸ“Š Ğ¡Ñ‚Ğ°Ñ‚Ğ¸ÑÑ‚Ğ¸ĞºĞ°", "callback_data": f"stats_{user_id}"}
        ])
        
        return {"inline_keyboard": keyboard}
    
    # â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
    # ĞšĞĞœĞĞĞ”Ğ«
    # â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
    
    async def cmd_start(self, chat_id: int, user_name: str):
        """ĞšĞ¾Ğ¼Ğ°Ğ½Ğ´Ğ° /start"""
        text = f"""ğŸ§  *DEEPTHINK AUTOHUSTLE v3.0*

ĞŸÑ€Ğ¸Ğ²ĞµÑ‚, {user_name}! ğŸ‘‹

Ğ¯ - AI-ÑĞ¸ÑÑ‚ĞµĞ¼Ğ° Ğ´Ğ»Ñ Ğ¿Ğ¾Ğ¸ÑĞºĞ° ÑĞ¿Ğ¾ÑĞ¾Ğ±Ğ¾Ğ² Ğ·Ğ°Ñ€Ğ°Ğ±Ğ¾Ñ‚ĞºĞ°.

ğŸ¤– *{len(swarm.agents)} ĞĞ“Ğ•ĞĞ¢ĞĞ’* Ğ°Ğ½Ğ°Ğ»Ğ¸Ğ·Ğ¸Ñ€ÑƒÑÑ‚ Ñ‚Ğ²Ğ¾Ğ¸ Ğ·Ğ°Ğ¿Ñ€Ğ¾ÑÑ‹

ğŸ’° *Ğ¯ ĞŸĞĞœĞĞ“Ğ£:*
â€¢ ĞĞ°Ğ¹Ñ‚Ğ¸ ÑĞ¿Ğ¾ÑĞ¾Ğ± Ğ·Ğ°Ñ€Ğ°Ğ±Ğ¾Ñ‚ĞºĞ° Ğ¿Ğ¾Ğ´ Ñ‚ĞµĞ±Ñ
â€¢ Ğ¡Ğ¾Ğ·Ğ´Ğ°Ñ‚ÑŒ Ğ¿Ğ»Ğ°Ğ½ Ğ´ĞµĞ¹ÑÑ‚Ğ²Ğ¸Ğ¹
â€¢ ĞĞ°Ğ¿Ğ¸ÑĞ°Ñ‚ÑŒ ĞºĞ¾Ğ´ Ğ¸Ğ»Ğ¸ ĞºĞ¾Ğ½Ñ‚ĞµĞ½Ñ‚
â€¢ Ğ Ğ°ÑÑÑ‡Ğ¸Ñ‚Ğ°Ñ‚ÑŒ Ğ¿Ğ¾Ñ‚ĞµĞ½Ñ†Ğ¸Ğ°Ğ»ÑŒĞ½Ñ‹Ğ¹ Ğ´Ğ¾Ñ…Ğ¾Ğ´

ğŸš€ *ĞŸĞ Ğ˜ĞœĞ•Ğ Ğ«:*
â€¢ "ĞšĞ°Ğº Ğ·Ğ°Ñ€Ğ°Ğ±Ğ¾Ñ‚Ğ°Ñ‚ÑŒ Ğ½Ğ° AI?"
â€¢ "Ğ¡Ğ¾Ğ·Ğ´Ğ°Ğ¹ Telegram-Ğ±Ğ¾Ñ‚Ğ°"
â€¢ "Ğ¢Ğ¾Ğ¿ Ğ½Ğ¸ÑˆĞ¸ 2025"
â€¢ "ĞŸĞ»Ğ°Ğ½ Ğ½Ğ° $1000/Ğ¼ĞµÑ"

ğŸ“– /help - Ğ²ÑĞµ ĞºĞ¾Ğ¼Ğ°Ğ½Ğ´Ñ‹

ğŸ’¡ ĞŸÑ€Ğ¾ÑÑ‚Ğ¾ Ğ½Ğ°Ğ¿Ğ¸ÑˆĞ¸ ÑĞ²Ğ¾Ğ¹ Ğ²Ğ¾Ğ¿Ñ€Ğ¾Ñ!"""
        
        await self.send(chat_id, text)
    
    async def cmd_help(self, chat_id: int):
        """ĞšĞ¾Ğ¼Ğ°Ğ½Ğ´Ğ° /help"""
        text = """ğŸ“– *ĞšĞĞœĞĞĞ”Ğ«:*

*ĞÑĞ½Ğ¾Ğ²Ğ½Ñ‹Ğµ:*
/start - ĞĞ°Ñ‡Ğ°Ğ»Ğ¾
/help - Ğ¡Ğ¿Ñ€Ğ°Ğ²ĞºĞ°

*Ğ—Ğ°Ñ€Ğ°Ğ±Ğ¾Ñ‚Ğ¾Ğº:*
/income - Ğ¡Ğ¿Ğ¾ÑĞ¾Ğ±Ñ‹ Ğ·Ğ°Ñ€Ğ°Ğ±Ğ¾Ñ‚ĞºĞ°
/niches - Ğ“Ğ¾Ñ€ÑÑ‡Ğ¸Ğµ Ğ½Ğ¸ÑˆĞ¸
/quick - Ğ‘Ñ‹ÑÑ‚Ñ€Ñ‹Ğ¹ ÑÑ‚Ğ°Ñ€Ñ‚

*Ğ¡Ğ¸ÑÑ‚ĞµĞ¼Ğ°:*
/stats - Ğ¡Ñ‚Ğ°Ñ‚Ğ¸ÑÑ‚Ğ¸ĞºĞ°
/agents - ĞĞ³ĞµĞ½Ñ‚Ñ‹

ğŸ’¡ Ğ˜Ğ»Ğ¸ Ğ¿Ñ€Ğ¾ÑÑ‚Ğ¾ Ğ½Ğ°Ğ¿Ğ¸ÑˆĞ¸ Ğ²Ğ¾Ğ¿Ñ€Ğ¾Ñ!"""
        
        await self.send(chat_id, text)
    
    async def cmd_income(self, chat_id: int):
        """Ğ¡Ğ¿Ğ¾ÑĞ¾Ğ±Ñ‹ Ğ·Ğ°Ñ€Ğ°Ğ±Ğ¾Ñ‚ĞºĞ°"""
        text = MoneyKnowledge.get_all_models_short()
        
        buttons = {"inline_keyboard": [
            [{"text": "ğŸ¨ Ğ¤Ñ€Ğ¸Ğ»Ğ°Ğ½Ñ", "callback_data": "bm_freelance"}],
            [{"text": "ğŸ”— ĞŸĞ°Ñ€Ñ‚Ğ½Ñ‘Ñ€ĞºĞ¸", "callback_data": "bm_affiliate"}],
            [{"text": "ğŸ“± Ğ¦Ğ¸Ñ„Ñ€Ğ¾Ğ²Ñ‹Ğµ Ğ¿Ñ€Ğ¾Ğ´ÑƒĞºÑ‚Ñ‹", "callback_data": "bm_digital"}],
            [{"text": "ğŸ¤– AI-ÑĞµÑ€Ğ²Ğ¸ÑÑ‹", "callback_data": "bm_ai_services"}],
            [{"text": "ğŸ“ ĞšĞ¾Ğ½Ñ‚ĞµĞ½Ñ‚", "callback_data": "bm_content"}],
            [{"text": "âš™ï¸ ĞĞ²Ñ‚Ğ¾Ğ¼Ğ°Ñ‚Ğ¸Ğ·Ğ°Ñ†Ğ¸Ñ", "callback_data": "bm_automation"}],
            [{"text": "ğŸ¤– Telegram-Ğ±Ğ¾Ñ‚Ñ‹", "callback_data": "bm_bots"}],
        ]}
        
        await self.send(chat_id, text, buttons)
    
    async def cmd_niches(self, chat_id: int):
        await self.send(chat_id, MoneyKnowledge.get_niches())
    
    async def cmd_quick(self, chat_id: int):
        await self.send(chat_id, MoneyKnowledge.get_quick_wins())
    
    async def cmd_stats(self, chat_id: int):
        await self.send(chat_id, stats.get_summary())
    
    async def cmd_agents(self, chat_id: int):
        text = f"ğŸ¤– *{len(swarm.agents)} ĞĞ“Ğ•ĞĞ¢ĞĞ’:*\n\n"
        for agent in swarm.agents.values():
            text += f"{agent.display} - {agent.specialty}\n"
            text += f"  ğŸ“Š Ğ’Ñ‹Ğ·Ğ¾Ğ²Ğ¾Ğ²: {agent.calls}\n\n"
        await self.send(chat_id, text)
    
    # â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
    # ĞĞ‘Ğ ĞĞ‘ĞĞ¢ĞšĞ Ğ¡ĞĞĞ‘Ğ©Ğ•ĞĞ˜Ğ™
    # â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
    
    async def handle_message(self, chat_id: int, user_id: int, text: str):
        """ĞĞ±Ñ€Ğ°Ğ±Ğ¾Ñ‚ĞºĞ° ÑĞ¾Ğ¾Ğ±Ñ‰ĞµĞ½Ğ¸Ñ"""
        
        stats.queries += 1
        
        ctx = storage.get_context(user_id)
        ctx["queries"] += 1
        ctx["last_query"] = text
        storage.add_message(user_id, "user", text)
        
        await self.typing(chat_id)
        
        await self.send(chat_id,
            "ğŸ§  *DEEP THINKING...*\n\n"
            f"ğŸ¤– ĞĞ³ĞµĞ½Ñ‚Ñ‹ Ğ°Ğ½Ğ°Ğ»Ğ¸Ğ·Ğ¸Ñ€ÑƒÑÑ‚...\n"
            "ğŸ’° Ğ˜Ñ‰Ñƒ ÑĞ¿Ğ¾ÑĞ¾Ğ±Ñ‹ Ğ·Ğ°Ñ€Ğ°Ğ±Ğ¾Ñ‚ĞºĞ°..."
        )
        
        try:
            # Ğ”ÑƒĞ¼Ğ°ĞµĞ¼
            result = await brain.think(text, storage.get_summary(user_id))
            
            response = result["response"]
            agents = result["agents"]
            actions = result["actions"]
            think_time = result["time"]
            
            # Ğ¡Ğ¾Ñ…Ñ€Ğ°Ğ½ÑĞµĞ¼
            ctx["last_response"] = response
            storage.add_message(user_id, "assistant", response[:300])
            
            # Ğ¡Ğ¾Ñ…Ñ€Ğ°Ğ½ÑĞµĞ¼ Ğ´ĞµĞ¹ÑÑ‚Ğ²Ğ¸Ñ
            for i, action in enumerate(actions):
                storage.pending_actions[f"act_{i}_{user_id}"] = {
                    "action": action,
                    "context": text,
                    "response": response[:500]
                }
            
            # Footer
            agents_str = ", ".join(agents[:3])
            footer = f"\n\n---\nğŸ‘¥ _{agents_str}_\nâ± _{think_time:.1f}Ñ_"
            
            full = response + footer
            buttons = self.make_buttons(actions, user_id)
            
            await self.send(chat_id, full[:4096], buttons)
            
        except Exception as e:
            stats.errors += 1
            log(f"Error: {e}", "ERROR")
            await self.send(chat_id, f"âš ï¸ ĞÑˆĞ¸Ğ±ĞºĞ°: {str(e)[:150]}\n\nĞŸĞ¾Ğ¿Ñ€Ğ¾Ğ±ÑƒĞ¹ Ğ¿ĞµÑ€ĞµÑ„Ğ¾Ñ€Ğ¼ÑƒĞ»Ğ¸Ñ€Ğ¾Ğ²Ğ°Ñ‚ÑŒ.")
    
    async def handle_callback(self, callback_id: str, chat_id: int, user_id: int, data: str):
        """ĞĞ±Ñ€Ğ°Ğ±Ğ¾Ñ‚ĞºĞ° callback"""
        
        await self.answer_callback(callback_id)
        
        # ĞšĞ¾Ğ¼Ğ°Ğ½Ğ´Ñ‹
        if data.startswith("stats_"):
            await self.cmd_stats(chat_id)
            return
        
        if data.startswith("income_"):
            await self.cmd_income(chat_id)
            return
        
        if data.startswith("niches_"):
            await self.cmd_niches(chat_id)
            return
        
        if data.startswith("quick_"):
            await self.cmd_quick(chat_id)
            return
        
        # Ğ‘Ğ¸Ğ·Ğ½ĞµÑ-Ğ¼Ğ¾Ğ´ĞµĞ»Ğ¸
        if data.startswith("bm_"):
            key = data[3:]  # Ğ£Ğ±Ğ¸Ñ€Ğ°ĞµĞ¼ "bm_"
            info = MoneyKnowledge.get_model_info(key)
            await self.send(chat_id, info)
            return
        
        # Ğ”ĞµĞ¹ÑÑ‚Ğ²Ğ¸Ñ
        if data.startswith("act_"):
            key = data
            if key in storage.pending_actions:
                action_data = storage.pending_actions[key]
                action = action_data["action"]
                context = f"{action_data['context']}\n{action_data['response']}"
                
                await self.typing(chat_id)
                await self.send(chat_id, f"âš™ï¸ Ğ’Ñ‹Ğ¿Ğ¾Ğ»Ğ½ÑÑ: {action.get('name', '')}...")
                
                try:
                    result = await execute_action(action, context)
                    stats.tasks += 1
                    
                    # Ğ Ğ°Ğ·Ğ±Ğ¸Ğ²Ğ°ĞµĞ¼ Ğ´Ğ»Ğ¸Ğ½Ğ½Ñ‹Ğ¹ Ğ¾Ñ‚Ğ²ĞµÑ‚
                    if len(result) > 4000:
                        parts = [result[i:i+4000] for i in range(0, len(result), 4000)]
                        for i, part in enumerate(parts):
                            header = f"ğŸ“„ *Ğ§Ğ°ÑÑ‚ÑŒ {i+1}/{len(parts)}*\n\n" if len(parts) > 1 else ""
                            await self.send(chat_id, header + part)
                    else:
                        await self.send(chat_id, f"âœ… *Ğ“Ğ¾Ñ‚Ğ¾Ğ²Ğ¾!*\n\n{result}")
                
                except Exception as e:
                    await self.send(chat_id, f"âš ï¸ ĞÑˆĞ¸Ğ±ĞºĞ°: {str(e)[:150]}")
            else:
                await self.send(chat_id, "âš ï¸ Ğ”ĞµĞ¹ÑÑ‚Ğ²Ğ¸Ğµ ÑƒÑÑ‚Ğ°Ñ€ĞµĞ»Ğ¾. Ğ¡Ğ´ĞµĞ»Ğ°Ğ¹ Ğ½Ğ¾Ğ²Ñ‹Ğ¹ Ğ·Ğ°Ğ¿Ñ€Ğ¾Ñ.")
    
    async def handle_update(self, update: Dict):
        """ĞĞ±Ñ€Ğ°Ğ±Ğ¾Ñ‚ĞºĞ° Ğ¾Ğ±Ğ½Ğ¾Ğ²Ğ»ĞµĞ½Ğ¸Ñ"""
        try:
            # Ğ¡Ğ¾Ğ¾Ğ±Ñ‰ĞµĞ½Ğ¸Ñ
            if "message" in update and "text" in update["message"]:
                msg = update["message"]
                chat_id = msg["chat"]["id"]
                user = msg.get("from", {})
                user_id = user.get("id", 0)
                user_name = user.get("first_name", "User")
                text = msg["text"]
                
                # ĞšĞ¾Ğ¼Ğ°Ğ½Ğ´Ñ‹
                if text == "/start":
                    await self.cmd_start(chat_id, user_name)
                elif text == "/help":
                    await self.cmd_help(chat_id)
                elif text == "/income":
                    await self.cmd_income(chat_id)
                elif text == "/niches":
                    await self.cmd_niches(chat_id)
                elif text == "/quick":
                    await self.cmd_quick(chat_id)
                elif text == "/stats":
                    await self.cmd_stats(chat_id)
                elif text == "/agents":
                    await self.cmd_agents(chat_id)
                elif text.startswith("/"):
                    await self.send(chat_id, "â“ ĞĞµĞ¸Ğ·Ğ²ĞµÑÑ‚Ğ½Ğ°Ñ ĞºĞ¾Ğ¼Ğ°Ğ½Ğ´Ğ°. /help")
                else:
                    await self.handle_message(chat_id, user_id, text)
            
            # Callback
            elif "callback_query" in update:
                cb = update["callback_query"]
                await self.handle_callback(
                    cb["id"],
                    cb["message"]["chat"]["id"],
                    cb["from"]["id"],
                    cb["data"]
                )
                
        except Exception as e:
            stats.errors += 1
            log(f"Update error: {e}", "ERROR")
    
    async def run(self):
        """Ğ—Ğ°Ğ¿ÑƒÑĞº Ğ±Ğ¾Ñ‚Ğ°"""
        
        log("=" * 50)
        log("ğŸ§  DEEPTHINK AUTOHUSTLE v3.0")
        log("=" * 50)
        log(f"ğŸ¤– ĞĞ³ĞµĞ½Ñ‚Ğ¾Ğ²: {len(swarm.agents)}")
        log(f"ğŸ”§ ĞœĞ¾Ğ´ĞµĞ»ÑŒ: {config.DEFAULT_MODEL}")
        log("=" * 50)
        
        offset = 0
        
        async with httpx.AsyncClient(timeout=config.API_TIMEOUT) as client:
            log("âœ… Ğ‘ĞĞ¢ Ğ—ĞĞŸĞ£Ğ©Ğ•Ğ!")
            
            while True:
                try:
                    resp = await client.get(
                        f"{self.api}/getUpdates",
                        params={"offset": offset, "timeout": config.POLLING_TIMEOUT}
                    )
                    
                    data = resp.json()
                    
                    if data.get("ok") and data.get("result"):
                        for update in data["result"]:
                            offset = update["update_id"] + 1
                            asyncio.create_task(self.handle_update(update))
                    
                except httpx.TimeoutException:
                    continue
                except Exception as e:
                    log(f"Polling error: {e}", "ERROR")
                    stats.errors += 1
                    await asyncio.sleep(5)

# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
# Ğ“Ğ›ĞĞ’ĞĞĞ¯ Ğ¤Ğ£ĞĞšĞ¦Ğ˜Ğ¯
# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•

async def main():
    """Ğ“Ğ»Ğ°Ğ²Ğ½Ğ°Ñ Ñ„ÑƒĞ½ĞºÑ†Ğ¸Ñ"""
    
    print("\n" + "=" * 60)
    print("ğŸ§  DEEPTHINK AUTOHUSTLE v3.0")
    print("ğŸ’° ULTIMATE MONEY EDITION")
    print("ğŸš€ Render.com Ready")
    print("=" * 60 + "\n")
    
    bot = Bot()
    await bot.run()

def run():
    """Ğ¢Ğ¾Ñ‡ĞºĞ° Ğ²Ñ…Ğ¾Ğ´Ğ°"""
    
    # Ğ—Ğ°Ğ¿ÑƒÑĞºĞ°ĞµĞ¼ HTTP ÑĞµÑ€Ğ²ĞµÑ€ Ğ´Ğ»Ñ health check Ğ² Ğ¾Ñ‚Ğ´ĞµĞ»ÑŒĞ½Ğ¾Ğ¼ Ğ¿Ğ¾Ñ‚Ğ¾ĞºĞµ
    health_thread = threading.Thread(target=start_health_server, daemon=True)
    health_thread.start()
    
    # Ğ—Ğ°Ğ¿ÑƒÑĞºĞ°ĞµĞ¼ Ğ±Ğ¾Ñ‚Ğ°
    try:
        asyncio.run(main())
    except KeyboardInterrupt:
        print("\nğŸ‘‹ Ğ‘Ğ¾Ñ‚ Ğ¾ÑÑ‚Ğ°Ğ½Ğ¾Ğ²Ğ»ĞµĞ½")
    except Exception as e:
        print(f"âŒ ĞÑˆĞ¸Ğ±ĞºĞ°: {e}")
        import traceback
        traceback.print_exc()

if __name__ == "__main__":
    run()
