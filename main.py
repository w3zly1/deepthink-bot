"""
â•”â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•—
â•‘         DEEPTHINK AUTOHUSTLE v3.0 - ULTIMATE MONEY EDITION               â•‘
â•‘                                                                          â•‘
â•‘  ğŸ§  20 ÑĞ¿ĞµÑ†Ğ¸Ğ°Ğ»Ğ¸Ğ·Ğ¸Ñ€Ğ¾Ğ²Ğ°Ğ½Ğ½Ñ‹Ñ… AI-Ğ°Ğ³ĞµĞ½Ñ‚Ğ¾Ğ²                                     â•‘
â•‘  ğŸ’° Ğ¡Ğ¸ÑÑ‚ĞµĞ¼Ğ° Ğ³ĞµĞ½ĞµÑ€Ğ°Ñ†Ğ¸Ğ¸ Ğ¸Ğ´ĞµĞ¹ Ğ´Ğ»Ñ Ğ·Ğ°Ñ€Ğ°Ğ±Ğ¾Ñ‚ĞºĞ°                                 â•‘
â•‘  ğŸ“Š ĞšĞ°Ğ»ÑŒĞºÑƒĞ»ÑÑ‚Ğ¾Ñ€ Ğ¿Ğ¾Ñ‚ĞµĞ½Ñ†Ğ¸Ğ°Ğ»ÑŒĞ½Ğ¾Ğ³Ğ¾ Ğ´Ğ¾Ñ…Ğ¾Ğ´Ğ°                                    â•‘
â•‘  ğŸ¯ Ğ“Ğ¾Ñ‚Ğ¾Ğ²Ñ‹Ğµ Ğ±Ğ¸Ğ·Ğ½ĞµÑ-ÑˆĞ°Ğ±Ğ»Ğ¾Ğ½Ñ‹                                               â•‘
â•‘  âš¡ ĞĞ²Ñ‚Ğ¾Ğ¼Ğ°Ñ‚Ğ¸Ñ‡ĞµÑĞºĞ°Ñ Ğ³ĞµĞ½ĞµÑ€Ğ°Ñ†Ğ¸Ñ ĞºĞ¾Ğ½Ñ‚ĞµĞ½Ñ‚Ğ°                                    â•‘
â•‘  ğŸ”§ ĞĞ¿Ñ‚Ğ¸Ğ¼Ğ¸Ğ·Ğ°Ñ†Ğ¸Ñ Ğ¿Ğ¾Ğ´ Ğ»Ğ¸Ğ¼Ğ¸Ñ‚Ñ‹ API                                           â•‘
â•‘                                                                          â•‘
â•‘  Python 3.8+ | Render.com Ready | OpenRouter Optimized                   â•‘
â•šâ•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
"""

import asyncio
import json
import os
import re
import random
from datetime import datetime, timedelta
from typing import Dict, List, Optional, Any, Tuple, Set
from dataclasses import dataclass, field
from enum import Enum, auto
from collections import defaultdict
import logging

# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
# ĞšĞĞĞ¤Ğ˜Ğ“Ğ£Ğ ĞĞ¦Ğ˜Ğ¯ - ĞĞŸĞ¢Ğ˜ĞœĞ˜Ğ—Ğ˜Ğ ĞĞ’ĞĞĞĞĞ¯ Ğ”Ğ›Ğ¯ Ğ­ĞšĞĞĞĞœĞ˜Ğ˜ Ğ¢ĞĞšĞ•ĞĞĞ’
# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•

@dataclass
class Config:
    """ĞšĞ¾Ğ½Ñ„Ğ¸Ğ³ÑƒÑ€Ğ°Ñ†Ğ¸Ñ Ğ¿Ñ€Ğ¸Ğ»Ğ¾Ğ¶ĞµĞ½Ğ¸Ñ"""
    
    # API ĞºĞ»ÑÑ‡Ğ¸
    TELEGRAM_TOKEN: str = "8510653021:AAFCsjXyWLweEFBPrZD_wxlUmRe8uRQjQDY"
    OPENROUTER_KEY: str = "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"
    
    # ĞœĞ¾Ğ´ĞµĞ»Ğ¸ - Ğ‘Ğ•Ğ¡ĞŸĞ›ĞĞ¢ĞĞ«Ğ• Ğ˜ Ğ­ĞšĞĞĞĞœĞĞ«Ğ•
    FREE_MODELS: List[str] = field(default_factory=lambda: [
        "google/gemini-2.0-flash-exp:free",      # Ğ‘ĞµÑĞ¿Ğ»Ğ°Ñ‚Ğ½Ğ°Ñ, Ğ±Ñ‹ÑÑ‚Ñ€Ğ°Ñ
        "meta-llama/llama-3.1-8b-instruct:free", # Ğ‘ĞµÑĞ¿Ğ»Ğ°Ñ‚Ğ½Ğ°Ñ Llama
        "google/gemma-2-9b-it:free",             # Ğ‘ĞµÑĞ¿Ğ»Ğ°Ñ‚Ğ½Ğ°Ñ Gemma
        "mistralai/mistral-7b-instruct:free",   # Ğ‘ĞµÑĞ¿Ğ»Ğ°Ñ‚Ğ½Ğ°Ñ Mistral
    ])
    
    PREMIUM_MODELS: List[str] = field(default_factory=lambda: [
        "anthropic/claude-3.5-sonnet",
        "openai/gpt-4o-mini",
        "google/gemini-pro",
    ])
    
    DEFAULT_MODEL: str = "google/gemini-2.0-flash-exp:free"  # Ğ‘ĞµÑĞ¿Ğ»Ğ°Ñ‚Ğ½Ğ°Ñ Ğ¿Ğ¾ ÑƒĞ¼Ğ¾Ğ»Ñ‡Ğ°Ğ½Ğ¸Ñ
    
    # ĞĞŸĞ¢Ğ˜ĞœĞ˜Ğ—Ğ˜Ğ ĞĞ’ĞĞĞĞ«Ğ• Ğ›Ğ˜ĞœĞ˜Ğ¢Ğ« Ğ¢ĞĞšĞ•ĞĞĞ’
    MAX_TOKENS_FREE: int = 1000      # Ğ”Ğ»Ñ Ğ±ĞµÑĞ¿Ğ»Ğ°Ñ‚Ğ½Ñ‹Ñ… Ğ·Ğ°Ğ¿Ñ€Ğ¾ÑĞ¾Ğ²
    MAX_TOKENS_STANDARD: int = 800   # Ğ¡Ñ‚Ğ°Ğ½Ğ´Ğ°Ñ€Ñ‚Ğ½Ñ‹Ğ¹ Ğ¾Ñ‚Ğ²ĞµÑ‚
    MAX_TOKENS_SHORT: int = 400      # ĞšĞ¾Ñ€Ğ¾Ñ‚ĞºĞ¸Ğ¹ Ğ¾Ñ‚Ğ²ĞµÑ‚
    MAX_TOKENS_ACTION: int = 1200    # Ğ”Ğ»Ñ Ğ´ĞµĞ¹ÑÑ‚Ğ²Ğ¸Ğ¹
    
    TEMPERATURE: float = 0.7
    
    # Ğ›Ğ¸Ğ¼Ğ¸Ñ‚Ñ‹ Ğ°Ğ³ĞµĞ½Ñ‚Ğ¾Ğ²
    MAX_AGENTS_PER_QUERY: int = 3    # ĞœĞµĞ½ÑŒÑˆĞµ Ğ°Ğ³ĞµĞ½Ñ‚Ğ¾Ğ² = Ğ¼ĞµĞ½ÑŒÑˆĞµ Ñ‚Ğ¾ĞºĞµĞ½Ğ¾Ğ²
    MAX_CONTEXT_LENGTH: int = 2000
    MAX_HISTORY_ITEMS: int = 10
    MAX_ACTIONS_PER_RESPONSE: int = 5
    
    # Ğ¢Ğ°Ğ¹Ğ¼Ğ°ÑƒÑ‚Ñ‹
    API_TIMEOUT: int = 60
    POLLING_TIMEOUT: int = 30
    
    # Ğ ĞµĞ¶Ğ¸Ğ¼ ÑĞºĞ¾Ğ½Ğ¾Ğ¼Ğ¸Ğ¸
    ECONOMY_MODE: bool = True  # Ğ˜ÑĞ¿Ğ¾Ğ»ÑŒĞ·Ğ¾Ğ²Ğ°Ñ‚ÑŒ Ğ±ĞµÑĞ¿Ğ»Ğ°Ñ‚Ğ½Ñ‹Ğµ Ğ¼Ğ¾Ğ´ĞµĞ»Ğ¸
    
    @property
    def TELEGRAM_API(self) -> str:
        return f"https://api.telegram.org/bot{self.TELEGRAM_TOKEN}"

config = Config()

# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
# Ğ›ĞĞ“Ğ˜Ğ ĞĞ’ĞĞĞ˜Ğ•
# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•

logging.basicConfig(
    level=logging.INFO,
    format='%(asctime)s | %(levelname)s | %(message)s',
    datefmt='%H:%M:%S'
)
logger = logging.getLogger('DeepThink')

# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
# ĞŸĞ•Ğ Ğ•Ğ§Ğ˜Ğ¡Ğ›Ğ•ĞĞ˜Ğ¯
# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•

class AgentType(Enum):
    """Ğ¢Ğ¸Ğ¿Ñ‹ Ğ°Ğ³ĞµĞ½Ñ‚Ğ¾Ğ² - 20 ÑĞ¿ĞµÑ†Ğ¸Ğ°Ğ»Ğ¸Ğ·Ğ°Ñ†Ğ¸Ğ¹"""
    # ĞÑĞ½Ğ¾Ğ²Ğ½Ñ‹Ğµ
    RESEARCHER = "researcher"
    MONEY_EXPERT = "money_expert"
    STRATEGIST = "strategist"
    CONTENT_CREATOR = "content_creator"
    CODER = "coder"
    MARKETER = "marketer"
    
    # Ğ¡Ğ¿ĞµÑ†Ğ¸Ğ°Ğ»Ğ¸Ğ·Ğ¸Ñ€Ğ¾Ğ²Ğ°Ğ½Ğ½Ñ‹Ğµ Ğ´Ğ»Ñ Ğ·Ğ°Ñ€Ğ°Ğ±Ğ¾Ñ‚ĞºĞ°
    DROPSHIPPER = "dropshipper"
    AFFILIATE = "affiliate"
    FREELANCER = "freelancer"
    CRYPTO_EXPERT = "crypto_expert"
    ECOMMERCE = "ecommerce"
    SAAS_EXPERT = "saas_expert"
    
    # ĞĞ½Ğ°Ğ»Ğ¸Ñ‚Ğ¸ĞºĞ° Ğ¸ ĞºÑ€ĞµĞ°Ñ‚Ğ¸Ğ²
    DATA_ANALYST = "data_analyst"
    CREATIVE_DIRECTOR = "creative_director"
    COPYWRITER = "copywriter"
    SEO_EXPERT = "seo_expert"
    
    # Ğ¡Ğ¿ĞµÑ†Ğ¸Ğ°Ğ»Ğ¸ÑÑ‚Ñ‹
    INVESTOR = "investor"
    AUTOMATION = "automation"
    COACH = "coach"
    LEGAL = "legal"

class IncomeLevel(Enum):
    """Ğ£Ñ€Ğ¾Ğ²Ğ½Ğ¸ Ğ´Ğ¾Ñ…Ğ¾Ğ´Ğ°"""
    STARTER = "starter"       # $100-500/Ğ¼ĞµÑ
    GROWING = "growing"       # $500-2000/Ğ¼ĞµÑ
    SERIOUS = "serious"       # $2000-10000/Ğ¼ĞµÑ
    SCALING = "scaling"       # $10000+/Ğ¼ĞµÑ

class BusinessModel(Enum):
    """Ğ‘Ğ¸Ğ·Ğ½ĞµÑ-Ğ¼Ğ¾Ğ´ĞµĞ»Ğ¸"""
    FREELANCE = "freelance"
    AFFILIATE = "affiliate"
    DROPSHIPPING = "dropshipping"
    DIGITAL_PRODUCTS = "digital_products"
    SAAS = "saas"
    CONTENT = "content"
    CONSULTING = "consulting"
    ECOMMERCE = "ecommerce"
    AUTOMATION = "automation"
    AI_SERVICES = "ai_services"

# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
# Ğ‘ĞĞ—Ğ Ğ—ĞĞĞĞ˜Ğ™ Ğ Ğ¡ĞŸĞĞ¡ĞĞ‘ĞĞ¥ Ğ—ĞĞ ĞĞ‘ĞĞ¢ĞšĞ
# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•

class MoneyKnowledgeBase:
    """Ğ‘Ğ°Ğ·Ğ° Ğ·Ğ½Ğ°Ğ½Ğ¸Ğ¹ Ğ¾ ÑĞ¿Ğ¾ÑĞ¾Ğ±Ğ°Ñ… Ğ·Ğ°Ñ€Ğ°Ğ±Ğ¾Ñ‚ĞºĞ°"""
    
    INCOME_STREAMS = {
        BusinessModel.FREELANCE: {
            "name": "ğŸ¨ Ğ¤Ñ€Ğ¸Ğ»Ğ°Ğ½Ñ",
            "description": "ĞŸÑ€Ğ¾Ğ´Ğ°Ğ¶Ğ° ÑĞ²Ğ¾Ğ¸Ñ… Ğ½Ğ°Ğ²Ñ‹ĞºĞ¾Ğ²",
            "income_range": "$500 - $10,000/Ğ¼ĞµÑ",
            "time_to_profit": "1-4 Ğ½ĞµĞ´ĞµĞ»Ğ¸",
            "difficulty": "Ğ¡Ñ€ĞµĞ´Ğ½ÑÑ",
            "ai_automation": "40-60%",
            "skills_needed": ["ĞšĞ¾Ğ¿Ğ¸Ñ€Ğ°Ğ¹Ñ‚Ğ¸Ğ½Ğ³", "Ğ”Ğ¸Ğ·Ğ°Ğ¹Ğ½", "Ğ Ğ°Ğ·Ñ€Ğ°Ğ±Ğ¾Ñ‚ĞºĞ°", "ĞœĞ°Ñ€ĞºĞµÑ‚Ğ¸Ğ½Ğ³"],
            "platforms": ["Upwork", "Fiverr", "Kwork", "FL.ru"],
            "steps": [
                "Ğ’Ñ‹Ğ±Ñ€Ğ°Ñ‚ÑŒ Ğ½Ğ¸ÑˆÑƒ Ğ¸ Ğ½Ğ°Ğ²Ñ‹Ğº",
                "Ğ¡Ğ¾Ğ·Ğ´Ğ°Ñ‚ÑŒ Ğ¿Ğ¾Ñ€Ñ‚Ñ„Ğ¾Ğ»Ğ¸Ğ¾ (AI Ğ¿Ğ¾Ğ¼Ğ¾Ğ¶ĞµÑ‚)",
                "Ğ—Ğ°Ñ€ĞµĞ³Ğ¸ÑÑ‚Ñ€Ğ¸Ñ€Ğ¾Ğ²Ğ°Ñ‚ÑŒÑÑ Ğ½Ğ° Ğ¿Ğ»Ğ°Ñ‚Ñ„Ğ¾Ñ€Ğ¼Ğ°Ñ…",
                "Ğ¡Ğ¾Ğ·Ğ´Ğ°Ñ‚ÑŒ ÑƒĞ±ĞµĞ´Ğ¸Ñ‚ĞµĞ»ÑŒĞ½Ñ‹Ğ¹ Ğ¿Ñ€Ğ¾Ñ„Ğ¸Ğ»ÑŒ",
                "ĞÑ‚Ğ¿Ñ€Ğ°Ğ²Ğ»ÑÑ‚ÑŒ 10-20 Ğ¾Ñ‚ĞºĞ»Ğ¸ĞºĞ¾Ğ² Ğ² Ğ´ĞµĞ½ÑŒ"
            ]
        },
        BusinessModel.AFFILIATE: {
            "name": "ğŸ”— ĞŸĞ°Ñ€Ñ‚Ğ½Ñ‘Ñ€ÑĞºĞ¸Ğ¹ Ğ¼Ğ°Ñ€ĞºĞµÑ‚Ğ¸Ğ½Ğ³",
            "description": "ĞšĞ¾Ğ¼Ğ¸ÑÑĞ¸Ñ Ğ·Ğ° Ğ¿Ñ€Ğ¾Ğ´Ğ°Ğ¶Ğ¸ Ğ¿Ğ¾ Ğ²Ğ°ÑˆĞ¸Ğ¼ ÑÑÑ‹Ğ»ĞºĞ°Ğ¼",
            "income_range": "$200 - $50,000/Ğ¼ĞµÑ",
            "time_to_profit": "1-3 Ğ¼ĞµÑÑÑ†Ğ°",
            "difficulty": "Ğ¡Ñ€ĞµĞ´Ğ½ÑÑ",
            "ai_automation": "70-80%",
            "skills_needed": ["ĞšĞ¾Ğ½Ñ‚ĞµĞ½Ñ‚", "SEO", "Ğ ĞµĞºĞ»Ğ°Ğ¼Ğ°"],
            "platforms": ["Amazon Associates", "Admitad", "CJ Affiliate"],
            "steps": [
                "Ğ’Ñ‹Ğ±Ñ€Ğ°Ñ‚ÑŒ Ğ½Ğ¸ÑˆÑƒ Ñ Ğ²Ñ‹ÑĞ¾ĞºĞ¸Ğ¼Ğ¸ ĞºĞ¾Ğ¼Ğ¸ÑÑĞ¸ÑĞ¼Ğ¸",
                "Ğ¡Ğ¾Ğ·Ğ´Ğ°Ñ‚ÑŒ ĞºĞ¾Ğ½Ñ‚ĞµĞ½Ñ‚-Ğ¿Ğ»Ğ¾Ñ‰Ğ°Ğ´ĞºÑƒ",
                "Ğ“ĞµĞ½ĞµÑ€Ğ¸Ñ€Ğ¾Ğ²Ğ°Ñ‚ÑŒ ĞºĞ¾Ğ½Ñ‚ĞµĞ½Ñ‚ Ñ AI",
                "ĞŸÑ€Ğ¸Ğ²Ğ»ĞµĞºĞ°Ñ‚ÑŒ Ñ‚Ñ€Ğ°Ñ„Ğ¸Ğº",
                "ĞĞ¿Ñ‚Ğ¸Ğ¼Ğ¸Ğ·Ğ¸Ñ€Ğ¾Ğ²Ğ°Ñ‚ÑŒ ĞºĞ¾Ğ½Ğ²ĞµÑ€ÑĞ¸Ñ"
            ]
        },
        BusinessModel.DROPSHIPPING: {
            "name": "ğŸ“¦ Ğ”Ñ€Ğ¾Ğ¿ÑˆĞ¸Ğ¿Ğ¿Ğ¸Ğ½Ğ³",
            "description": "ĞŸÑ€Ğ¾Ğ´Ğ°Ğ¶Ğ° Ğ±ĞµĞ· ÑĞºĞ»Ğ°Ğ´Ğ°",
            "income_range": "$500 - $30,000/Ğ¼ĞµÑ",
            "time_to_profit": "2-6 Ğ½ĞµĞ´ĞµĞ»ÑŒ",
            "difficulty": "Ğ¡Ñ€ĞµĞ´Ğ½ÑÑ",
            "ai_automation": "50-70%",
            "skills_needed": ["ĞœĞ°Ñ€ĞºĞµÑ‚Ğ¸Ğ½Ğ³", "ĞĞ½Ğ°Ğ»Ğ¸Ñ‚Ğ¸ĞºĞ°", "Ğ ĞµĞºĞ»Ğ°Ğ¼Ğ°"],
            "platforms": ["Shopify", "WooCommerce", "Wildberries", "Ozon"],
            "steps": [
                "ĞĞ°Ğ¹Ñ‚Ğ¸ winning product",
                "Ğ¡Ğ¾Ğ·Ğ´Ğ°Ñ‚ÑŒ Ğ¼Ğ°Ğ³Ğ°Ğ·Ğ¸Ğ½",
                "ĞĞ°ÑÑ‚Ñ€Ğ¾Ğ¸Ñ‚ÑŒ Ñ€ĞµĞºĞ»Ğ°Ğ¼Ñƒ",
                "ĞĞ²Ñ‚Ğ¾Ğ¼Ğ°Ñ‚Ğ¸Ğ·Ğ¸Ñ€Ğ¾Ğ²Ğ°Ñ‚ÑŒ Ğ¾Ğ±Ñ€Ğ°Ğ±Ğ¾Ñ‚ĞºÑƒ Ğ·Ğ°ĞºĞ°Ğ·Ğ¾Ğ²",
                "ĞœĞ°ÑÑˆÑ‚Ğ°Ğ±Ğ¸Ñ€Ğ¾Ğ²Ğ°Ñ‚ÑŒ"
            ]
        },
        BusinessModel.DIGITAL_PRODUCTS: {
            "name": "ğŸ“± Ğ¦Ğ¸Ñ„Ñ€Ğ¾Ğ²Ñ‹Ğµ Ğ¿Ñ€Ğ¾Ğ´ÑƒĞºÑ‚Ñ‹",
            "description": "ĞšÑƒÑ€ÑÑ‹, ÑˆĞ°Ğ±Ğ»Ğ¾Ğ½Ñ‹, Ğ³Ğ°Ğ¹Ğ´Ñ‹",
            "income_range": "$100 - $100,000/Ğ¼ĞµÑ",
            "time_to_profit": "2-8 Ğ½ĞµĞ´ĞµĞ»ÑŒ",
            "difficulty": "ĞĞ¸Ğ·ĞºĞ°Ñ-Ğ¡Ñ€ĞµĞ´Ğ½ÑÑ",
            "ai_automation": "80-90%",
            "skills_needed": ["Ğ­ĞºÑĞ¿ĞµÑ€Ñ‚Ğ¸Ğ·Ğ° Ğ² Ğ½Ğ¸ÑˆĞµ", "ĞœĞ°Ñ€ĞºĞµÑ‚Ğ¸Ğ½Ğ³"],
            "platforms": ["Gumroad", "Notion", "Teachable", "GetCourse"],
            "steps": [
                "ĞĞ¿Ñ€ĞµĞ´ĞµĞ»Ğ¸Ñ‚ÑŒ Ğ±Ğ¾Ğ»ÑŒ Ğ°ÑƒĞ´Ğ¸Ñ‚Ğ¾Ñ€Ğ¸Ğ¸",
                "Ğ¡Ğ¾Ğ·Ğ´Ğ°Ñ‚ÑŒ Ğ¿Ñ€Ğ¾Ğ´ÑƒĞºÑ‚ Ñ Ğ¿Ğ¾Ğ¼Ğ¾Ñ‰ÑŒÑ AI",
                "ĞĞ°ÑÑ‚Ñ€Ğ¾Ğ¸Ñ‚ÑŒ Ğ²Ğ¾Ñ€Ğ¾Ğ½ĞºÑƒ Ğ¿Ñ€Ğ¾Ğ´Ğ°Ğ¶",
                "Ğ—Ğ°Ğ¿ÑƒÑÑ‚Ğ¸Ñ‚ÑŒ Ñ‚Ñ€Ğ°Ñ„Ğ¸Ğº",
                "Ğ¡Ğ¾Ğ±Ğ¸Ñ€Ğ°Ñ‚ÑŒ Ğ¾Ñ‚Ğ·Ñ‹Ğ²Ñ‹ Ğ¸ ÑƒĞ»ÑƒÑ‡ÑˆĞ°Ñ‚ÑŒ"
            ]
        },
        BusinessModel.SAAS: {
            "name": "ğŸ’» SaaS / ĞœĞ¸ĞºÑ€Ğ¾-SaaS",
            "description": "ĞŸÑ€Ğ¾Ğ³Ñ€Ğ°Ğ¼Ğ¼Ğ½Ğ¾Ğµ Ğ¾Ğ±ĞµÑĞ¿ĞµÑ‡ĞµĞ½Ğ¸Ğµ ĞºĞ°Ğº ÑƒÑĞ»ÑƒĞ³Ğ°",
            "income_range": "$500 - $500,000/Ğ¼ĞµÑ",
            "time_to_profit": "1-6 Ğ¼ĞµÑÑÑ†ĞµĞ²",
            "difficulty": "Ğ’Ñ‹ÑĞ¾ĞºĞ°Ñ",
            "ai_automation": "30-50%",
            "skills_needed": ["ĞŸÑ€Ğ¾Ğ³Ñ€Ğ°Ğ¼Ğ¼Ğ¸Ñ€Ğ¾Ğ²Ğ°Ğ½Ğ¸Ğµ", "ĞœĞ°Ñ€ĞºĞµÑ‚Ğ¸Ğ½Ğ³", "UX"],
            "platforms": ["Stripe", "Paddle", "AWS", "Vercel"],
            "steps": [
                "ĞĞ°Ğ¹Ñ‚Ğ¸ Ğ¿Ñ€Ğ¾Ğ±Ğ»ĞµĞ¼Ñƒ Ğ´Ğ»Ñ Ñ€ĞµÑˆĞµĞ½Ğ¸Ñ",
                "MVP Ğ·Ğ° 2-4 Ğ½ĞµĞ´ĞµĞ»Ğ¸",
                "ĞŸĞ¾Ğ»ÑƒÑ‡Ğ¸Ñ‚ÑŒ Ğ¿ĞµÑ€Ğ²Ñ‹Ñ… 10 Ğ¿Ğ¾Ğ»ÑŒĞ·Ğ¾Ğ²Ğ°Ñ‚ĞµĞ»ĞµĞ¹",
                "Ğ˜Ñ‚ĞµÑ€Ğ¸Ñ€Ğ¾Ğ²Ğ°Ñ‚ÑŒ Ğ½Ğ° Ğ¾ÑĞ½Ğ¾Ğ²Ğµ Ñ„Ğ¸Ğ´Ğ±ÑĞºĞ°",
                "ĞœĞ°ÑÑˆÑ‚Ğ°Ğ±Ğ¸Ñ€Ğ¾Ğ²Ğ°Ñ‚ÑŒ Ğ¼Ğ°Ñ€ĞºĞµÑ‚Ğ¸Ğ½Ğ³"
            ]
        },
        BusinessModel.CONTENT: {
            "name": "ğŸ“ ĞšĞ¾Ğ½Ñ‚ĞµĞ½Ñ‚-Ğ±Ğ¸Ğ·Ğ½ĞµÑ",
            "description": "YouTube, Ğ±Ğ»Ğ¾Ğ³, Ğ¿Ğ¾Ğ´ĞºĞ°ÑÑ‚",
            "income_range": "$100 - $100,000/Ğ¼ĞµÑ",
            "time_to_profit": "3-12 Ğ¼ĞµÑÑÑ†ĞµĞ²",
            "difficulty": "Ğ¡Ñ€ĞµĞ´Ğ½ÑÑ",
            "ai_automation": "60-80%",
            "skills_needed": ["ĞšĞ¾Ğ½Ñ‚ĞµĞ½Ñ‚", "ĞŸĞ¾ÑÑ‚Ğ¾ÑĞ½ÑÑ‚Ğ²Ğ¾", "ĞœĞ°Ñ€ĞºĞµÑ‚Ğ¸Ğ½Ğ³"],
            "platforms": ["YouTube", "Telegram", "TikTok", "Medium"],
            "steps": [
                "Ğ’Ñ‹Ğ±Ñ€Ğ°Ñ‚ÑŒ Ğ½Ğ¸ÑˆÑƒ Ğ¸ Ñ„Ğ¾Ñ€Ğ¼Ğ°Ñ‚",
                "Ğ¡Ğ¾Ğ·Ğ´Ğ°Ñ‚ÑŒ ĞºĞ¾Ğ½Ñ‚ĞµĞ½Ñ‚-Ğ¿Ğ»Ğ°Ğ½ Ñ AI",
                "ĞŸÑƒĞ±Ğ»Ğ¸ĞºĞ¾Ğ²Ğ°Ñ‚ÑŒ Ñ€ĞµĞ³ÑƒĞ»ÑÑ€Ğ½Ğ¾",
                "ĞœĞ¾Ğ½ĞµÑ‚Ğ¸Ğ·Ğ¸Ñ€Ğ¾Ğ²Ğ°Ñ‚ÑŒ Ğ°ÑƒĞ´Ğ¸Ñ‚Ğ¾Ñ€Ğ¸Ñ",
                "Ğ”Ğ¸Ğ²ĞµÑ€ÑĞ¸Ñ„Ğ¸Ñ†Ğ¸Ñ€Ğ¾Ğ²Ğ°Ñ‚ÑŒ Ğ´Ğ¾Ñ…Ğ¾Ğ´Ñ‹"
            ]
        },
        BusinessModel.AI_SERVICES: {
            "name": "ğŸ¤– AI-ÑĞµÑ€Ğ²Ğ¸ÑÑ‹",
            "description": "Ğ£ÑĞ»ÑƒĞ³Ğ¸ Ğ½Ğ° Ğ¾ÑĞ½Ğ¾Ğ²Ğµ AI",
            "income_range": "$1,000 - $50,000/Ğ¼ĞµÑ",
            "time_to_profit": "1-4 Ğ½ĞµĞ´ĞµĞ»Ğ¸",
            "difficulty": "ĞĞ¸Ğ·ĞºĞ°Ñ-Ğ¡Ñ€ĞµĞ´Ğ½ÑÑ",
            "ai_automation": "90-95%",
            "skills_needed": ["ĞŸÑ€Ğ¾Ğ¼Ğ¿Ñ‚-Ğ¸Ğ½Ğ¶Ğ¸Ğ½Ğ¸Ñ€Ğ¸Ğ½Ğ³", "ĞœĞ°Ñ€ĞºĞµÑ‚Ğ¸Ğ½Ğ³"],
            "platforms": ["Ğ¡Ğ¾Ğ±ÑÑ‚Ğ²ĞµĞ½Ğ½Ñ‹Ğ¹ Ğ±Ğ¾Ñ‚", "Fiverr", "Telegram"],
            "steps": [
                "Ğ’Ñ‹Ğ±Ñ€Ğ°Ñ‚ÑŒ AI-ÑƒÑĞ»ÑƒĞ³Ñƒ (Ñ‚ĞµĞºÑÑ‚Ñ‹, Ğ¸Ğ·Ğ¾Ğ±Ñ€Ğ°Ğ¶ĞµĞ½Ğ¸Ñ, ĞºĞ¾Ğ´)",
                "Ğ¡Ğ¾Ğ·Ğ´Ğ°Ñ‚ÑŒ Ğ²Ğ¾Ñ€Ğ¾Ğ½ĞºÑƒ/Ğ±Ğ¾Ñ‚Ğ°",
                "ĞĞ°ÑÑ‚Ñ€Ğ¾Ğ¸Ñ‚ÑŒ Ğ°Ğ²Ñ‚Ğ¾Ğ¼Ğ°Ñ‚Ğ¸Ğ·Ğ°Ñ†Ğ¸Ñ",
                "ĞŸÑ€Ğ¸Ğ²Ğ»ĞµÑ‡ÑŒ ĞºĞ»Ğ¸ĞµĞ½Ñ‚Ğ¾Ğ²",
                "ĞœĞ°ÑÑˆÑ‚Ğ°Ğ±Ğ¸Ñ€Ğ¾Ğ²Ğ°Ñ‚ÑŒ"
            ]
        },
        BusinessModel.AUTOMATION: {
            "name": "âš™ï¸ ĞĞ²Ñ‚Ğ¾Ğ¼Ğ°Ñ‚Ğ¸Ğ·Ğ°Ñ†Ğ¸Ñ Ğ´Ğ»Ñ Ğ±Ğ¸Ğ·Ğ½ĞµÑĞ°",
            "description": "Ğ‘Ğ¾Ñ‚Ñ‹, Ğ¸Ğ½Ñ‚ĞµĞ³Ñ€Ğ°Ñ†Ğ¸Ğ¸, Ğ°Ğ²Ñ‚Ğ¾Ğ¼Ğ°Ñ‚Ğ¸Ğ·Ğ°Ñ†Ğ¸Ğ¸",
            "income_range": "$2,000 - $30,000/Ğ¼ĞµÑ",
            "time_to_profit": "2-4 Ğ½ĞµĞ´ĞµĞ»Ğ¸",
            "difficulty": "Ğ¡Ñ€ĞµĞ´Ğ½ÑÑ",
            "ai_automation": "60-80%",
            "skills_needed": ["No-code/Low-code", "Ğ›Ğ¾Ğ³Ğ¸ĞºĞ°", "ĞšĞ¾Ğ¼Ğ¼ÑƒĞ½Ğ¸ĞºĞ°Ñ†Ğ¸Ñ"],
            "platforms": ["Make", "Zapier", "n8n", "Telegram Bots"],
            "steps": [
                "Ğ˜Ğ·ÑƒÑ‡Ğ¸Ñ‚ÑŒ Ğ¸Ğ½ÑÑ‚Ñ€ÑƒĞ¼ĞµĞ½Ñ‚Ñ‹ Ğ°Ğ²Ñ‚Ğ¾Ğ¼Ğ°Ñ‚Ğ¸Ğ·Ğ°Ñ†Ğ¸Ğ¸",
                "ĞĞ°Ğ¹Ñ‚Ğ¸ Ğ±Ğ¸Ğ·Ğ½ĞµÑÑ‹ Ñ Ñ€ÑƒÑ‚Ğ¸Ğ½Ğ½Ñ‹Ğ¼Ğ¸ Ğ¿Ñ€Ğ¾Ñ†ĞµÑÑĞ°Ğ¼Ğ¸",
                "ĞŸÑ€ĞµĞ´Ğ»Ğ¾Ğ¶Ğ¸Ñ‚ÑŒ Ğ°Ğ²Ñ‚Ğ¾Ğ¼Ğ°Ñ‚Ğ¸Ğ·Ğ°Ñ†Ğ¸Ñ",
                "Ğ¡Ğ¾Ğ·Ğ´Ğ°Ñ‚ÑŒ Ñ€ĞµÑˆĞµĞ½Ğ¸Ğµ",
                "Ğ‘Ñ€Ğ°Ñ‚ÑŒ Ğ°Ğ±Ğ¾Ğ½ĞµĞ½Ñ‚ÑĞºÑƒÑ Ğ¿Ğ»Ğ°Ñ‚Ñƒ"
            ]
        }
    }
    
    QUICK_WINS = [
        {
            "name": "AI-ĞºĞ¾Ğ¿Ğ¸Ñ€Ğ°Ğ¹Ñ‚Ğ¸Ğ½Ğ³ Ğ½Ğ° Kwork",
            "income": "$300-1000/Ğ¼ĞµÑ",
            "time": "3-7 Ğ´Ğ½ĞµĞ¹ Ğ´Ğ¾ Ğ¿ĞµÑ€Ğ²Ğ¾Ğ³Ğ¾ Ğ·Ğ°ĞºĞ°Ğ·Ğ°",
            "steps": ["Ğ ĞµĞ³Ğ¸ÑÑ‚Ñ€Ğ°Ñ†Ğ¸Ñ", "Ğ¡Ğ¾Ğ·Ğ´Ğ°Ñ‚ÑŒ 5 ĞºĞ²Ğ¾Ñ€ĞºĞ¾Ğ²", "AI Ğ¿Ğ¸ÑˆĞµÑ‚ Ñ‚ĞµĞºÑÑ‚Ñ‹"]
        },
        {
            "name": "Telegram-Ğ±Ğ¾Ñ‚ Ğ´Ğ»Ñ Ğ±Ğ¸Ğ·Ğ½ĞµÑĞ°",
            "income": "$500-3000/Ğ¿Ñ€Ğ¾ĞµĞºÑ‚",
            "time": "1-2 Ğ½ĞµĞ´ĞµĞ»Ğ¸",
            "steps": ["Ğ˜Ğ·ÑƒÑ‡Ğ¸Ñ‚ÑŒ aiogram", "ĞĞ°Ğ¹Ñ‚Ğ¸ ĞºĞ»Ğ¸ĞµĞ½Ñ‚Ğ°", "Ğ¡Ğ¾Ğ·Ğ´Ğ°Ñ‚ÑŒ Ğ±Ğ¾Ñ‚Ğ°"]
        },
        {
            "name": "AI-Ğ´Ğ¸Ğ·Ğ°Ğ¹Ğ½ Ğ½Ğ° Fiverr",
            "income": "$500-2000/Ğ¼ĞµÑ",
            "time": "1-2 Ğ½ĞµĞ´ĞµĞ»Ğ¸",
            "steps": ["Midjourney/DALL-E", "Ğ¡Ğ¾Ğ·Ğ´Ğ°Ñ‚ÑŒ Ğ¿Ğ¾Ñ€Ñ‚Ñ„Ğ¾Ğ»Ğ¸Ğ¾", "ĞŸÑ€Ğ¾Ğ´Ğ°Ğ²Ğ°Ñ‚ÑŒ"]
        },
        {
            "name": "Notion-ÑˆĞ°Ğ±Ğ»Ğ¾Ğ½Ñ‹",
            "income": "$100-5000/Ğ¼ĞµÑ",
            "time": "1 Ğ½ĞµĞ´ĞµĞ»Ñ",
            "steps": ["Ğ¡Ğ¾Ğ·Ğ´Ğ°Ñ‚ÑŒ ÑˆĞ°Ğ±Ğ»Ğ¾Ğ½", "Gumroad", "ĞŸÑ€Ğ¾Ğ´Ğ²Ğ¸Ğ³Ğ°Ñ‚ÑŒ Ğ² Twitter/Reddit"]
        },
        {
            "name": "AI-ĞºĞ¾Ğ½ÑÑƒĞ»ÑŒÑ‚Ğ°Ñ†Ğ¸Ğ¸",
            "income": "$1000-5000/Ğ¼ĞµÑ",
            "time": "Ğ¡Ñ€Ğ°Ğ·Ñƒ",
            "steps": ["Ğ£Ğ¿Ğ°ĞºĞ¾Ğ²Ğ°Ñ‚ÑŒ ÑĞºÑĞ¿ĞµÑ€Ñ‚Ğ¸Ğ·Ñƒ", "Calendly", "LinkedIn/Telegram"]
        }
    ]
    
    NICHES_2024_2025 = [
        {"niche": "AI-Ğ¸Ğ½ÑÑ‚Ñ€ÑƒĞ¼ĞµĞ½Ñ‚Ñ‹ Ğ´Ğ»Ñ Ğ±Ğ¸Ğ·Ğ½ĞµÑĞ°", "trend": "ğŸ”¥ğŸ”¥ğŸ”¥", "competition": "Ğ¡Ñ€ĞµĞ´Ğ½ÑÑ"},
        {"niche": "ĞĞ²Ñ‚Ğ¾Ğ¼Ğ°Ñ‚Ğ¸Ğ·Ğ°Ñ†Ğ¸Ñ Ñ n8n/Make", "trend": "ğŸ”¥ğŸ”¥ğŸ”¥", "competition": "ĞĞ¸Ğ·ĞºĞ°Ñ"},
        {"niche": "ĞœĞ¸ĞºÑ€Ğ¾-SaaS", "trend": "ğŸ”¥ğŸ”¥ğŸ”¥", "competition": "Ğ¡Ñ€ĞµĞ´Ğ½ÑÑ"},
        {"niche": "AI-ĞºĞ¾Ğ½Ñ‚ĞµĞ½Ñ‚ Ğ´Ğ»Ñ ÑĞ¾Ñ†ÑĞµÑ‚ĞµĞ¹", "trend": "ğŸ”¥ğŸ”¥", "competition": "Ğ’Ñ‹ÑĞ¾ĞºĞ°Ñ"},
        {"niche": "Telegram-Ğ±Ğ¾Ñ‚Ñ‹", "trend": "ğŸ”¥ğŸ”¥", "competition": "Ğ¡Ñ€ĞµĞ´Ğ½ÑÑ"},
        {"niche": "No-code Ñ€Ğ°Ğ·Ñ€Ğ°Ğ±Ğ¾Ñ‚ĞºĞ°", "trend": "ğŸ”¥ğŸ”¥", "competition": "Ğ¡Ñ€ĞµĞ´Ğ½ÑÑ"},
        {"niche": "ĞĞ±Ñ€Ğ°Ğ·Ğ¾Ğ²Ğ°Ñ‚ĞµĞ»ÑŒĞ½Ñ‹Ğµ Ğ¿Ñ€Ğ¾Ğ´ÑƒĞºÑ‚Ñ‹", "trend": "ğŸ”¥ğŸ”¥", "competition": "Ğ’Ñ‹ÑĞ¾ĞºĞ°Ñ"},
        {"niche": "E-commerce Ğ°Ğ²Ñ‚Ğ¾Ğ¼Ğ°Ñ‚Ğ¸Ğ·Ğ°Ñ†Ğ¸Ñ", "trend": "ğŸ”¥ğŸ”¥", "competition": "ĞĞ¸Ğ·ĞºĞ°Ñ"},
    ]

    @classmethod
    def get_business_model(cls, model: BusinessModel) -> Dict:
        return cls.INCOME_STREAMS.get(model, {})
    
    @classmethod
    def get_quick_wins(cls) -> List[Dict]:
        return cls.QUICK_WINS
    
    @classmethod
    def get_hot_niches(cls) -> List[Dict]:
        return cls.NICHES_2024_2025
    
    @classmethod
    def format_business_model(cls, model: BusinessModel) -> str:
        data = cls.get_business_model(model)
        if not data:
            return "Ğ˜Ğ½Ñ„Ğ¾Ñ€Ğ¼Ğ°Ñ†Ğ¸Ñ Ğ½ĞµĞ´Ğ¾ÑÑ‚ÑƒĞ¿Ğ½Ğ°"
        
        steps = "\n".join([f"  {i+1}. {s}" for i, s in enumerate(data['steps'])])
        platforms = ", ".join(data['platforms'])
        
        return f"""
{data['name']}

ğŸ“ {data['description']}
ğŸ’µ Ğ”Ğ¾Ñ…Ğ¾Ğ´: {data['income_range']}
â± Ğ”Ğ¾ Ğ¿ĞµÑ€Ğ²Ğ¾Ğ¹ Ğ¿Ñ€Ğ¸Ğ±Ñ‹Ğ»Ğ¸: {data['time_to_profit']}
ğŸ“Š Ğ¡Ğ»Ğ¾Ğ¶Ğ½Ğ¾ÑÑ‚ÑŒ: {data['difficulty']}
ğŸ¤– AI-Ğ°Ğ²Ñ‚Ğ¾Ğ¼Ğ°Ñ‚Ğ¸Ğ·Ğ°Ñ†Ğ¸Ñ: {data['ai_automation']}

ğŸ“‹ Ğ¨Ğ°Ğ³Ğ¸:
{steps}

ğŸŒ ĞŸĞ»Ğ°Ñ‚Ñ„Ğ¾Ñ€Ğ¼Ñ‹: {platforms}
"""

# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
# Ğ¡Ğ¢Ğ Ğ£ĞšĞ¢Ğ£Ğ Ğ« Ğ”ĞĞĞĞ«Ğ¥
# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•

@dataclass
class UserProfile:
    """ĞŸÑ€Ğ¾Ñ„Ğ¸Ğ»ÑŒ Ğ¿Ğ¾Ğ»ÑŒĞ·Ğ¾Ğ²Ğ°Ñ‚ĞµĞ»Ñ"""
    user_id: int
    username: str = ""
    first_name: str = ""
    created_at: datetime = field(default_factory=datetime.now)
    last_active: datetime = field(default_factory=datetime.now)
    total_queries: int = 0
    total_tasks: int = 0
    expertise_level: str = "beginner"
    income_goal: str = "$1000/Ğ¼ĞµÑ"
    preferred_models: List[str] = field(default_factory=list)
    interests: List[str] = field(default_factory=list)
    completed_actions: List[str] = field(default_factory=list)

@dataclass
class ConversationContext:
    """ĞšĞ¾Ğ½Ñ‚ĞµĞºÑÑ‚ Ñ€Ğ°Ğ·Ğ³Ğ¾Ğ²Ğ¾Ñ€Ğ°"""
    user_id: int
    messages: List[Dict] = field(default_factory=list)
    current_topic: str = ""
    last_query: str = ""
    last_response: str = ""
    last_actions: List[Dict] = field(default_factory=list)
    session_start: datetime = field(default_factory=datetime.now)
    
    def add_message(self, role: str, content: str):
        self.messages.append({
            "role": role,
            "content": content[:500],  # Ğ›Ğ¸Ğ¼Ğ¸Ñ‚ Ğ´Ğ»Ñ ÑĞºĞ¾Ğ½Ğ¾Ğ¼Ğ¸Ğ¸
            "time": datetime.now().isoformat()
        })
        if len(self.messages) > config.MAX_HISTORY_ITEMS:
            self.messages = self.messages[-config.MAX_HISTORY_ITEMS:]
    
    def get_summary(self) -> str:
        if not self.messages:
            return ""
        recent = self.messages[-3:]
        return "\n".join([f"{m['role']}: {m['content'][:150]}" for m in recent])

# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
# Ğ¡Ğ¢ĞĞ¢Ğ˜Ğ¡Ğ¢Ğ˜ĞšĞ
# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•

class Statistics:
    """Ğ¡Ğ¸ÑÑ‚ĞµĞ¼Ğ° ÑÑ‚Ğ°Ñ‚Ğ¸ÑÑ‚Ğ¸ĞºĞ¸"""
    
    def __init__(self):
        self.queries_total = 0
        self.tasks_completed = 0
        self.tokens_saved = 0
        self.errors = 0
        self.start_time = datetime.now()
        self.agents_usage: Dict[str, int] = defaultdict(int)
        self.models_usage: Dict[str, int] = defaultdict(int)
        self.popular_topics: Dict[str, int] = defaultdict(int)
    
    def record_query(self, topic: str = "general"):
        self.queries_total += 1
        self.popular_topics[topic] += 1
    
    def record_model_usage(self, model: str):
        self.models_usage[model] += 1
    
    def record_tokens_saved(self, saved: int):
        self.tokens_saved += saved
    
    def record_agent(self, agent: str):
        self.agents_usage[agent] += 1
    
    def record_task(self):
        self.tasks_completed += 1
    
    def record_error(self):
        self.errors += 1
    
    def get_summary(self) -> str:
        uptime = datetime.now() - self.start_time
        hours = uptime.total_seconds() / 3600
        
        top_agents = sorted(self.agents_usage.items(), key=lambda x: x[1], reverse=True)[:5]
        top_topics = sorted(self.popular_topics.items(), key=lambda x: x[1], reverse=True)[:5]
        
        return f"""ğŸ“Š *Ğ¡Ğ¢ĞĞ¢Ğ˜Ğ¡Ğ¢Ğ˜ĞšĞ DEEPTHINK v3.0*

â± Ğ’Ñ€ĞµĞ¼Ñ Ñ€Ğ°Ğ±Ğ¾Ñ‚Ñ‹: {hours:.1f} Ñ‡Ğ°ÑĞ¾Ğ²
ğŸ’¬ Ğ—Ğ°Ğ¿Ñ€Ğ¾ÑĞ¾Ğ²: {self.queries_total}
âœ… Ğ—Ğ°Ğ´Ğ°Ñ‡ Ğ²Ñ‹Ğ¿Ğ¾Ğ»Ğ½ĞµĞ½Ğ¾: {self.tasks_completed}
ğŸ’° Ğ¢Ğ¾ĞºĞµĞ½Ğ¾Ğ² ÑÑĞºĞ¾Ğ½Ğ¾Ğ¼Ğ»ĞµĞ½Ğ¾: ~{self.tokens_saved}
âŒ ĞÑˆĞ¸Ğ±Ğ¾Ğº: {self.errors}

ğŸ¤– *Ğ¢Ğ¾Ğ¿ Ğ°Ğ³ĞµĞ½Ñ‚Ğ¾Ğ²:*
{chr(10).join([f"â€¢ {a}: {c}" for a, c in top_agents]) or "â€¢ ĞĞµÑ‚ Ğ´Ğ°Ğ½Ğ½Ñ‹Ñ…"}

ğŸ“ˆ *ĞŸĞ¾Ğ¿ÑƒĞ»ÑÑ€Ğ½Ñ‹Ğµ Ñ‚ĞµĞ¼Ñ‹:*
{chr(10).join([f"â€¢ {t}: {c}" for t, c in top_topics]) or "â€¢ ĞĞµÑ‚ Ğ´Ğ°Ğ½Ğ½Ñ‹Ñ…"}

ğŸ’¡ Ğ ĞµĞ¶Ğ¸Ğ¼ ÑĞºĞ¾Ğ½Ğ¾Ğ¼Ğ¸Ğ¸: {'âœ… Ğ’ĞšĞ›' if config.ECONOMY_MODE else 'âŒ Ğ’Ğ«ĞšĞ›'}
"""

stats = Statistics()

# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
# AI Ğ”Ğ’Ğ˜Ğ–ĞĞš - ĞĞŸĞ¢Ğ˜ĞœĞ˜Ğ—Ğ˜Ğ ĞĞ’ĞĞĞĞ«Ğ™
# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•

print("ğŸš€ Ğ—Ğ°Ğ³Ñ€ÑƒĞ·ĞºĞ° ÑĞ¸ÑÑ‚ĞµĞ¼Ñ‹...")

import httpx

try:
    from openai import OpenAI
    ai_client = OpenAI(
        base_url="https://openrouter.ai/api/v1",
        api_key=config.OPENROUTER_KEY
    )
    logger.info("âœ… AI ĞºĞ»Ğ¸ĞµĞ½Ñ‚ Ğ³Ğ¾Ñ‚Ğ¾Ğ²")
except Exception as e:
    logger.error(f"âŒ ĞÑˆĞ¸Ğ±ĞºĞ° AI: {e}")
    ai_client = None

class AIEngine:
    """ĞĞ¿Ñ‚Ğ¸Ğ¼Ğ¸Ğ·Ğ¸Ñ€Ğ¾Ğ²Ğ°Ğ½Ğ½Ñ‹Ğ¹ AI Ğ´Ğ²Ğ¸Ğ¶Ğ¾Ğº Ñ fallback Ğ½Ğ° Ğ±ĞµÑĞ¿Ğ»Ğ°Ñ‚Ğ½Ñ‹Ğµ Ğ¼Ğ¾Ğ´ĞµĞ»Ğ¸"""
    
    def __init__(self):
        self.client = ai_client
        self.current_model_index = 0
        self.request_count = 0
        self.errors_count = 0
    
    def _get_model(self, prefer_free: bool = True) -> str:
        """ĞŸĞ¾Ğ»ÑƒÑ‡Ğ¸Ñ‚ÑŒ Ğ¼Ğ¾Ğ´ĞµĞ»ÑŒ Ñ ÑƒÑ‡ĞµÑ‚Ğ¾Ğ¼ Ñ€ĞµĞ¶Ğ¸Ğ¼Ğ° ÑĞºĞ¾Ğ½Ğ¾Ğ¼Ğ¸Ğ¸"""
        if config.ECONOMY_MODE or prefer_free:
            models = config.FREE_MODELS
        else:
            models = config.PREMIUM_MODELS
        
        # Ğ Ğ¾Ñ‚Ğ°Ñ†Ğ¸Ñ Ğ¼Ğ¾Ğ´ĞµĞ»ĞµĞ¹ Ğ¿Ñ€Ğ¸ Ğ¾ÑˆĞ¸Ğ±ĞºĞ°Ñ…
        model = models[self.current_model_index % len(models)]
        return model
    
    def _rotate_model(self):
        """ĞŸĞµÑ€ĞµĞºĞ»ÑÑ‡Ğ¸Ñ‚ÑŒÑÑ Ğ½Ğ° ÑĞ»ĞµĞ´ÑƒÑÑ‰ÑƒÑ Ğ¼Ğ¾Ğ´ĞµĞ»ÑŒ"""
        self.current_model_index += 1
    
    async def generate(
        self,
        prompt: str,
        max_tokens: int = None,
        temperature: float = None,
        system_prompt: str = None,
        prefer_free: bool = True
    ) -> Tuple[str, bool]:
        """Ğ“ĞµĞ½ĞµÑ€Ğ°Ñ†Ğ¸Ñ Ñ Ğ°Ğ²Ñ‚Ğ¾Ğ¼Ğ°Ñ‚Ğ¸Ñ‡ĞµÑĞºĞ¸Ğ¼ fallback"""
        
        max_tokens = max_tokens or config.MAX_TOKENS_STANDARD
        temperature = temperature or config.TEMPERATURE
        
        # Ğ£Ğ¼ĞµĞ½ÑŒÑˆĞ°ĞµĞ¼ Ñ‚Ğ¾ĞºĞµĞ½Ñ‹ ĞµÑĞ»Ğ¸ Ğ² Ñ€ĞµĞ¶Ğ¸Ğ¼Ğµ ÑĞºĞ¾Ğ½Ğ¾Ğ¼Ğ¸Ğ¸
        if config.ECONOMY_MODE:
            max_tokens = min(max_tokens, config.MAX_TOKENS_FREE)
            stats.record_tokens_saved(config.MAX_TOKENS_ACTION - max_tokens)
        
        messages = []
        if system_prompt:
            messages.append({"role": "system", "content": system_prompt[:500]})
        messages.append({"role": "user", "content": prompt[:config.MAX_CONTEXT_LENGTH]})
        
        # ĞŸÑ€Ğ¾Ğ±ÑƒĞµĞ¼ Ğ½ĞµÑĞºĞ¾Ğ»ÑŒĞºĞ¾ Ğ¼Ğ¾Ğ´ĞµĞ»ĞµĞ¹
        attempts = 0
        max_attempts = len(config.FREE_MODELS) + 1
        
        while attempts < max_attempts:
            model = self._get_model(prefer_free)
            
            try:
                self.request_count += 1
                stats.record_model_usage(model)
                
                response = self.client.chat.completions.create(
                    model=model,
                    messages=messages,
                    temperature=temperature,
                    max_tokens=max_tokens
                )
                
                result = response.choices[0].message.content
                logger.info(f"âœ… ĞÑ‚Ğ²ĞµÑ‚ Ğ¾Ñ‚ {model.split('/')[-1]}")
                return result, True
                
            except Exception as e:
                error_str = str(e)
                logger.warning(f"âš ï¸ {model}: {error_str[:100]}")
                
                # Ğ•ÑĞ»Ğ¸ Ğ¾ÑˆĞ¸Ğ±ĞºĞ° 402 (Ğ½ĞµÑ‚ ĞºÑ€ĞµĞ´Ğ¸Ñ‚Ğ¾Ğ²) - Ğ¿ĞµÑ€ĞµĞºĞ»ÑÑ‡Ğ°ĞµĞ¼ÑÑ
                if "402" in error_str or "credits" in error_str.lower():
                    self._rotate_model()
                    attempts += 1
                    continue
                
                # Ğ”Ñ€ÑƒĞ³Ğ¸Ğµ Ğ¾ÑˆĞ¸Ğ±ĞºĞ¸
                self.errors_count += 1
                stats.record_error()
                self._rotate_model()
                attempts += 1
        
        return "âš ï¸ Ğ’ÑĞµ Ğ¼Ğ¾Ğ´ĞµĞ»Ğ¸ Ğ½ĞµĞ´Ğ¾ÑÑ‚ÑƒĞ¿Ğ½Ñ‹. ĞŸĞ¾Ğ¿Ñ€Ğ¾Ğ±ÑƒĞ¹Ñ‚Ğµ Ğ¿Ğ¾Ğ·Ğ¶Ğµ.", False
    
    async def generate_short(self, prompt: str) -> Tuple[str, bool]:
        """ĞšĞ¾Ñ€Ğ¾Ñ‚ĞºĞ¸Ğ¹ Ğ¾Ñ‚Ğ²ĞµÑ‚ Ğ´Ğ»Ñ ÑĞºĞ¾Ğ½Ğ¾Ğ¼Ğ¸Ğ¸ Ñ‚Ğ¾ĞºĞµĞ½Ğ¾Ğ²"""
        return await self.generate(
            prompt=prompt,
            max_tokens=config.MAX_TOKENS_SHORT,
            temperature=0.5
        )
    
    async def generate_json(self, prompt: str) -> Tuple[Any, bool]:
        """Ğ“ĞµĞ½ĞµÑ€Ğ°Ñ†Ğ¸Ñ JSON"""
        response, success = await self.generate(
            prompt=prompt + "\n\nĞ’ĞµÑ€Ğ½Ğ¸ Ğ¢ĞĞ›Ğ¬ĞšĞ JSON!",
            max_tokens=config.MAX_TOKENS_SHORT,
            temperature=0.3
        )
        
        if success:
            try:
                match = re.search(r'[\[\{].*[\]\}]', response, re.DOTALL)
                if match:
                    return json.loads(match.group()), True
            except:
                pass
        
        return None, False

ai_engine = AIEngine()

# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
# Ğ¡Ğ˜Ğ¡Ğ¢Ğ•ĞœĞ ĞĞ“Ğ•ĞĞ¢ĞĞ’ - 20 Ğ¡ĞŸĞ•Ğ¦Ğ˜ĞĞ›Ğ˜Ğ—ĞĞ¦Ğ˜Ğ™
# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•

class Agent:
    """ĞĞ³ĞµĞ½Ñ‚ Ñ Ğ¾Ğ¿Ñ‚Ğ¸Ğ¼Ğ¸Ğ·Ğ¸Ñ€Ğ¾Ğ²Ğ°Ğ½Ğ½Ñ‹Ğ¼Ğ¸ Ğ¿Ñ€Ğ¾Ğ¼Ğ¿Ñ‚Ğ°Ğ¼Ğ¸"""
    
    def __init__(
        self,
        agent_type: AgentType,
        name: str,
        emoji: str,
        specialty: str,
        keywords: List[str]
    ):
        self.agent_type = agent_type
        self.name = name
        self.emoji = emoji
        self.specialty = specialty
        self.keywords = keywords
        self.calls = 0
    
    @property
    def display_name(self) -> str:
        return f"{self.emoji} {self.name}"
    
    def matches(self, query: str) -> float:
        """ĞÑ†ĞµĞ½ĞºĞ° ÑĞ¾Ğ¾Ñ‚Ğ²ĞµÑ‚ÑÑ‚Ğ²Ğ¸Ñ Ğ·Ğ°Ğ¿Ñ€Ğ¾ÑÑƒ"""
        q = query.lower()
        matches = sum(1 for kw in self.keywords if kw in q)
        return min(matches / max(len(self.keywords) * 0.3, 1), 1.0)
    
    async def analyze(self, task: str, context: str = "") -> Tuple[str, bool]:
        """ĞĞ½Ğ°Ğ»Ğ¸Ğ· Ğ·Ğ°Ğ´Ğ°Ñ‡Ğ¸ - ĞĞŸĞ¢Ğ˜ĞœĞ˜Ğ—Ğ˜Ğ ĞĞ’ĞĞĞĞ«Ğ™ ĞŸĞ ĞĞœĞŸĞ¢"""
        
        self.calls += 1
        stats.record_agent(self.name)
        
        # ĞšĞ¾Ñ€Ğ¾Ñ‚ĞºĞ¸Ğ¹ ÑĞ¸ÑÑ‚ĞµĞ¼Ğ½Ñ‹Ğ¹ Ğ¿Ñ€Ğ¾Ğ¼Ğ¿Ñ‚ Ğ´Ğ»Ñ ÑĞºĞ¾Ğ½Ğ¾Ğ¼Ğ¸Ğ¸ Ñ‚Ğ¾ĞºĞµĞ½Ğ¾Ğ²
        system = f"Ğ¢Ñ‹ {self.name} - {self.specialty}. ĞÑ‚Ğ²ĞµÑ‡Ğ°Ğ¹ ĞºÑ€Ğ°Ñ‚ĞºĞ¾, Ğ¿Ğ¾ Ğ´ĞµĞ»Ñƒ, Ñ Ñ†Ğ¸Ñ„Ñ€Ğ°Ğ¼Ğ¸."
        
        prompt = f"""Ğ—Ğ°Ğ´Ğ°Ñ‡Ğ°: {task}

{'ĞšĞ¾Ğ½Ñ‚ĞµĞºÑÑ‚: ' + context[:300] if context else ''}

Ğ”Ğ°Ğ¹ ĞºĞ¾Ğ½ĞºÑ€ĞµÑ‚Ğ½Ñ‹Ğ¹ Ğ¾Ñ‚Ğ²ĞµÑ‚ Ñ:
- Ğ¦Ğ¸Ñ„Ñ€Ğ°Ğ¼Ğ¸ Ğ¸ Ğ¿Ñ€Ğ¸Ğ¼ĞµÑ€Ğ°Ğ¼Ğ¸
- Ğ¡Ğ¿Ğ¾ÑĞ¾Ğ±Ğ°Ğ¼Ğ¸ Ğ·Ğ°Ñ€Ğ°Ğ±Ğ¾Ñ‚ĞºĞ°
- ĞšĞ¾Ğ½ĞºÑ€ĞµÑ‚Ğ½Ñ‹Ğ¼Ğ¸ ÑˆĞ°Ğ³Ğ°Ğ¼Ğ¸"""
        
        return await ai_engine.generate(
            prompt=prompt,
            system_prompt=system,
            max_tokens=config.MAX_TOKENS_STANDARD
        )

class AgentSwarm:
    """Ğ Ğ¾Ğ¹ Ğ¸Ğ· 20 Ğ°Ğ³ĞµĞ½Ñ‚Ğ¾Ğ²"""
    
    def __init__(self):
        self.agents: Dict[AgentType, Agent] = {}
        self._init_agents()
    
    def _init_agents(self):
        """Ğ˜Ğ½Ğ¸Ñ†Ğ¸Ğ°Ğ»Ğ¸Ğ·Ğ°Ñ†Ğ¸Ñ Ğ²ÑĞµÑ… Ğ°Ğ³ĞµĞ½Ñ‚Ğ¾Ğ²"""
        
        agents_data = [
            # ĞÑĞ½Ğ¾Ğ²Ğ½Ñ‹Ğµ
            (AgentType.RESEARCHER, "Ğ˜ÑÑĞ»ĞµĞ´Ğ¾Ğ²Ğ°Ñ‚ĞµĞ»ÑŒ", "ğŸ”¬", 
             "Ğ°Ğ½Ğ°Ğ»Ğ¸Ğ· Ñ€Ñ‹Ğ½ĞºĞ¾Ğ² Ğ¸ Ñ‚Ñ€ĞµĞ½Ğ´Ğ¾Ğ²", 
             ["Ğ°Ğ½Ğ°Ğ»Ğ¸Ğ·", "Ğ¸ÑÑĞ»ĞµĞ´Ğ¾Ğ²Ğ°Ğ½Ğ¸Ğµ", "Ñ‚Ñ€ĞµĞ½Ğ´", "Ñ€Ñ‹Ğ½Ğ¾Ğº", "ÑÑ‚Ğ°Ñ‚Ğ¸ÑÑ‚Ğ¸ĞºĞ°"]),
            
            (AgentType.MONEY_EXPERT, "Ğ­ĞºÑĞ¿ĞµÑ€Ñ‚ Ğ·Ğ°Ñ€Ğ°Ğ±Ğ¾Ñ‚ĞºĞ°", "ğŸ’°",
             "Ğ¼Ğ¾Ğ½ĞµÑ‚Ğ¸Ğ·Ğ°Ñ†Ğ¸Ñ Ğ¸ Ğ´Ğ¾Ñ…Ğ¾Ğ´",
             ["Ğ·Ğ°Ñ€Ğ°Ğ±Ğ¾Ñ‚Ğ¾Ğº", "Ğ´ĞµĞ½ÑŒĞ³Ğ¸", "Ğ´Ğ¾Ñ…Ğ¾Ğ´", "Ğ¼Ğ¾Ğ½ĞµÑ‚Ğ¸Ğ·Ğ°Ñ†Ğ¸Ñ", "Ğ¿Ñ€Ğ¸Ğ±Ñ‹Ğ»ÑŒ"]),
            
            (AgentType.STRATEGIST, "Ğ¡Ñ‚Ñ€Ğ°Ñ‚ĞµĞ³", "ğŸ—ï¸",
             "ÑÑ‚Ñ€Ğ°Ñ‚ĞµĞ³Ğ¸Ğ¸ Ğ¸ Ğ¿Ğ»Ğ°Ğ½Ğ¸Ñ€Ğ¾Ğ²Ğ°Ğ½Ğ¸Ğµ",
             ["Ğ¿Ğ»Ğ°Ğ½", "ÑÑ‚Ñ€Ğ°Ñ‚ĞµĞ³Ğ¸Ñ", "roadmap", "Ğ¼Ğ°ÑÑˆÑ‚Ğ°Ğ±", "Ñ€Ğ°Ğ·Ğ²Ğ¸Ñ‚Ğ¸Ğµ"]),
            
            (AgentType.CONTENT_CREATOR, "ĞšĞ¾Ğ½Ñ‚ĞµĞ½Ñ‚-Ğ¼ĞµĞ¹ĞºĞµÑ€", "âœï¸",
             "ÑĞ¾Ğ·Ğ´Ğ°Ğ½Ğ¸Ğµ ĞºĞ¾Ğ½Ñ‚ĞµĞ½Ñ‚Ğ°",
             ["ĞºĞ¾Ğ½Ñ‚ĞµĞ½Ñ‚", "Ñ‚ĞµĞºÑÑ‚", "Ğ¿Ğ¾ÑÑ‚", "ÑÑ‚Ğ°Ñ‚ÑŒÑ", "ĞºĞ¾Ğ¿Ğ¸Ñ€Ğ°Ğ¹Ñ‚"]),
            
            (AgentType.CODER, "ĞšĞ¾Ğ´ĞµÑ€", "ğŸ’»",
             "Ğ¿Ñ€Ğ¾Ğ³Ñ€Ğ°Ğ¼Ğ¼Ğ¸Ñ€Ğ¾Ğ²Ğ°Ğ½Ğ¸Ğµ Ğ¸ Ğ°Ğ²Ñ‚Ğ¾Ğ¼Ğ°Ñ‚Ğ¸Ğ·Ğ°Ñ†Ğ¸Ñ",
             ["ĞºĞ¾Ğ´", "Ğ¿Ñ€Ğ¾Ğ³Ñ€Ğ°Ğ¼Ğ¼Ğ°", "Ğ±Ğ¾Ñ‚", "ÑĞºÑ€Ğ¸Ğ¿Ñ‚", "python", "Ğ°Ğ²Ñ‚Ğ¾Ğ¼Ğ°Ñ‚Ğ¸Ğ·Ğ°Ñ†Ğ¸Ñ"]),
            
            (AgentType.MARKETER, "ĞœĞ°Ñ€ĞºĞµÑ‚Ğ¾Ğ»Ğ¾Ğ³", "ğŸ“¢",
             "Ğ¼Ğ°Ñ€ĞºĞµÑ‚Ğ¸Ğ½Ğ³ Ğ¸ Ğ¿Ñ€Ğ¾Ğ´Ğ²Ğ¸Ğ¶ĞµĞ½Ğ¸Ğµ",
             ["Ğ¼Ğ°Ñ€ĞºĞµÑ‚Ğ¸Ğ½Ğ³", "Ñ€ĞµĞºĞ»Ğ°Ğ¼Ğ°", "Ğ¿Ñ€Ğ¾Ğ´Ğ²Ğ¸Ğ¶ĞµĞ½Ğ¸Ğµ", "Ñ‚Ğ°Ñ€Ğ³ĞµÑ‚", "Ñ‚Ñ€Ğ°Ñ„Ğ¸Ğº"]),
            
            # Ğ¡Ğ¿ĞµÑ†Ğ¸Ğ°Ğ»Ğ¸Ğ·Ğ¸Ñ€Ğ¾Ğ²Ğ°Ğ½Ğ½Ñ‹Ğµ Ğ´Ğ»Ñ Ğ·Ğ°Ñ€Ğ°Ğ±Ğ¾Ñ‚ĞºĞ°
            (AgentType.DROPSHIPPER, "Ğ”Ñ€Ğ¾Ğ¿ÑˆĞ¸Ğ¿Ğ¿ĞµÑ€", "ğŸ“¦",
             "Ğ´Ñ€Ğ¾Ğ¿ÑˆĞ¸Ğ¿Ğ¿Ğ¸Ğ½Ğ³ Ğ¸ e-commerce",
             ["Ğ´Ñ€Ğ¾Ğ¿ÑˆĞ¸Ğ¿Ğ¿Ğ¸Ğ½Ğ³", "Ñ‚Ğ¾Ğ²Ğ°Ñ€", "Ğ¿Ğ¾ÑÑ‚Ğ°Ğ²Ñ‰Ğ¸Ğº", "Ğ¼Ğ°Ğ³Ğ°Ğ·Ğ¸Ğ½", "wildberries", "ozon"]),
            
            (AgentType.AFFILIATE, "ĞŸĞ°Ñ€Ñ‚Ğ½Ñ‘Ñ€Ñ‰Ğ¸Ğº", "ğŸ”—",
             "Ğ¿Ğ°Ñ€Ñ‚Ğ½Ñ‘Ñ€ÑĞºĞ¸Ğ¹ Ğ¼Ğ°Ñ€ĞºĞµÑ‚Ğ¸Ğ½Ğ³",
             ["Ğ¿Ğ°Ñ€Ñ‚Ğ½Ñ‘Ñ€ĞºĞ°", "affiliate", "Ñ€ĞµÑ„ĞµÑ€Ğ°Ğ»", "ÑÑÑ‹Ğ»ĞºĞ°", "ĞºĞ¾Ğ¼Ğ¸ÑÑĞ¸Ñ"]),
            
            (AgentType.FREELANCER, "Ğ¤Ñ€Ğ¸Ğ»Ğ°Ğ½ÑĞµÑ€", "ğŸ¯",
             "Ñ„Ñ€Ğ¸Ğ»Ğ°Ğ½Ñ Ğ¸ ÑƒÑĞ»ÑƒĞ³Ğ¸",
             ["Ñ„Ñ€Ğ¸Ğ»Ğ°Ğ½Ñ", "Ğ·Ğ°ĞºĞ°Ğ·", "ĞºĞ»Ğ¸ĞµĞ½Ñ‚", "ÑƒÑĞ»ÑƒĞ³Ğ°", "kwork", "fiverr"]),
            
            (AgentType.CRYPTO_EXPERT, "ĞšÑ€Ğ¸Ğ¿Ñ‚Ğ¾-ÑĞºÑĞ¿ĞµÑ€Ñ‚", "ğŸª™",
             "ĞºÑ€Ğ¸Ğ¿Ñ‚Ğ¾Ğ²Ğ°Ğ»ÑÑ‚Ñ‹ Ğ¸ web3",
             ["ĞºÑ€Ğ¸Ğ¿Ñ‚Ğ¾", "Ğ±Ğ¸Ñ‚ĞºĞ¾Ğ¸Ğ½", "Ğ±Ğ»Ğ¾ĞºÑ‡ĞµĞ¹Ğ½", "nft", "web3", "Ñ‚Ğ¾ĞºĞµĞ½"]),
            
            (AgentType.ECOMMERCE, "E-commerce", "ğŸ›’",
             "Ğ¸Ğ½Ñ‚ĞµÑ€Ğ½ĞµÑ‚-Ñ‚Ğ¾Ñ€Ğ³Ğ¾Ğ²Ğ»Ñ",
             ["Ğ¼Ğ°Ğ³Ğ°Ğ·Ğ¸Ğ½", "Ñ‚Ğ¾Ğ²Ğ°Ñ€", "Ğ¿Ñ€Ğ¾Ğ´Ğ°Ğ¶Ğ°", "Ğ¼Ğ°Ñ€ĞºĞµÑ‚Ğ¿Ğ»ĞµĞ¹Ñ", "ÑĞºĞ»Ğ°Ğ´"]),
            
            (AgentType.SAAS_EXPERT, "SaaS-ÑĞºÑĞ¿ĞµÑ€Ñ‚", "â˜ï¸",
             "SaaS Ğ¸ Ğ¿Ğ¾Ğ´Ğ¿Ğ¸ÑĞ¾Ñ‡Ğ½Ñ‹Ğµ Ğ¼Ğ¾Ğ´ĞµĞ»Ğ¸",
             ["saas", "Ğ¿Ğ¾Ğ´Ğ¿Ğ¸ÑĞºĞ°", "ÑĞµÑ€Ğ²Ğ¸Ñ", "Ğ¿Ñ€Ğ¸Ğ»Ğ¾Ğ¶ĞµĞ½Ğ¸Ğµ", "ÑÑ‚Ğ°Ñ€Ñ‚Ğ°Ğ¿"]),
            
            # ĞĞ½Ğ°Ğ»Ğ¸Ñ‚Ğ¸ĞºĞ° Ğ¸ ĞºÑ€ĞµĞ°Ñ‚Ğ¸Ğ²
            (AgentType.DATA_ANALYST, "ĞĞ½Ğ°Ğ»Ğ¸Ñ‚Ğ¸Ğº Ğ´Ğ°Ğ½Ğ½Ñ‹Ñ…", "ğŸ“Š",
             "Ğ°Ğ½Ğ°Ğ»Ğ¸Ñ‚Ğ¸ĞºĞ° Ğ¸ Ğ¼ĞµÑ‚Ñ€Ğ¸ĞºĞ¸",
             ["Ğ´Ğ°Ğ½Ğ½Ñ‹Ğµ", "Ğ¼ĞµÑ‚Ñ€Ğ¸ĞºĞ°", "Ğ°Ğ½Ğ°Ğ»Ğ¸Ñ‚Ğ¸ĞºĞ°", "kpi", "Ğ¾Ñ‚Ñ‡Ñ‘Ñ‚"]),
            
            (AgentType.CREATIVE_DIRECTOR, "ĞšÑ€ĞµĞ°Ñ‚Ğ¸Ğ²Ñ‰Ğ¸Ğº", "ğŸ¨",
             "ĞºÑ€ĞµĞ°Ñ‚Ğ¸Ğ² Ğ¸ Ğ¸Ğ´ĞµĞ¸",
             ["Ğ¸Ğ´ĞµÑ", "ĞºÑ€ĞµĞ°Ñ‚Ğ¸Ğ²", "Ğ±Ñ€ĞµĞ½Ğ´", "ĞºĞ¾Ğ½Ñ†ĞµĞ¿Ñ†Ğ¸Ñ", "ÑƒĞ½Ğ¸ĞºĞ°Ğ»ÑŒĞ½Ñ‹Ğ¹"]),
            
            (AgentType.COPYWRITER, "ĞšĞ¾Ğ¿Ğ¸Ñ€Ğ°Ğ¹Ñ‚ĞµÑ€", "ğŸ“",
             "Ğ¿Ñ€Ğ¾Ğ´Ğ°ÑÑ‰Ğ¸Ğµ Ñ‚ĞµĞºÑÑ‚Ñ‹",
             ["Ñ‚ĞµĞºÑÑ‚", "Ğ¿Ñ€Ğ¾Ğ´Ğ°ÑÑ‰Ğ¸Ğ¹", "Ğ·Ğ°Ğ³Ğ¾Ğ»Ğ¾Ğ²Ğ¾Ğº", "Ğ¿Ğ¸ÑÑŒĞ¼Ğ¾", "Ğ»ĞµĞ½Ğ´Ğ¸Ğ½Ğ³"]),
            
            (AgentType.SEO_EXPERT, "SEO-ÑĞºÑĞ¿ĞµÑ€Ñ‚", "ğŸ”",
             "Ğ¿Ğ¾Ğ¸ÑĞºĞ¾Ğ²Ğ°Ñ Ğ¾Ğ¿Ñ‚Ğ¸Ğ¼Ğ¸Ğ·Ğ°Ñ†Ğ¸Ñ",
             ["seo", "Ğ¿Ğ¾Ğ¸ÑĞº", "google", "ĞºĞ»ÑÑ‡ĞµĞ²Ñ‹Ğµ", "Ğ¾Ğ¿Ñ‚Ğ¸Ğ¼Ğ¸Ğ·Ğ°Ñ†Ğ¸Ñ"]),
            
            # Ğ¡Ğ¿ĞµÑ†Ğ¸Ğ°Ğ»Ğ¸ÑÑ‚Ñ‹
            (AgentType.INVESTOR, "Ğ˜Ğ½Ğ²ĞµÑÑ‚Ğ¾Ñ€", "ğŸ“ˆ",
             "Ğ¸Ğ½Ğ²ĞµÑÑ‚Ğ¸Ñ†Ğ¸Ğ¸ Ğ¸ Ñ„Ğ¸Ğ½Ğ°Ğ½ÑÑ‹",
             ["Ğ¸Ğ½Ğ²ĞµÑÑ‚Ğ¸Ñ†Ğ¸Ñ", "Ğ²Ğ»Ğ¾Ğ¶ĞµĞ½Ğ¸Ğµ", "Ğ°ĞºÑ‚Ğ¸Ğ²", "Ğ¿Ğ¾Ñ€Ñ‚Ñ„ĞµĞ»ÑŒ", "Ñ€Ğ¸ÑĞº"]),
            
            (AgentType.AUTOMATION, "ĞĞ²Ñ‚Ğ¾Ğ¼Ğ°Ñ‚Ğ¸Ğ·Ğ°Ñ‚Ğ¾Ñ€", "âš™ï¸",
             "Ğ°Ğ²Ñ‚Ğ¾Ğ¼Ğ°Ñ‚Ğ¸Ğ·Ğ°Ñ†Ğ¸Ñ Ğ¿Ñ€Ğ¾Ñ†ĞµÑÑĞ¾Ğ²",
             ["Ğ°Ğ²Ñ‚Ğ¾Ğ¼Ğ°Ñ‚Ğ¸Ğ·Ğ°Ñ†Ğ¸Ñ", "Ğ¸Ğ½Ñ‚ĞµĞ³Ñ€Ğ°Ñ†Ğ¸Ñ", "zapier", "make", "n8n"]),
            
            (AgentType.COACH, "ĞšĞ¾ÑƒÑ‡", "ğŸ¯",
             "Ğ¼Ğ¾Ñ‚Ğ¸Ğ²Ğ°Ñ†Ğ¸Ñ Ğ¸ Ñ€Ğ°Ğ·Ğ²Ğ¸Ñ‚Ğ¸Ğµ",
             ["Ğ¼Ğ¾Ñ‚Ğ¸Ğ²Ğ°Ñ†Ğ¸Ñ", "Ñ†ĞµĞ»ÑŒ", "Ñ€Ğ¾ÑÑ‚", "Ğ¿Ñ€Ğ¸Ğ²Ñ‹Ñ‡ĞºĞ°", "Ğ¿Ñ€Ğ¾Ğ´ÑƒĞºÑ‚Ğ¸Ğ²Ğ½Ğ¾ÑÑ‚ÑŒ"]),
            
            (AgentType.LEGAL, "Ğ®Ñ€Ğ¸ÑÑ‚", "âš–ï¸",
             "Ğ¿Ñ€Ğ°Ğ²Ğ¾Ğ²Ñ‹Ğµ Ğ²Ğ¾Ğ¿Ñ€Ğ¾ÑÑ‹",
             ["Ğ·Ğ°ĞºĞ¾Ğ½", "Ğ´Ğ¾Ğ³Ğ¾Ğ²Ğ¾Ñ€", "Ğ¿Ñ€Ğ°Ğ²Ğ¾", "Ğ½Ğ°Ğ»Ğ¾Ğ³", "ÑÑ€Ğ¸Ğ´Ğ¸Ñ‡ĞµÑĞºĞ¸Ğ¹"]),
        ]
        
        for data in agents_data:
            agent = Agent(*data)
            self.agents[data[0]] = agent
        
        logger.info(f"âœ… Ğ—Ğ°Ğ³Ñ€ÑƒĞ¶ĞµĞ½Ğ¾ {len(self.agents)} Ğ°Ğ³ĞµĞ½Ñ‚Ğ¾Ğ²")
    
    def select_for_query(self, query: str, max_agents: int = None) -> List[Agent]:
        """Ğ£Ğ¼Ğ½Ñ‹Ğ¹ Ğ²Ñ‹Ğ±Ğ¾Ñ€ Ğ°Ğ³ĞµĞ½Ñ‚Ğ¾Ğ²"""
        max_agents = max_agents or config.MAX_AGENTS_PER_QUERY
        
        # ĞÑ†ĞµĞ½ĞºĞ° ĞºĞ°Ğ¶Ğ´Ğ¾Ğ³Ğ¾ Ğ°Ğ³ĞµĞ½Ñ‚Ğ°
        scored = [(agent, agent.matches(query)) for agent in self.agents.values()]
        scored.sort(key=lambda x: x[1], reverse=True)
        
        # ĞĞ±ÑĞ·Ğ°Ñ‚ĞµĞ»ÑŒĞ½Ñ‹Ğµ Ğ°Ğ³ĞµĞ½Ñ‚Ñ‹
        must_have = {AgentType.MONEY_EXPERT, AgentType.RESEARCHER}
        selected = []
        
        for agent_type in must_have:
            if agent_type in self.agents:
                selected.append(self.agents[agent_type])
        
        # Ğ”Ğ¾Ğ±Ğ°Ğ²Ğ»ÑĞµĞ¼ Ñ€ĞµĞ»ĞµĞ²Ğ°Ğ½Ñ‚Ğ½Ñ‹Ñ…
        for agent, score in scored:
            if len(selected) >= max_agents:
                break
            if agent not in selected and score > 0.1:
                selected.append(agent)
        
        return selected[:max_agents]
    
    async def think_together(
        self,
        query: str,
        context: str = ""
    ) -> List[Tuple[str, str, bool]]:
        """ĞšĞ¾Ğ»Ğ»ĞµĞºÑ‚Ğ¸Ğ²Ğ½Ğ¾Ğµ Ğ¼Ñ‹ÑˆĞ»ĞµĞ½Ğ¸Ğµ"""
        
        agents = self.select_for_query(query)
        
        tasks = [agent.analyze(query, context) for agent in agents]
        results = await asyncio.gather(*tasks, return_exceptions=True)
        
        responses = []
        for agent, result in zip(agents, results):
            if isinstance(result, Exception):
                responses.append((agent.display_name, f"ĞÑˆĞ¸Ğ±ĞºĞ°: {result}", False))
            else:
                text, success = result
                responses.append((agent.display_name, text, success))
        
        return responses

swarm = AgentSwarm()

# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
# Ğ¡Ğ˜ĞĞ¢Ğ•Ğ—ĞĞ¢ĞĞ  ĞĞ¢Ğ’Ğ•Ğ¢ĞĞ’ - ĞĞŸĞ¢Ğ˜ĞœĞ˜Ğ—Ğ˜Ğ ĞĞ’ĞĞĞĞ«Ğ™
# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•

class ResponseSynthesizer:
    """Ğ¡Ğ¸Ğ½Ñ‚ĞµĞ·Ğ°Ñ‚Ğ¾Ñ€ Ñ ÑĞºĞ¾Ğ½Ğ¾Ğ¼Ğ¸ĞµĞ¹ Ñ‚Ğ¾ĞºĞµĞ½Ğ¾Ğ²"""
    
    @staticmethod
    async def synthesize(
        query: str,
        agent_responses: List[Tuple[str, str, bool]],
        user_profile: UserProfile = None
    ) -> str:
        """Ğ¡Ğ¸Ğ½Ñ‚ĞµĞ· Ğ¾Ñ‚Ğ²ĞµÑ‚Ğ¾Ğ² Ğ² ĞµĞ´Ğ¸Ğ½Ñ‹Ğ¹"""
        
        # Ğ¡Ğ¾Ğ±Ğ¸Ñ€Ğ°ĞµĞ¼ ÑƒÑĞ¿ĞµÑˆĞ½Ñ‹Ğµ Ğ¾Ñ‚Ğ²ĞµÑ‚Ñ‹
        valid_responses = [
            f"[{name}]: {text[:400]}"
            for name, text, success in agent_responses if success
        ]
        
        if not valid_responses:
            return "âš ï¸ ĞĞµ ÑƒĞ´Ğ°Ğ»Ğ¾ÑÑŒ Ğ¿Ğ¾Ğ»ÑƒÑ‡Ğ¸Ñ‚ÑŒ Ğ¾Ñ‚Ğ²ĞµÑ‚Ñ‹ Ğ¾Ñ‚ Ğ°Ğ³ĞµĞ½Ñ‚Ğ¾Ğ². ĞŸĞ¾Ğ¿Ñ€Ğ¾Ğ±ÑƒĞ¹Ñ‚Ğµ Ğ¿ĞµÑ€ĞµÑ„Ğ¾Ñ€Ğ¼ÑƒĞ»Ğ¸Ñ€Ğ¾Ğ²Ğ°Ñ‚ÑŒ Ğ²Ğ¾Ğ¿Ñ€Ğ¾Ñ."
        
        agents_input = "\n\n".join(valid_responses)
        
        # ĞšĞ¾Ñ€Ğ¾Ñ‚ĞºĞ¸Ğ¹ Ğ¿Ñ€Ğ¾Ğ¼Ğ¿Ñ‚ Ğ´Ğ»Ñ ÑĞ¸Ğ½Ñ‚ĞµĞ·Ğ°
        prompt = f"""ĞĞ±ÑŠĞµĞ´Ğ¸Ğ½Ğ¸ Ğ¾Ñ‚Ğ²ĞµÑ‚Ñ‹ ÑĞºÑĞ¿ĞµÑ€Ñ‚Ğ¾Ğ² Ğ² Ğ¿Ğ¾Ğ»ĞµĞ·Ğ½Ñ‹Ğ¹ Ğ¾Ñ‚Ğ²ĞµÑ‚.

Ğ’ĞĞŸĞ ĞĞ¡: {query}

ĞĞ¢Ğ’Ğ•Ğ¢Ğ« Ğ­ĞšĞ¡ĞŸĞ•Ğ Ğ¢ĞĞ’:
{agents_input}

Ğ¤ĞĞ ĞœĞĞ¢ ĞĞ¢Ğ’Ğ•Ğ¢Ğ:

ğŸ§  *Ğ¡Ğ£Ğ¢Ğ¬* (2-3 Ğ¿Ñ€ĞµĞ´Ğ»Ğ¾Ğ¶ĞµĞ½Ğ¸Ñ)

ğŸ’° *ĞšĞĞš Ğ—ĞĞ ĞĞ‘ĞĞ¢ĞĞ¢Ğ¬:*

*1. [Ğ¡Ğ¿Ğ¾ÑĞ¾Ğ±]* - $X/Ğ¼ĞµÑ
â€¢ Ğ”ĞµĞ»Ğ°ĞµĞ¼: ...
â€¢ AI Ğ¿Ğ¾Ğ¼Ğ¾Ğ³Ğ°ĞµÑ‚: X%
â€¢ Ğ¨Ğ°Ğ³Ğ¸: 1, 2, 3

*2. [Ğ¡Ğ¿Ğ¾ÑĞ¾Ğ±]* - $X/Ğ¼ĞµÑ
â€¢ Ğ”ĞµĞ»Ğ°ĞµĞ¼: ...

*3. [Ğ¡Ğ¿Ğ¾ÑĞ¾Ğ±]* - $X/Ğ¼ĞµÑ
â€¢ Ğ”ĞµĞ»Ğ°ĞµĞ¼: ...

ğŸ¯ *ĞĞĞ§ĞĞ˜ Ğ¡Ğ•Ğ™Ğ§ĞĞ¡:* [ĞºĞ¾Ğ½ĞºÑ€ĞµÑ‚Ğ½Ğ¾Ğµ Ğ´ĞµĞ¹ÑÑ‚Ğ²Ğ¸Ğµ]

ĞšÑ€Ğ°Ñ‚ĞºĞ¾ Ğ¸ Ğ¿Ğ¾ Ğ´ĞµĞ»Ñƒ!"""
        
        response, success = await ai_engine.generate(
            prompt=prompt,
            max_tokens=config.MAX_TOKENS_FREE
        )
        
        if not success:
            # Fallback - Ğ¿Ñ€Ğ¾ÑÑ‚Ğ¾Ğµ Ğ¾Ğ±ÑŠĞµĞ´Ğ¸Ğ½ĞµĞ½Ğ¸Ğµ
            return "\n\n---\n\n".join([
                f"{name}:\n{text[:500]}"
                for name, text, s in agent_responses if s
            ])
        
        return response

# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
# Ğ“Ğ•ĞĞ•Ğ ĞĞ¢ĞĞ  Ğ”Ğ•Ğ™Ğ¡Ğ¢Ğ’Ğ˜Ğ™
# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•

class ActionGenerator:
    """Ğ“ĞµĞ½ĞµÑ€Ğ°Ñ‚Ğ¾Ñ€ Ğ°Ğ²Ñ‚Ğ¾Ğ¼Ğ°Ñ‚Ğ¸Ñ‡ĞµÑĞºĞ¸Ñ… Ğ´ĞµĞ¹ÑÑ‚Ğ²Ğ¸Ğ¹"""
    
    ACTION_TEMPLATES = {
        "create_content": ("âœï¸", "Ğ¡Ğ¾Ğ·Ğ´Ğ°Ñ‚ÑŒ ĞºĞ¾Ğ½Ñ‚ĞµĞ½Ñ‚"),
        "create_code": ("ğŸ’»", "ĞĞ°Ğ¿Ğ¸ÑĞ°Ñ‚ÑŒ ĞºĞ¾Ğ´"),
        "create_plan": ("ğŸ“‹", "Ğ¡Ğ¾ÑÑ‚Ğ°Ğ²Ğ¸Ñ‚ÑŒ Ğ¿Ğ»Ğ°Ğ½"),
        "create_template": ("ğŸ“„", "Ğ¡Ğ¾Ğ·Ğ´Ğ°Ñ‚ÑŒ ÑˆĞ°Ğ±Ğ»Ğ¾Ğ½"),
        "brainstorm": ("ğŸ’¡", "Ğ“ĞµĞ½ĞµÑ€Ğ¸Ñ€Ğ¾Ğ²Ğ°Ñ‚ÑŒ Ğ¸Ğ´ĞµĞ¸"),
        "analyze": ("ğŸ“Š", "ĞŸÑ€Ğ¾Ğ²ĞµÑÑ‚Ğ¸ Ğ°Ğ½Ğ°Ğ»Ğ¸Ğ·"),
        "find_niches": ("ğŸ”", "ĞĞ°Ğ¹Ñ‚Ğ¸ Ğ½Ğ¸ÑˆĞ¸"),
        "calculate_income": ("ğŸ§®", "Ğ Ğ°ÑÑÑ‡Ğ¸Ñ‚Ğ°Ñ‚ÑŒ Ğ´Ğ¾Ñ…Ğ¾Ğ´"),
    }
    
    @classmethod
    async def generate(cls, query: str, analysis: str) -> List[Dict]:
        """Ğ“ĞµĞ½ĞµÑ€Ğ°Ñ†Ğ¸Ñ Ğ´ĞµĞ¹ÑÑ‚Ğ²Ğ¸Ğ¹"""
        
        # Ğ‘Ñ‹ÑÑ‚Ñ€Ğ°Ñ Ğ³ĞµĞ½ĞµÑ€Ğ°Ñ†Ğ¸Ñ Ğ±ĞµĞ· AI Ğ´Ğ»Ñ ÑĞºĞ¾Ğ½Ğ¾Ğ¼Ğ¸Ğ¸
        actions = []
        q = query.lower()
        
        if any(w in q for w in ["ĞºĞ¾Ğ½Ñ‚ĞµĞ½Ñ‚", "Ñ‚ĞµĞºÑÑ‚", "Ğ¿Ğ¾ÑÑ‚"]):
            actions.append({
                "type": "create_content",
                "name": "âœï¸ Ğ¡Ğ¾Ğ·Ğ´Ğ°Ñ‚ÑŒ ĞºĞ¾Ğ½Ñ‚ĞµĞ½Ñ‚",
                "description": f"Ğ“Ğ¾Ñ‚Ğ¾Ğ²Ñ‹Ğ¹ ĞºĞ¾Ğ½Ñ‚ĞµĞ½Ñ‚ Ğ¿Ğ¾ Ñ‚ĞµĞ¼Ğµ: {query[:50]}"
            })
        
        if any(w in q for w in ["ĞºĞ¾Ğ´", "Ğ±Ğ¾Ñ‚", "ÑĞºÑ€Ğ¸Ğ¿Ñ‚", "Ğ°Ğ²Ñ‚Ğ¾Ğ¼Ğ°Ñ‚Ğ¸Ğ·Ğ°Ñ†Ğ¸Ñ"]):
            actions.append({
                "type": "create_code",
                "name": "ğŸ’» ĞĞ°Ğ¿Ğ¸ÑĞ°Ñ‚ÑŒ ĞºĞ¾Ğ´",
                "description": f"Ğ Ğ°Ğ±Ğ¾Ñ‡Ğ¸Ğ¹ ĞºĞ¾Ğ´: {query[:50]}"
            })
        
        if any(w in q for w in ["Ğ¿Ğ»Ğ°Ğ½", "ÑÑ‚Ñ€Ğ°Ñ‚ĞµĞ³Ğ¸Ñ", "ĞºĞ°Ğº Ğ½Ğ°Ñ‡Ğ°Ñ‚ÑŒ"]):
            actions.append({
                "type": "create_plan",
                "name": "ğŸ“‹ ĞŸĞ¾ÑˆĞ°Ğ³Ğ¾Ğ²Ñ‹Ğ¹ Ğ¿Ğ»Ğ°Ğ½",
                "description": f"Ğ”ĞµÑ‚Ğ°Ğ»ÑŒĞ½Ñ‹Ğ¹ Ğ¿Ğ»Ğ°Ğ½: {query[:50]}"
            })
        
        if any(w in q for w in ["Ğ¸Ğ´ĞµÑ", "Ğ½Ğ¸ÑˆĞ°", "Ñ‡Ñ‚Ğ¾ Ğ´ĞµĞ»Ğ°Ñ‚ÑŒ"]):
            actions.append({
                "type": "brainstorm",
                "name": "ğŸ’¡ 10 Ğ¸Ğ´ĞµĞ¹",
                "description": f"Ğ˜Ğ´ĞµĞ¸ Ğ´Ğ»Ñ Ğ·Ğ°Ñ€Ğ°Ğ±Ğ¾Ñ‚ĞºĞ°: {query[:50]}"
            })
        
        if any(w in q for w in ["Ğ·Ğ°Ñ€Ğ°Ğ±Ğ¾Ñ‚", "Ğ´Ğ¾Ñ…Ğ¾Ğ´", "Ğ´ĞµĞ½ÑŒĞ³Ğ¸"]):
            actions.append({
                "type": "calculate_income",
                "name": "ğŸ§® Ğ Ğ°ÑÑ‡Ñ‘Ñ‚ Ğ´Ğ¾Ñ…Ğ¾Ğ´Ğ°",
                "description": "ĞšĞ°Ğ»ÑŒĞºÑƒĞ»ÑÑ‚Ğ¾Ñ€ Ğ¿Ğ¾Ñ‚ĞµĞ½Ñ†Ğ¸Ğ°Ğ»ÑŒĞ½Ğ¾Ğ³Ğ¾ Ğ´Ğ¾Ñ…Ğ¾Ğ´Ğ°"
            })
        
        # Ğ”ĞµÑ„Ğ¾Ğ»Ñ‚Ğ½Ñ‹Ğµ Ğ´ĞµĞ¹ÑÑ‚Ğ²Ğ¸Ñ ĞµÑĞ»Ğ¸ Ğ½Ğ¸Ñ‡ĞµĞ³Ğ¾ Ğ½Ğµ Ğ¿Ğ¾Ğ´Ğ¾ÑˆĞ»Ğ¾
        if not actions:
            actions = [
                {
                    "type": "create_plan",
                    "name": "ğŸ“‹ ĞŸĞ»Ğ°Ğ½ Ğ´ĞµĞ¹ÑÑ‚Ğ²Ğ¸Ğ¹",
                    "description": f"ĞŸĞ»Ğ°Ğ½ Ğ¿Ğ¾ Ñ‚ĞµĞ¼Ğµ: {query[:50]}"
                },
                {
                    "type": "brainstorm",
                    "name": "ğŸ’¡ Ğ˜Ğ´ĞµĞ¸",
                    "description": "Ğ“ĞµĞ½ĞµÑ€Ğ°Ñ†Ğ¸Ñ Ğ¸Ğ´ĞµĞ¹"
                }
            ]
        
        return actions[:config.MAX_ACTIONS_PER_RESPONSE]
    
    @classmethod
    async def execute(cls, action: Dict, context: str) -> str:
        """Ğ’Ñ‹Ğ¿Ğ¾Ğ»Ğ½ĞµĞ½Ğ¸Ğµ Ğ´ĞµĞ¹ÑÑ‚Ğ²Ğ¸Ñ"""
        
        action_type = action.get("type", "create_plan")
        desc = action.get("description", "")
        
        prompts = {
            "create_content": f"""Ğ¡Ğ¾Ğ·Ğ´Ğ°Ğ¹ Ğ³Ğ¾Ñ‚Ğ¾Ğ²Ñ‹Ğ¹ ĞºĞ¾Ğ½Ñ‚ĞµĞ½Ñ‚: {desc}

Ğ’ĞºĞ»ÑÑ‡Ğ¸:
- Ğ—Ğ°Ğ³Ğ¾Ğ»Ğ¾Ğ²Ğ¾Ğº
- ĞÑĞ½Ğ¾Ğ²Ğ½Ğ¾Ğ¹ Ñ‚ĞµĞºÑÑ‚ (300-500 ÑĞ»Ğ¾Ğ²)
- ĞŸÑ€Ğ¸Ğ·Ñ‹Ğ² Ğº Ğ´ĞµĞ¹ÑÑ‚Ğ²Ğ¸Ñ
- Ğ¥ĞµÑˆÑ‚ĞµĞ³Ğ¸

ĞšĞ¾Ğ½Ñ‚ĞµĞ½Ñ‚ Ğ´Ğ¾Ğ»Ğ¶ĞµĞ½ Ğ±Ñ‹Ñ‚ÑŒ Ğ³Ğ¾Ñ‚Ğ¾Ğ² Ğº Ğ¿ÑƒĞ±Ğ»Ğ¸ĞºĞ°Ñ†Ğ¸Ğ¸!""",

            "create_code": f"""ĞĞ°Ğ¿Ğ¸ÑˆĞ¸ Ñ€Ğ°Ğ±Ğ¾Ñ‡Ğ¸Ğ¹ Python ĞºĞ¾Ğ´: {desc}

Ğ¢Ñ€ĞµĞ±Ğ¾Ğ²Ğ°Ğ½Ğ¸Ñ:
- ĞŸĞ¾Ğ»Ğ½Ğ¾ÑÑ‚ÑŒÑ Ñ€Ğ°Ğ±Ğ¾Ñ‡Ğ¸Ğ¹ ĞºĞ¾Ğ´
- ĞšĞ¾Ğ¼Ğ¼ĞµĞ½Ñ‚Ğ°Ñ€Ğ¸Ğ¸ Ğ½Ğ° Ñ€ÑƒÑÑĞºĞ¾Ğ¼
- ĞĞ±Ñ€Ğ°Ğ±Ğ¾Ñ‚ĞºĞ° Ğ¾ÑˆĞ¸Ğ±Ğ¾Ğº
- ĞŸÑ€Ğ¸Ğ¼ĞµÑ€ Ğ¸ÑĞ¿Ğ¾Ğ»ÑŒĞ·Ğ¾Ğ²Ğ°Ğ½Ğ¸Ñ""",

            "create_plan": f"""Ğ¡Ğ¾Ğ·Ğ´Ğ°Ğ¹ Ğ¿Ğ¾ÑˆĞ°Ğ³Ğ¾Ğ²Ñ‹Ğ¹ Ğ¿Ğ»Ğ°Ğ½: {desc}

Ğ¤Ğ¾Ñ€Ğ¼Ğ°Ñ‚:
ğŸ“… Ğ”Ğ•ĞĞ¬ 1-7:
â€¢ ĞšĞ¾Ğ½ĞºÑ€ĞµÑ‚Ğ½Ñ‹Ğµ Ğ´ĞµĞ¹ÑÑ‚Ğ²Ğ¸Ñ
â€¢ ĞĞ¶Ğ¸Ğ´Ğ°ĞµĞ¼Ñ‹Ğµ Ñ€ĞµĞ·ÑƒĞ»ÑŒÑ‚Ğ°Ñ‚Ñ‹

ğŸ“… ĞĞ•Ğ”Ğ•Ğ›Ğ¯ 2-4:
â€¢ Ğ¡Ğ»ĞµĞ´ÑƒÑÑ‰Ğ¸Ğµ ÑˆĞ°Ğ³Ğ¸
â€¢ ĞœĞµÑ‚Ñ€Ğ¸ĞºĞ¸ ÑƒÑĞ¿ĞµÑ…Ğ°

ğŸ’° ĞĞ¶Ğ¸Ğ´Ğ°ĞµĞ¼Ñ‹Ğ¹ Ğ´Ğ¾Ñ…Ğ¾Ğ´: $X/Ğ¼ĞµÑ""",

            "brainstorm": f"""Ğ¡Ğ³ĞµĞ½ĞµÑ€Ğ¸Ñ€ÑƒĞ¹ 10 Ğ¸Ğ´ĞµĞ¹: {desc}

Ğ”Ğ»Ñ ĞºĞ°Ğ¶Ğ´Ğ¾Ğ¹ Ğ¸Ğ´ĞµĞ¸:
1. [ĞĞ°Ğ·Ğ²Ğ°Ğ½Ğ¸Ğµ]
   ğŸ’° ĞŸĞ¾Ñ‚ĞµĞ½Ñ†Ğ¸Ğ°Ğ»: $X/Ğ¼ĞµÑ
   â± Ğ’Ñ€ĞµĞ¼Ñ Ğ´Ğ¾ Ñ€ĞµĞ·ÑƒĞ»ÑŒÑ‚Ğ°Ñ‚Ğ°
   ğŸ¯ ĞŸĞµÑ€Ğ²Ñ‹Ğ¹ ÑˆĞ°Ğ³""",

            "calculate_income": f"""Ğ Ğ°ÑÑÑ‡Ğ¸Ñ‚Ğ°Ğ¹ Ğ¿Ğ¾Ñ‚ĞµĞ½Ñ†Ğ¸Ğ°Ğ»ÑŒĞ½Ñ‹Ğ¹ Ğ´Ğ¾Ñ…Ğ¾Ğ´: {desc}

ĞšĞĞ›Ğ¬ĞšĞ£Ğ›Ğ¯Ğ¢ĞĞ  Ğ”ĞĞ¥ĞĞ”Ğ:

ğŸ“Š Ğ‘Ğ°Ğ·Ğ¾Ğ²Ñ‹Ğ¹ ÑÑ†ĞµĞ½Ğ°Ñ€Ğ¸Ğ¹:
â€¢ Ğ§Ğ°ÑĞ¾Ğ² Ğ² Ğ½ĞµĞ´ĞµĞ»Ñ: X
â€¢ Ğ¡Ñ‚Ğ°Ğ²ĞºĞ°/Ñ†ĞµĞ½Ğ°: $X
â€¢ Ğ”Ğ¾Ñ…Ğ¾Ğ´: $X/Ğ¼ĞµÑ

ğŸ“ˆ ĞĞ¿Ñ‚Ğ¸Ğ¼Ğ¸ÑÑ‚Ğ¸Ñ‡Ğ½Ñ‹Ğ¹:
â€¢ ĞŸÑ€Ğ¸ Ğ¼Ğ°ÑÑˆÑ‚Ğ°Ğ±Ğ¸Ñ€Ğ¾Ğ²Ğ°Ğ½Ğ¸Ğ¸: $X/Ğ¼ĞµÑ

âš ï¸ ĞšĞ¾Ğ½ÑĞµÑ€Ğ²Ğ°Ñ‚Ğ¸Ğ²Ğ½Ñ‹Ğ¹:
â€¢ ĞœĞ¸Ğ½Ğ¸Ğ¼ÑƒĞ¼: $X/Ğ¼ĞµÑ

ğŸ¯ Ğ ĞµĞºĞ¾Ğ¼ĞµĞ½Ğ´Ğ°Ñ†Ğ¸Ñ: ...""",

            "analyze": f"""ĞŸÑ€Ğ¾Ğ²ĞµĞ´Ğ¸ Ğ°Ğ½Ğ°Ğ»Ğ¸Ğ·: {desc}

SWOT:
âœ… Ğ¡Ğ¸Ğ»ÑŒĞ½Ñ‹Ğµ ÑÑ‚Ğ¾Ñ€Ğ¾Ğ½Ñ‹:
âŒ Ğ¡Ğ»Ğ°Ğ±Ñ‹Ğµ ÑÑ‚Ğ¾Ñ€Ğ¾Ğ½Ñ‹:
ğŸš€ Ğ’Ğ¾Ğ·Ğ¼Ğ¾Ğ¶Ğ½Ğ¾ÑÑ‚Ğ¸:
âš ï¸ Ğ£Ğ³Ñ€Ğ¾Ğ·Ñ‹:

ğŸ“Š Ğ’Ñ‹Ğ²Ğ¾Ğ´: ...""",
        }
        
        prompt = prompts.get(action_type, prompts["create_plan"])
        prompt += f"\n\nĞšĞ¾Ğ½Ñ‚ĞµĞºÑÑ‚: {context[:500]}"
        
        response, success = await ai_engine.generate(
            prompt=prompt,
            max_tokens=config.MAX_TOKENS_ACTION
        )
        
        if success:
            stats.record_task()
        
        return response

# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
# Ğ“Ğ›ĞĞ’ĞĞ«Ğ™ ĞœĞĞ—Ğ“
# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•

class DeepThinkBrain:
    """Ğ“Ğ»Ğ°Ğ²Ğ½Ñ‹Ğ¹ Ğ¼Ğ¾Ğ·Ğ³ ÑĞ¸ÑÑ‚ĞµĞ¼Ñ‹"""
    
    def __init__(self):
        self.knowledge = MoneyKnowledgeBase()
        self.synthesizer = ResponseSynthesizer()
        self.action_gen = ActionGenerator()
    
    async def think(
        self,
        query: str,
        context: ConversationContext = None,
        user_profile: UserProfile = None
    ) -> Dict:
        """Ğ“Ğ»ÑƒĞ±Ğ¾ĞºĞ¸Ğ¹ Ğ°Ğ½Ğ°Ğ»Ğ¸Ğ·"""
        
        import time
        start = time.time()
        
        stats.record_query(self._detect_topic(query))
        
        # ĞšĞ¾Ğ½Ñ‚ĞµĞºÑÑ‚ Ñ€Ğ°Ğ·Ğ³Ğ¾Ğ²Ğ¾Ñ€Ğ°
        ctx_summary = context.get_summary() if context else ""
        
        # ĞšĞ¾Ğ»Ğ»ĞµĞºÑ‚Ğ¸Ğ²Ğ½Ğ¾Ğµ Ğ¼Ñ‹ÑˆĞ»ĞµĞ½Ğ¸Ğµ Ğ°Ğ³ĞµĞ½Ñ‚Ğ¾Ğ²
        responses = await swarm.think_together(query, ctx_summary)
        
        # Ğ¡Ğ¸Ğ½Ñ‚ĞµĞ·
        synthesis = await self.synthesizer.synthesize(
            query, responses, user_profile
        )
        
        # Ğ“ĞµĞ½ĞµÑ€Ğ°Ñ†Ğ¸Ñ Ğ´ĞµĞ¹ÑÑ‚Ğ²Ğ¸Ğ¹
        actions = await self.action_gen.generate(query, synthesis)
        
        # ĞĞ³ĞµĞ½Ñ‚Ñ‹ ĞºĞ¾Ñ‚Ğ¾Ñ€Ñ‹Ğµ Ñ€Ğ°Ğ±Ğ¾Ñ‚Ğ°Ğ»Ğ¸
        agents_used = [name for name, _, success in responses if success]
        
        total_time = time.time() - start
        
        return {
            "response": synthesis,
            "agents": agents_used[:4],
            "actions": actions,
            "time": total_time
        }
    
    def _detect_topic(self, query: str) -> str:
        """ĞĞ¿Ñ€ĞµĞ´ĞµĞ»ĞµĞ½Ğ¸Ğµ Ñ‚ĞµĞ¼Ñ‹"""
        q = query.lower()
        if any(w in q for w in ["Ğ·Ğ°Ñ€Ğ°Ğ±Ğ¾Ñ‚", "Ğ´ĞµĞ½ÑŒĞ³Ğ¸", "Ğ´Ğ¾Ñ…Ğ¾Ğ´"]):
            return "money"
        if any(w in q for w in ["ĞºĞ¾Ğ´", "Ğ±Ğ¾Ñ‚", "Ğ¿Ñ€Ğ¾Ğ³Ñ€Ğ°Ğ¼Ğ¼"]):
            return "tech"
        if any(w in q for w in ["ĞºĞ¾Ğ½Ñ‚ĞµĞ½Ñ‚", "Ñ‚ĞµĞºÑÑ‚"]):
            return "content"
        if any(w in q for w in ["Ğ¼Ğ°Ñ€ĞºĞµÑ‚Ğ¸Ğ½Ğ³", "Ñ€ĞµĞºĞ»Ğ°Ğ¼Ğ°"]):
            return "marketing"
        return "general"

brain = DeepThinkBrain()

# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
# ĞœĞ•ĞĞ•Ğ”Ğ–Ğ•Ğ  ĞŸĞĞ›Ğ¬Ğ—ĞĞ’ĞĞ¢Ğ•Ğ›Ğ•Ğ™
# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•

class UserManager:
    """ĞœĞµĞ½ĞµĞ´Ğ¶ĞµÑ€ Ğ¿Ğ¾Ğ»ÑŒĞ·Ğ¾Ğ²Ğ°Ñ‚ĞµĞ»ĞµĞ¹"""
    
    def __init__(self):
        self.profiles: Dict[int, UserProfile] = {}
        self.contexts: Dict[int, ConversationContext] = {}
    
    def get_profile(self, user_data: Dict) -> UserProfile:
        uid = user_data.get("id")
        if uid not in self.profiles:
            self.profiles[uid] = UserProfile(
                user_id=uid,
                username=user_data.get("username", ""),
                first_name=user_data.get("first_name", "User")
            )
        profile = self.profiles[uid]
        profile.last_active = datetime.now()
        return profile
    
    def get_context(self, user_id: int) -> ConversationContext:
        if user_id not in self.contexts:
            self.contexts[user_id] = ConversationContext(user_id=user_id)
        return self.contexts[user_id]

user_manager = UserManager()

# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
# TELEGRAM BOT
# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•

class TelegramBot:
    """Telegram Ğ±Ğ¾Ñ‚ Ñ Ñ€Ğ°ÑÑˆĞ¸Ñ€ĞµĞ½Ğ½Ñ‹Ğ¼ Ñ„ÑƒĞ½ĞºÑ†Ğ¸Ğ¾Ğ½Ğ°Ğ»Ğ¾Ğ¼"""
    
    def __init__(self):
        self.api = config.TELEGRAM_API
        self.pending_actions: Dict[str, Dict] = {}
    
    async def send(
        self,
        chat_id: int,
        text: str,
        buttons: Dict = None,
        parse_mode: str = "Markdown"
    ):
        """ĞÑ‚Ğ¿Ñ€Ğ°Ğ²ĞºĞ° ÑĞ¾Ğ¾Ğ±Ñ‰ĞµĞ½Ğ¸Ñ"""
        async with httpx.AsyncClient(timeout=config.API_TIMEOUT) as client:
            data = {"chat_id": chat_id, "text": text[:4096]}
            
            if parse_mode:
                data["parse_mode"] = parse_mode
            if buttons:
                data["reply_markup"] = json.dumps(buttons)
            
            try:
                await client.post(f"{self.api}/sendMessage", json=data)
            except:
                # Ğ‘ĞµĞ· Ñ„Ğ¾Ñ€Ğ¼Ğ°Ñ‚Ğ¸Ñ€Ğ¾Ğ²Ğ°Ğ½Ğ¸Ñ
                data.pop("parse_mode", None)
                try:
                    await client.post(f"{self.api}/sendMessage", json=data)
                except Exception as e:
                    logger.error(f"Send error: {e}")
    
    async def answer_callback(self, callback_id: str, text: str = None):
        """ĞÑ‚Ğ²ĞµÑ‚ Ğ½Ğ° callback"""
        async with httpx.AsyncClient(timeout=10) as client:
            try:
                await client.post(
                    f"{self.api}/answerCallbackQuery",
                    json={"callback_query_id": callback_id, "text": text}
                )
            except:
                pass
    
    async def send_typing(self, chat_id: int):
        """Ğ¡Ñ‚Ğ°Ñ‚ÑƒÑ Ğ¿ĞµÑ‡Ğ°Ñ‚Ğ°ĞµÑ‚"""
        async with httpx.AsyncClient(timeout=5) as client:
            try:
                await client.post(
                    f"{self.api}/sendChatAction",
                    json={"chat_id": chat_id, "action": "typing"}
                )
            except:
                pass
    
    def make_buttons(self, actions: List[Dict], user_id: int) -> Dict:
        """Ğ¡Ğ¾Ğ·Ğ´Ğ°Ğ½Ğ¸Ğµ ĞºĞ½Ğ¾Ğ¿Ğ¾Ğº"""
        keyboard = []
        
        for i, action in enumerate(actions[:5]):
            keyboard.append([{
                "text": action.get("name", "ğŸ¤– Ğ”ĞµĞ¹ÑÑ‚Ğ²Ğ¸Ğµ")[:30],
                "callback_data": f"act_{i}_{user_id}"
            }])
        
        # Ğ”Ğ¾Ğ¿Ğ¾Ğ»Ğ½Ğ¸Ñ‚ĞµĞ»ÑŒĞ½Ñ‹Ğµ ĞºĞ½Ğ¾Ğ¿ĞºĞ¸
        keyboard.append([
            {"text": "ğŸ’° Ğ¡Ğ¿Ğ¾ÑĞ¾Ğ±Ñ‹ Ğ·Ğ°Ñ€Ğ°Ğ±Ğ¾Ñ‚ĞºĞ°", "callback_data": f"income_{user_id}"},
            {"text": "ğŸ”¥ Ğ“Ğ¾Ñ€ÑÑ‡Ğ¸Ğµ Ğ½Ğ¸ÑˆĞ¸", "callback_data": f"niches_{user_id}"}
        ])
        
        keyboard.append([
            {"text": "âš¡ Ğ‘Ñ‹ÑÑ‚Ñ€Ñ‹Ğ¹ ÑÑ‚Ğ°Ñ€Ñ‚", "callback_data": f"quickwin_{user_id}"},
            {"text": "ğŸ“Š Ğ¡Ñ‚Ğ°Ñ‚Ğ¸ÑÑ‚Ğ¸ĞºĞ°", "callback_data": f"stats_{user_id}"}
        ])
        
        keyboard.append([
            {"text": "âš™ï¸ ĞĞ°ÑÑ‚Ñ€Ğ¾Ğ¹ĞºĞ¸", "callback_data": f"settings_{user_id}"},
            {"text": "â“ ĞŸĞ¾Ğ¼Ğ¾Ñ‰ÑŒ", "callback_data": f"help_{user_id}"}
        ])
        
        return {"inline_keyboard": keyboard}
    
    # â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
    # ĞšĞĞœĞĞĞ”Ğ«
    # â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
    
    async def cmd_start(self, chat_id: int, user_data: Dict):
        """ĞšĞ¾Ğ¼Ğ°Ğ½Ğ´Ğ° /start"""
        profile = user_manager.get_profile(user_data)
        
        text = f"""ğŸ§  *DEEPTHINK AUTOHUSTLE v3.0*
_Ultimate Money Edition_

ĞŸÑ€Ğ¸Ğ²ĞµÑ‚, {profile.first_name}! ğŸ‘‹

Ğ¯ - AI-ÑĞ¸ÑÑ‚ĞµĞ¼Ğ° Ğ´Ğ»Ñ Ğ¿Ğ¾Ğ¸ÑĞºĞ° ÑĞ¿Ğ¾ÑĞ¾Ğ±Ğ¾Ğ² Ğ·Ğ°Ñ€Ğ°Ğ±Ğ¾Ñ‚ĞºĞ°.

ğŸ¤– *{len(swarm.agents)} ĞĞ“Ğ•ĞĞ¢ĞĞ’:*
â€¢ Ğ­ĞºÑĞ¿ĞµÑ€Ñ‚ Ğ·Ğ°Ñ€Ğ°Ğ±Ğ¾Ñ‚ĞºĞ°, Ğ¡Ñ‚Ñ€Ğ°Ñ‚ĞµĞ³, ĞœĞ°Ñ€ĞºĞµÑ‚Ğ¾Ğ»Ğ¾Ğ³
â€¢ ĞšĞ¾Ğ´ĞµÑ€, ĞšĞ¾Ğ¿Ğ¸Ñ€Ğ°Ğ¹Ñ‚ĞµÑ€, SEO-ÑĞ¿ĞµÑ†Ğ¸Ğ°Ğ»Ğ¸ÑÑ‚
â€¢ ĞšÑ€Ğ¸Ğ¿Ñ‚Ğ¾ÑĞºÑĞ¿ĞµÑ€Ñ‚, SaaS-ÑĞºÑĞ¿ĞµÑ€Ñ‚ Ğ¸ Ğ´Ñ€ÑƒĞ³Ğ¸Ğµ

ğŸ’° *Ğ§Ğ¢Ğ Ğ¯ Ğ£ĞœĞ•Ğ®:*
â€¢ ĞĞ°Ğ¹Ñ‚Ğ¸ ÑĞ¿Ğ¾ÑĞ¾Ğ±Ñ‹ Ğ·Ğ°Ñ€Ğ°Ğ±Ğ¾Ñ‚ĞºĞ° Ğ¿Ğ¾Ğ´ Ñ‚ĞµĞ±Ñ
â€¢ Ğ¡Ğ¾Ğ·Ğ´Ğ°Ñ‚ÑŒ Ğ±Ğ¸Ğ·Ğ½ĞµÑ-Ğ¿Ğ»Ğ°Ğ½ Ğ·Ğ° Ğ¼Ğ¸Ğ½ÑƒÑ‚Ñ‹
â€¢ ĞĞ°Ğ¿Ğ¸ÑĞ°Ñ‚ÑŒ ĞºĞ¾Ğ´, ĞºĞ¾Ğ½Ñ‚ĞµĞ½Ñ‚, ÑÑ‚Ñ€Ğ°Ñ‚ĞµĞ³Ğ¸Ñ
â€¢ Ğ Ğ°ÑÑÑ‡Ğ¸Ñ‚Ğ°Ñ‚ÑŒ Ğ¿Ğ¾Ñ‚ĞµĞ½Ñ†Ğ¸Ğ°Ğ»ÑŒĞ½Ñ‹Ğ¹ Ğ´Ğ¾Ñ…Ğ¾Ğ´

ğŸš€ *Ğ‘Ğ«Ğ¡Ğ¢Ğ Ğ«Ğ™ Ğ¡Ğ¢ĞĞ Ğ¢:*
â€¢ "ĞšĞ°Ğº Ğ·Ğ°Ñ€Ğ°Ğ±Ğ¾Ñ‚Ğ°Ñ‚ÑŒ Ğ½Ğ° AI?"
â€¢ "Ğ¡Ğ¾Ğ·Ğ´Ğ°Ğ¹ Telegram-Ğ±Ğ¾Ñ‚Ğ° Ğ´Ğ»Ñ Ğ±Ğ¸Ğ·Ğ½ĞµÑĞ°"
â€¢ "Ğ¢Ğ¾Ğ¿ Ğ½Ğ¸ÑˆĞ¸ 2025 Ğ´Ğ»Ñ Ğ½Ğ¾Ğ²Ğ¸Ñ‡ĞºĞ°"
â€¢ "ĞŸĞ»Ğ°Ğ½ Ğ·Ğ°Ñ€Ğ°Ğ±Ğ¾Ñ‚ĞºĞ° $1000/Ğ¼ĞµÑ"

ğŸ’¡ ĞŸÑ€Ğ¾ÑÑ‚Ğ¾ Ğ½Ğ°Ğ¿Ğ¸ÑˆĞ¸ ÑĞ²Ğ¾Ğ¹ Ğ²Ğ¾Ğ¿Ñ€Ğ¾Ñ!

/help - Ğ²ÑĞµ ĞºĞ¾Ğ¼Ğ°Ğ½Ğ´Ñ‹
/income - ÑĞ¿Ğ¾ÑĞ¾Ğ±Ñ‹ Ğ·Ğ°Ñ€Ğ°Ğ±Ğ¾Ñ‚ĞºĞ°
/niches - Ğ³Ğ¾Ñ€ÑÑ‡Ğ¸Ğµ Ğ½Ğ¸ÑˆĞ¸"""
        
        await self.send(chat_id, text)
    
    async def cmd_help(self, chat_id: int):
        """ĞšĞ¾Ğ¼Ğ°Ğ½Ğ´Ğ° /help"""
        text = """ğŸ“– *ĞšĞĞœĞĞĞ”Ğ« DEEPTHINK v3.0*

*ĞĞ¡ĞĞĞ’ĞĞ«Ğ•:*
/start - ĞĞ°Ñ‡Ğ°Ğ»Ğ¾ Ñ€Ğ°Ğ±Ğ¾Ñ‚Ñ‹
/help - Ğ­Ñ‚Ğ° ÑĞ¿Ñ€Ğ°Ğ²ĞºĞ°

*Ğ—ĞĞ ĞĞ‘ĞĞ¢ĞĞš:*
/income - 8 ÑĞ¿Ğ¾ÑĞ¾Ğ±Ğ¾Ğ² Ğ·Ğ°Ñ€Ğ°Ğ±Ğ¾Ñ‚ĞºĞ°
/niches - Ğ“Ğ¾Ñ€ÑÑ‡Ğ¸Ğµ Ğ½Ğ¸ÑˆĞ¸ 2024-2025
/quickwin - Ğ‘Ñ‹ÑÑ‚Ñ€Ñ‹Ğµ Ğ¿Ğ¾Ğ±ĞµĞ´Ñ‹ (Ğ´ĞµĞ½ÑŒĞ³Ğ¸ Ğ·Ğ° Ğ½ĞµĞ´ĞµĞ»Ñ)
/calc - ĞšĞ°Ğ»ÑŒĞºÑƒĞ»ÑÑ‚Ğ¾Ñ€ Ğ´Ğ¾Ñ…Ğ¾Ğ´Ğ°

*Ğ¡ĞĞ—Ğ”ĞĞĞ˜Ğ•:*
/plan [Ñ‚ĞµĞ¼Ğ°] - Ğ‘Ğ¸Ğ·Ğ½ĞµÑ-Ğ¿Ğ»Ğ°Ğ½
/content [Ñ‚ĞµĞ¼Ğ°] - Ğ“Ğ¾Ñ‚Ğ¾Ğ²Ñ‹Ğ¹ ĞºĞ¾Ğ½Ñ‚ĞµĞ½Ñ‚
/code [Ğ¾Ğ¿Ğ¸ÑĞ°Ğ½Ğ¸Ğµ] - ĞĞ°Ğ¿Ğ¸ÑĞ°Ñ‚ÑŒ ĞºĞ¾Ğ´
/ideas [Ñ‚ĞµĞ¼Ğ°] - 10 Ğ¸Ğ´ĞµĞ¹

*Ğ¡Ğ˜Ğ¡Ğ¢Ğ•ĞœĞ:*
/stats - Ğ¡Ñ‚Ğ°Ñ‚Ğ¸ÑÑ‚Ğ¸ĞºĞ° Ğ±Ğ¾Ñ‚Ğ°
/agents - Ğ¡Ğ¿Ğ¸ÑĞ¾Ğº Ğ°Ğ³ĞµĞ½Ñ‚Ğ¾Ğ²
/settings - ĞĞ°ÑÑ‚Ñ€Ğ¾Ğ¹ĞºĞ¸
/mode - ĞŸĞµÑ€ĞµĞºĞ»ÑÑ‡Ğ¸Ñ‚ÑŒ Ñ€ĞµĞ¶Ğ¸Ğ¼ ÑĞºĞ¾Ğ½Ğ¾Ğ¼Ğ¸Ğ¸

*Ğ¡ĞĞ’Ğ•Ğ¢Ğ«:*
âœ… Ğ§ĞµĞ¼ ĞºĞ¾Ğ½ĞºÑ€ĞµÑ‚Ğ½ĞµĞµ Ğ·Ğ°Ğ¿Ñ€Ğ¾Ñ - Ñ‚ĞµĞ¼ Ğ»ÑƒÑ‡ÑˆĞµ Ğ¾Ñ‚Ğ²ĞµÑ‚
âœ… Ğ£ĞºĞ°Ğ·Ñ‹Ğ²Ğ°Ğ¹ Ğ±ÑĞ´Ğ¶ĞµÑ‚, ÑÑ€Ğ¾ĞºĞ¸, Ñ†ĞµĞ»Ğ¸
âœ… Ğ˜ÑĞ¿Ğ¾Ğ»ÑŒĞ·ÑƒĞ¹ ĞºĞ½Ğ¾Ğ¿ĞºĞ¸ Ğ´Ğ»Ñ Ğ´ĞµĞ¹ÑÑ‚Ğ²Ğ¸Ğ¹"""
        
        await self.send(chat_id, text)
    
    async def cmd_income(self, chat_id: int):
        """Ğ¡Ğ¿Ğ¾ÑĞ¾Ğ±Ñ‹ Ğ·Ğ°Ñ€Ğ°Ğ±Ğ¾Ñ‚ĞºĞ°"""
        text = "ğŸ’° *8 Ğ¡ĞŸĞĞ¡ĞĞ‘ĞĞ’ Ğ—ĞĞ ĞĞ‘ĞĞ¢ĞšĞ Ğ¡ AI*\n\n"
        
        for model, data in MoneyKnowledgeBase.INCOME_STREAMS.items():
            text += f"*{data['name']}*\n"
            text += f"ğŸ’µ {data['income_range']}\n"
            text += f"â± {data['time_to_profit']}\n"
            text += f"ğŸ¤– AI: {data['ai_automation']}\n\n"
        
        text += "_ĞĞ°Ğ¶Ğ¼Ğ¸ Ğ½Ğ° ĞºĞ½Ğ¾Ğ¿ĞºÑƒ Ğ´Ğ»Ñ Ğ¿Ğ¾Ğ´Ñ€Ğ¾Ğ±Ğ½Ğ¾ÑÑ‚ĞµĞ¹_"
        
        buttons = {"inline_keyboard": [
            [{"text": "ğŸ¨ Ğ¤Ñ€Ğ¸Ğ»Ğ°Ğ½Ñ", "callback_data": "bm_freelance"}],
            [{"text": "ğŸ”— ĞŸĞ°Ñ€Ñ‚Ğ½Ñ‘Ñ€ĞºĞ¸", "callback_data": "bm_affiliate"}],
            [{"text": "ğŸ“¦ Ğ”Ñ€Ğ¾Ğ¿ÑˆĞ¸Ğ¿Ğ¿Ğ¸Ğ½Ğ³", "callback_data": "bm_dropshipping"}],
            [{"text": "ğŸ“± Ğ¦Ğ¸Ñ„Ñ€Ğ¾Ğ²Ñ‹Ğµ Ğ¿Ñ€Ğ¾Ğ´ÑƒĞºÑ‚Ñ‹", "callback_data": "bm_digital"}],
            [{"text": "â˜ï¸ SaaS", "callback_data": "bm_saas"}],
            [{"text": "ğŸ¤– AI-ÑĞµÑ€Ğ²Ğ¸ÑÑ‹", "callback_data": "bm_ai"}],
        ]}
        
        await self.send(chat_id, text, buttons)
    
    async def cmd_niches(self, chat_id: int):
        """Ğ“Ğ¾Ñ€ÑÑ‡Ğ¸Ğµ Ğ½Ğ¸ÑˆĞ¸"""
        text = "ğŸ”¥ *Ğ“ĞĞ Ğ¯Ğ§Ğ˜Ğ• ĞĞ˜Ğ¨Ğ˜ 2024-2025*\n\n"
        
        for niche in MoneyKnowledgeBase.NICHES_2024_2025:
            text += f"â€¢ *{niche['niche']}*\n"
            text += f"  Ğ¢Ñ€ĞµĞ½Ğ´: {niche['trend']} | ĞšĞ¾Ğ½ĞºÑƒÑ€ĞµĞ½Ñ†Ğ¸Ñ: {niche['competition']}\n\n"
        
        text += "_Ğ’Ñ‹Ğ±ĞµÑ€Ğ¸ Ğ½Ğ¸ÑˆÑƒ Ğ¸ ÑĞ¿Ñ€Ğ¾ÑĞ¸ Ğ¿Ğ¾Ğ´Ñ€Ğ¾Ğ±Ğ½ĞµĞµ!_"
        
        await self.send(chat_id, text)
    
    async def cmd_quickwin(self, chat_id: int):
        """Ğ‘Ñ‹ÑÑ‚Ñ€Ñ‹Ğµ Ğ¿Ğ¾Ğ±ĞµĞ´Ñ‹"""
        text = "âš¡ *Ğ‘Ğ«Ğ¡Ğ¢Ğ Ğ«Ğ• ĞŸĞĞ‘Ğ•Ğ”Ğ« - Ğ”Ğ•ĞĞ¬Ğ“Ğ˜ Ğ—Ğ ĞĞ•Ğ”Ğ•Ğ›Ğ®*\n\n"
        
        for i, qw in enumerate(MoneyKnowledgeBase.QUICK_WINS, 1):
            text += f"*{i}. {qw['name']}*\n"
            text += f"ğŸ’° {qw['income']}\n"
            text += f"â± {qw['time']}\n"
            text += f"ğŸ“‹ {' â†’ '.join(qw['steps'])}\n\n"
        
        text += "_ĞĞ°Ğ¿Ğ¸ÑˆĞ¸ Ğ½Ğ¾Ğ¼ĞµÑ€ Ğ´Ğ»Ñ Ğ¿Ğ¾Ğ´Ñ€Ğ¾Ğ±Ğ½Ğ¾Ğ³Ğ¾ Ğ¿Ğ»Ğ°Ğ½Ğ°!_"
        
        await self.send(chat_id, text)
    
    async def cmd_stats(self, chat_id: int):
        """Ğ¡Ñ‚Ğ°Ñ‚Ğ¸ÑÑ‚Ğ¸ĞºĞ°"""
        await self.send(chat_id, stats.get_summary())
    
    async def cmd_agents(self, chat_id: int):
        """Ğ¡Ğ¿Ğ¸ÑĞ¾Ğº Ğ°Ğ³ĞµĞ½Ñ‚Ğ¾Ğ²"""
        text = f"ğŸ¤– *{len(swarm.agents)} ĞĞ“Ğ•ĞĞ¢ĞĞ’ DEEPTHINK*\n\n"
        
        for agent in swarm.agents.values():
            text += f"{agent.display_name}\n"
            text += f"  _{agent.specialty}_\n"
            text += f"  ğŸ“Š Ğ’Ñ‹Ğ·Ğ¾Ğ²Ğ¾Ğ²: {agent.calls}\n\n"
        
        await self.send(chat_id, text)
    
    async def cmd_settings(self, chat_id: int, user_id: int):
        """ĞĞ°ÑÑ‚Ñ€Ğ¾Ğ¹ĞºĞ¸"""
        profile = user_manager.profiles.get(user_id)
        
        text = f"""âš™ï¸ *ĞĞĞ¡Ğ¢Ğ ĞĞ™ĞšĞ˜*

ğŸ‘¤ ID: `{user_id}`
ğŸ“Š Ğ—Ğ°Ğ¿Ñ€Ğ¾ÑĞ¾Ğ²: {profile.total_queries if profile else 0}
ğŸ¯ Ğ£Ñ€Ğ¾Ğ²ĞµĞ½ÑŒ: {profile.expertise_level if profile else 'beginner'}

ğŸ’¡ *Ğ ĞµĞ¶Ğ¸Ğ¼ ÑĞºĞ¾Ğ½Ğ¾Ğ¼Ğ¸Ğ¸:* {'âœ… Ğ’ĞšĞ›' if config.ECONOMY_MODE else 'âŒ Ğ’Ğ«ĞšĞ›'}
_(Ğ±ĞµÑĞ¿Ğ»Ğ°Ñ‚Ğ½Ñ‹Ğµ Ğ¼Ğ¾Ğ´ĞµĞ»Ğ¸ Ğ´Ğ»Ñ ÑĞºĞ¾Ğ½Ğ¾Ğ¼Ğ¸Ğ¸ Ñ‚Ğ¾ĞºĞµĞ½Ğ¾Ğ²)_

ğŸ”§ Ğ’Ñ‹Ğ±ĞµÑ€Ğ¸ Ğ½Ğ°ÑÑ‚Ñ€Ğ¾Ğ¹ĞºÑƒ:"""
        
        buttons = {"inline_keyboard": [
            [
                {"text": "ğŸŒ± ĞĞ¾Ğ²Ğ¸Ñ‡Ğ¾Ğº", "callback_data": f"lvl_beginner_{user_id}"},
                {"text": "ğŸ“ˆ Ğ¡Ñ€ĞµĞ´Ğ½Ğ¸Ğ¹", "callback_data": f"lvl_intermediate_{user_id}"},
                {"text": "ğŸ“ Ğ­ĞºÑĞ¿ĞµÑ€Ñ‚", "callback_data": f"lvl_expert_{user_id}"}
            ],
            [
                {"text": "ğŸ’° Ğ­ĞºĞ¾Ğ½Ğ¾Ğ¼Ğ¸Ñ Ğ’ĞšĞ›" if not config.ECONOMY_MODE else "ğŸš€ Ğ­ĞºĞ¾Ğ½Ğ¾Ğ¼Ğ¸Ñ Ğ’Ğ«ĞšĞ›", 
                 "callback_data": f"toggle_economy_{user_id}"}
            ]
        ]}
        
        await self.send(chat_id, text, buttons)
    
    async def cmd_mode(self, chat_id: int):
        """ĞŸĞµÑ€ĞµĞºĞ»ÑÑ‡ĞµĞ½Ğ¸Ğµ Ñ€ĞµĞ¶Ğ¸Ğ¼Ğ°"""
        config.ECONOMY_MODE = not config.ECONOMY_MODE
        status = "âœ… Ğ’ĞšĞ›Ğ®Ğ§ĞĞ" if config.ECONOMY_MODE else "âŒ Ğ’Ğ«ĞšĞ›Ğ®Ğ§Ğ•Ğ"
        await self.send(chat_id, f"ğŸ’¡ Ğ ĞµĞ¶Ğ¸Ğ¼ ÑĞºĞ¾Ğ½Ğ¾Ğ¼Ğ¸Ğ¸ Ñ‚Ğ¾ĞºĞµĞ½Ğ¾Ğ²: {status}")
    
    # â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
    # ĞĞ‘Ğ ĞĞ‘ĞĞ¢ĞšĞ Ğ¡ĞĞĞ‘Ğ©Ğ•ĞĞ˜Ğ™
    # â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
    
    async def handle_message(self, chat_id: int, user_data: Dict, text: str):
        """ĞĞ±Ñ€Ğ°Ğ±Ğ¾Ñ‚ĞºĞ° ÑĞ¾Ğ¾Ğ±Ñ‰ĞµĞ½Ğ¸Ñ"""
        user_id = user_data.get("id")
        profile = user_manager.get_profile(user_data)
        context = user_manager.get_context(user_id)
        
        # Ğ¡Ğ¾Ñ…Ñ€Ğ°Ğ½ÑĞµĞ¼ Ğ² ĞºĞ¾Ğ½Ñ‚ĞµĞºÑÑ‚
        context.add_message("user", text)
        context.last_query = text
        profile.total_queries += 1
        
        await self.send_typing(chat_id)
        
        # Ğ¡Ñ‚Ğ°Ñ‚ÑƒÑ
        await self.send(chat_id,
            "ğŸ§  *DEEP THINKING...*\n\n"
            f"ğŸ¤– Ğ¡Ğ¾Ğ±Ğ¸Ñ€Ğ°Ñ {config.MAX_AGENTS_PER_QUERY} ÑĞºÑĞ¿ĞµÑ€Ñ‚Ğ¾Ğ²...\n"
            "âš¡ ĞĞ½Ğ°Ğ»Ğ¸Ğ·Ğ¸Ñ€ÑƒÑ...\n"
            "ğŸ’° Ğ˜Ñ‰Ñƒ ÑĞ¿Ğ¾ÑĞ¾Ğ±Ñ‹ Ğ·Ğ°Ñ€Ğ°Ğ±Ğ¾Ñ‚ĞºĞ°..."
        )
        
        try:
            # Ğ”ÑƒĞ¼Ğ°ĞµĞ¼
            result = await brain.think(text, context, profile)
            
            response = result["response"]
            agents_used = result["agents"]
            actions = result["actions"]
            think_time = result["time"]
            
            # Ğ¡Ğ¾Ñ…Ñ€Ğ°Ğ½ÑĞµĞ¼ Ğ² ĞºĞ¾Ğ½Ñ‚ĞµĞºÑÑ‚
            context.add_message("assistant", response[:300])
            context.last_actions = actions
            context.last_response = response
            
            # Ğ¡Ğ¾Ñ…Ñ€Ğ°Ğ½ÑĞµĞ¼ Ğ´ĞµĞ¹ÑÑ‚Ğ²Ğ¸Ñ Ğ´Ğ»Ñ callback
            for i, action in enumerate(actions):
                self.pending_actions[f"act_{i}_{user_id}"] = {
                    "action": action,
                    "context": text,
                    "response": response[:1000]
                }
            
            # Footer
            agents_str = ", ".join(agents_used[:3])
            footer = f"\n\n---\nğŸ‘¥ _{agents_str}_\nâ± _{think_time:.1f}Ñ_"
            
            full_response = response + footer
            
            # ĞšĞ½Ğ¾Ğ¿ĞºĞ¸
            buttons = self.make_buttons(actions, user_id)
            
            await self.send(chat_id, full_response[:4096], buttons)
            
        except Exception as e:
            logger.error(f"Error: {e}")
            stats.record_error()
            await self.send(chat_id, f"âš ï¸ ĞÑˆĞ¸Ğ±ĞºĞ°: {str(e)[:200]}\n\nĞŸĞ¾Ğ¿Ñ€Ğ¾Ğ±ÑƒĞ¹ Ğ¿ĞµÑ€ĞµÑ„Ğ¾Ñ€Ğ¼ÑƒĞ»Ğ¸Ñ€Ğ¾Ğ²Ğ°Ñ‚ÑŒ.")
    
    async def handle_callback(self, callback_id: str, chat_id: int, user_id: int, data: str):
        """ĞĞ±Ñ€Ğ°Ğ±Ğ¾Ñ‚ĞºĞ° callback"""
        
        await self.answer_callback(callback_id)
        
        # Ğ¡Ñ‚Ğ°Ñ‚Ğ¸ÑÑ‚Ğ¸ĞºĞ°
        if data.startswith("stats_"):
            await self.cmd_stats(chat_id)
            return
        
        # ĞŸĞ¾Ğ¼Ğ¾Ñ‰ÑŒ
        if data.startswith("help_"):
            await self.cmd_help(chat_id)
            return
        
        # ĞĞ°ÑÑ‚Ñ€Ğ¾Ğ¹ĞºĞ¸
        if data.startswith("settings_"):
            await self.cmd_settings(chat_id, user_id)
            return
        
        # Ğ¡Ğ¿Ğ¾ÑĞ¾Ğ±Ñ‹ Ğ·Ğ°Ñ€Ğ°Ğ±Ğ¾Ñ‚ĞºĞ°
        if data.startswith("income_"):
            await self.cmd_income(chat_id)
            return
        
        # ĞĞ¸ÑˆĞ¸
        if data.startswith("niches_"):
            await self.cmd_niches(chat_id)
            return
        
        # Ğ‘Ñ‹ÑÑ‚Ñ€Ñ‹Ğµ Ğ¿Ğ¾Ğ±ĞµĞ´Ñ‹
        if data.startswith("quickwin_"):
            await self.cmd_quickwin(chat_id)
            return
        
        # Ğ‘Ğ¸Ğ·Ğ½ĞµÑ-Ğ¼Ğ¾Ğ´ĞµĞ»Ğ¸
        if data.startswith("bm_"):
            model_map = {
                "bm_freelance": BusinessModel.FREELANCE,
                "bm_affiliate": BusinessModel.AFFILIATE,
                "bm_dropshipping": BusinessModel.DROPSHIPPING,
                "bm_digital": BusinessModel.DIGITAL_PRODUCTS,
                "bm_saas": BusinessModel.SAAS,
                "bm_ai": BusinessModel.AI_SERVICES,
            }
            model = model_map.get(data)
            if model:
                info = MoneyKnowledgeBase.format_business_model(model)
                await self.send(chat_id, info)
            return
        
        # Ğ£Ñ€Ğ¾Ğ²ĞµĞ½ÑŒ
        if data.startswith("lvl_"):
            parts = data.split("_")
            level = parts[1]
            if user_id in user_manager.profiles:
                user_manager.profiles[user_id].expertise_level = level
            await self.send(chat_id, f"âœ… Ğ£Ñ€Ğ¾Ğ²ĞµĞ½ÑŒ: *{level}*")
            return
        
        # ĞŸĞµÑ€ĞµĞºĞ»ÑÑ‡ĞµĞ½Ğ¸Ğµ ÑĞºĞ¾Ğ½Ğ¾Ğ¼Ğ¸Ğ¸
        if data.startswith("toggle_economy_"):
            config.ECONOMY_MODE = not config.ECONOMY_MODE
            status = "âœ… Ğ’ĞšĞ›" if config.ECONOMY_MODE else "âŒ Ğ’Ğ«ĞšĞ›"
            await self.send(chat_id, f"ğŸ’¡ Ğ ĞµĞ¶Ğ¸Ğ¼ ÑĞºĞ¾Ğ½Ğ¾Ğ¼Ğ¸Ğ¸: {status}")
            return
        
        # Ğ’Ñ‹Ğ¿Ğ¾Ğ»Ğ½ĞµĞ½Ğ¸Ğµ Ğ´ĞµĞ¹ÑÑ‚Ğ²Ğ¸Ñ
        if data.startswith("act_"):
            key = data
            if key in self.pending_actions:
                action_data = self.pending_actions[key]
                action = action_data["action"]
                context = action_data.get("context", "")
                response = action_data.get("response", "")
                
                await self.send_typing(chat_id)
                await self.send(chat_id, f"âš™ï¸ Ğ’Ñ‹Ğ¿Ğ¾Ğ»Ğ½ÑÑ: {action.get('name', '')}...")
                
                try:
                    result = await ActionGenerator.execute(
                        action, 
                        f"{context}\n\n{response}"
                    )
                    
                    profile = user_manager.profiles.get(user_id)
                    if profile:
                        profile.total_tasks += 1
                    
                    # Ğ Ğ°Ğ·Ğ±Ğ¸Ğ²Ğ°ĞµĞ¼ Ğ´Ğ»Ğ¸Ğ½Ğ½Ñ‹Ğ¹ Ğ¾Ñ‚Ğ²ĞµÑ‚
                    if len(result) > 4000:
                        parts = [result[i:i+4000] for i in range(0, len(result), 4000)]
                        for i, part in enumerate(parts):
                            header = f"ğŸ“„ *Ğ§Ğ°ÑÑ‚ÑŒ {i+1}/{len(parts)}*\n\n" if len(parts) > 1 else ""
                            await self.send(chat_id, header + part)
                    else:
                        await self.send(chat_id, f"âœ… *Ğ“Ğ¾Ñ‚Ğ¾Ğ²Ğ¾!*\n\n{result}")
                        
                except Exception as e:
                    await self.send(chat_id, f"âš ï¸ ĞÑˆĞ¸Ğ±ĞºĞ°: {str(e)[:200]}")
            else:
                await self.send(chat_id, "âš ï¸ Ğ”ĞµĞ¹ÑÑ‚Ğ²Ğ¸Ğµ ÑƒÑÑ‚Ğ°Ñ€ĞµĞ»Ğ¾. Ğ¡Ğ´ĞµĞ»Ğ°Ğ¹ Ğ½Ğ¾Ğ²Ñ‹Ğ¹ Ğ·Ğ°Ğ¿Ñ€Ğ¾Ñ.")
            return
    
    async def handle_update(self, update: Dict):
        """ĞĞ±Ñ€Ğ°Ğ±Ğ¾Ñ‚ĞºĞ° Ğ¾Ğ±Ğ½Ğ¾Ğ²Ğ»ĞµĞ½Ğ¸Ñ"""
        try:
            # Ğ¡Ğ¾Ğ¾Ğ±Ñ‰ĞµĞ½Ğ¸Ñ
            if "message" in update and "text" in update["message"]:
                msg = update["message"]
                chat_id = msg["chat"]["id"]
                user_data = msg.get("from", {})
                text = msg["text"]
                
                # ĞšĞ¾Ğ¼Ğ°Ğ½Ğ´Ñ‹
                commands = {
                    "/start": lambda: self.cmd_start(chat_id, user_data),
                    "/help": lambda: self.cmd_help(chat_id),
                    "/income": lambda: self.cmd_income(chat_id),
                    "/niches": lambda: self.cmd_niches(chat_id),
                    "/quickwin": lambda: self.cmd_quickwin(chat_id),
                    "/stats": lambda: self.cmd_stats(chat_id),
                    "/agents": lambda: self.cmd_agents(chat_id),
                    "/settings": lambda: self.cmd_settings(chat_id, user_data.get("id")),
                    "/mode": lambda: self.cmd_mode(chat_id),
                }
                
                if text in commands:
                    await commands[text]()
                elif text.startswith("/"):
                    await self.send(chat_id, "â“ ĞĞµĞ¸Ğ·Ğ²ĞµÑÑ‚Ğ½Ğ°Ñ ĞºĞ¾Ğ¼Ğ°Ğ½Ğ´Ğ°. /help")
                else:
                    await self.handle_message(chat_id, user_data, text)
            
            # Callbacks
            elif "callback_query" in update:
                cb = update["callback_query"]
                await self.handle_callback(
                    cb["id"],
                    cb["message"]["chat"]["id"],
                    cb["from"]["id"],
                    cb["data"]
                )
                
        except Exception as e:
            logger.error(f"Update error: {e}")
            stats.record_error()
    
    async def run(self):
        """Ğ—Ğ°Ğ¿ÑƒÑĞº Ğ±Ğ¾Ñ‚Ğ°"""
        
        logger.info("=" * 60)
        logger.info("ğŸ§  DEEPTHINK AUTOHUSTLE v3.0 - ULTIMATE MONEY EDITION")
        logger.info("=" * 60)
        logger.info(f"ğŸ¤– ĞĞ³ĞµĞ½Ñ‚Ğ¾Ğ²: {len(swarm.agents)}")
        logger.info(f"ğŸ’¡ Ğ ĞµĞ¶Ğ¸Ğ¼ ÑĞºĞ¾Ğ½Ğ¾Ğ¼Ğ¸Ğ¸: {'Ğ’ĞšĞ›' if config.ECONOMY_MODE else 'Ğ’Ğ«ĞšĞ›'}")
        logger.info(f"ğŸ”§ ĞœĞ¾Ğ´ĞµĞ»ÑŒ: {config.DEFAULT_MODEL}")
        logger.info("=" * 60)
        
        offset = 0
        
        async with httpx.AsyncClient(timeout=config.API_TIMEOUT) as client:
            logger.info("âœ… Ğ‘ĞĞ¢ Ğ—ĞĞŸĞ£Ğ©Ğ•Ğ!")
            
            while True:
                try:
                    response = await client.get(
                        f"{self.api}/getUpdates",
                        params={"offset": offset, "timeout": config.POLLING_TIMEOUT}
                    )
                    
                    data = response.json()
                    
                    if data.get("ok") and data.get("result"):
                        for update in data["result"]:
                            offset = update["update_id"] + 1
                            asyncio.create_task(self.handle_update(update))
                    
                except httpx.TimeoutException:
                    continue
                except Exception as e:
                    logger.error(f"Polling error: {e}")
                    stats.record_error()
                    await asyncio.sleep(5)

# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
# Ğ—ĞĞŸĞ£Ğ¡Ğš
# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•

async def main():
    """Ğ“Ğ»Ğ°Ğ²Ğ½Ğ°Ñ Ñ„ÑƒĞ½ĞºÑ†Ğ¸Ñ"""
    print("\n" + "â•" * 60)
    print("ğŸ§  DEEPTHINK AUTOHUSTLE v3.0")
    print("ğŸ’° ULTIMATE MONEY EDITION")
    print("â•" * 60 + "\n")
    
    bot = TelegramBot()
    await bot.run()

if __name__ == "__main__":
    try:
        asyncio.run(main())
    except KeyboardInterrupt:
        print("\nğŸ‘‹ Ğ‘Ğ¾Ñ‚ Ğ¾ÑÑ‚Ğ°Ğ½Ğ¾Ğ²Ğ»ĞµĞ½")
    except Exception as e:
        print(f"âŒ ĞÑˆĞ¸Ğ±ĞºĞ°: {e}")
        import traceback
        traceback.print_exc()
